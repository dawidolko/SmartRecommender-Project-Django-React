\documentclass[a4paper,12pt,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amsmath, amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{url}
\usepackage{titlesec}
\usepackage{tocloft}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{xcolor}

% Marginesy
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% Numeracja stron na środku
\pagestyle{plain}

% Interlinia 1,5
\onehalfspacing

% Wcięcia akapitów
\setlength{\parindent}{1cm}

% Tytuły - wyrównane do prawej
\titleformat{\section}[block]{\bfseries\Large\raggedright}{}{1em}{}
\titleformat{\subsection}[block]{\bfseries\large\raggedright}{}{1em}{}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red}
}

\begin{document}

\begin{titlepage}

\begin{minipage}{0.7\textwidth}
    {\large\bf UNIWERSYTET RZESZOWSKI}\\
    {\large\bf Wydział Nauk Ścisłych i Technicznych}
\end{minipage}
\hfill
\begin{minipage}{0.25\textwidth}
    \centering
    \includegraphics[width=8em]{logoUR.jpg}
\end{minipage}


\vspace{3cm}

\begin{center}
    {\Large Dawid Olko} \\
    {\large nr albumu: 125148} \\
    {\large Kierunek: Informatyka}
\end{center}

\vspace{2cm}

\begin{center}
    {\LARGE\bf System rekomendacji produktów oparty na filtracji współpracy, analizie sentymentu i regułach asocjacyjnych}
\end{center}

\vspace{1.5cm}

\begin{center}
    {\large Praca inżynierska}
\end{center}

\vspace{1.5cm}

\begin{flushright}
    {\large Praca wykonana pod kierunkiem}\\
    {\large dr inż. Piotra Grochowalskiego}
\end{flushright}

\vspace{3cm}

\begin{center}
    {\large Rzesz\'ow, 2026}
\end{center}

\end{titlepage}

% Spis treści
\tableofcontents
\newpage


\section*{Wstęp}
\addcontentsline{toc}{section}{Wstęp}

Współczesne sklepy internetowe oferują tysiące produktów, co utrudnia wybór. Systemy rekomendacyjne rozwiązują ten problem poprzez spersonalizowane sugestie.

Rozwój technologii e-commerce oraz dynamiczny wzrost ilości dostępnych produktów w sklepach internetowych stworzył nowe wyzwanie – problem wyboru optymalnego produktu spośród tysięcy opcji. W odpowiedzi na to wyzwanie narodziły się systemy rekomendacyjne, które od początku XXI wieku stały się fundamentalnym narzędziem wspierającym decyzje użytkowników. Pionierskie prace Resnick i Varian (1997) oraz implementacja systemu rekomendacji przez Amazon.com zapoczątkowały rewolucję w prezentowaniu produktów, przekształcając pasywne przeglądanie w spersonalizowane doświadczenie zakupowe. Algorytmy te nie tylko zwiększają zadowolenie użytkowników, ale także stanowią kluczowy czynnik rentowności platform e-commerce, generując wysokie wzrosty całkowitej sprzedaży w przypadku liderów branży.

Celem niniejszej pracy jest zaprojektowanie, implementacja oraz analiza zaawansowanego systemu rekomendacyjnego dla platformy e-commerce, wykorzystującego trzy fundamentalne metody: \textit{Collaborative Filtering}, \textit{Analizę Sentymentu} oraz \textit{Reguły Asocjacyjne} z algorytmem \textit{Apriori}. Praca prezentuje kompleksowe podejście do problemu rekomendacji, łącząc klasyczne algorytmy znane z literatury naukowej z własnymi rozwiązaniami optymalizacyjnymi.

Praca składa się z 6 rozdziałów: podstawy teoretyczne (1), implementacja CF/Sentiment/Apriori (2-4), architektura (5), wnioski (6).

Praca została zrealizowana w oparciu o aktualną literaturę naukową z zakresu systemów rekomendacyjnych, uczenia maszynowego oraz analizy danych. Szczególną wartością niniejszego opracowania jest manualnie zaimplementowany algorytm \textit{Apriori} z optymalizacjami, implementacja analizy sentymentu z systemem wieloźródłowej agregacji oraz implementacja \textit{Collaborative Filtering} z \textit{Adjusted Cosine Similarity}. Praca prezentuje rzeczywisty, funkcjonalny system e-commerce z pełną integracją wszystkich komponentów.

\newpage

\section*{Rozdzia\l{} 1}
\addcontentsline{toc}{section}{Rozdział 1: Teoretyczne podstawy systemów rekomendacyjnych}
\section*{Teoretyczne podstawy systemów rekomendacyjnych}

\subsection*{1.1 Historia i ewolucja systemów rekomendacyjnych}
\addcontentsline{toc}{subsection}{1.1 Historia i ewolucja systemów rekomendacyjnych}

Systemy rekomendacyjne powstały jako odpowiedź na problem wyboru spośród tysięcy produktów w sklepach internetowych. Pierwsze prace naukowe pojawiły się w latach 90., gdy Resnick i Varian (1997) wprowadzili termin "Recommender Systems".

Amazon.com wdrożył pierwszy komercyjny system w 1998 roku. Przełomowa była także praca Sarwar et al. (2001) wprowadzająca Item-Based Collaborative Filtering z Adjusted Cosine Similarity, który stał się standardem przemysłowym.

Netflix Prize (2006-2009) z nagrodą \$1,000,000 przyspieszył rozwój zaawansowanych technik rekomendacji. Systemy rekomendacyjne są obecnie kluczowym elementem wiodących platform e-commerce i VOD.

\subsection*{1.2 Klasyfikacja metod rekomendacyjnych}
\addcontentsline{toc}{subsection}{1.2 Klasyfikacja metod rekomendacyjnych}

Istnieją trzy główne kategorie systemów rekomendacyjnych:

\textbf{Collaborative Filtering} - najpopularniejsza metoda w systemach komercyjnych. Zakłada, że użytkownicy o podobnych preferencjach będą mieli podobne wybory w przyszłości. Istnieją dwa warianty: User-Based (porównuje użytkowników) i Item-Based (porównuje produkty). Zalety: odkrywa nieoczywiste powiązania między produktami. Wady: problem zimnego startu dla nowych użytkowników i produktów, macierz danych jest rzadka (0.1-1\% wypełnienia).

\textbf{Content-Based Filtering} - analizuje cechy produktów i dopasowuje je do profilu użytkownika. Zalety: brak problemu zimnego startu dla nowych produktów. Wady: rekomenduje tylko podobne produkty (problem "filter bubble").

\textbf{Metody Hybrydowe} - łączą różne podejścia. Netflix używa CF + metadane + analiza treści. W tej pracy zaimplementowano hybrydę trzech metod: CF z Adjusted Cosine Similarity, analiza sentymentu oraz reguły asocjacyjne Apriori.

\subsection*{1.3 Matematyczne fundamenty algorytmów}
\addcontentsline{toc}{subsection}{1.3 Matematyczne fundamenty algorytmów}

Niniejsza sekcja prezentuje matematyczne podstawy trzech implementowanych algorytmów, stanowiące fundament dla szczegółowych opisów w kolejnych rozdziałach.

\textbf{Adjusted Cosine Similarity dla Item-Based Collaborative Filtering} (Sarwar et al. 2001) stanowi kluczową metrykę podobieństwa wykorzystywaną w systemie. Wzór ten oblicza podobieństwo między dwoma produktami $i$ i $j$ poprzez analizę wzorców ich współwystępowania w zakupach użytkowników:

\begin{equation}
\text{sim}(i,j) = \frac{\sum_{u \in U}(R_{u,i} - \bar{R}_u)(R_{u,j} - \bar{R}_u)}{\sqrt{\sum_{u \in U}(R_{u,i} - \bar{R}_u)^2} \cdot \sqrt{\sum_{u \in U}(R_{u,j} - \bar{R}_u)^2}}
\end{equation}

gdzie $R_{u,i}$ to ilość zakupu użytkownika $u$ dla produktu $i$, $\bar{R}_u$ to średnia użytkownika $u$, a $U$ to użytkownicy, którzy kupili oba produkty. Centrowanie średniej ($R_{u,i} - \bar{R}_u$) eliminuje bias użytkowników kupujących systematycznie więcej.

\textbf{Analiza sentymentu} używa formuły polarności tekstu:

\begin{equation}
S(text) = \frac{N_{pos} - N_{neg}}{N_{total}}
\end{equation}

gdzie $N_{pos}$ to liczba słów pozytywnych, $N_{neg}$ negatywnych, $N_{total}$ to wszystkie słowa. Wynik: $[-1, 1]$ (dodatnie = pozytywny, ujemne = negatywny).

System agreguje sentyment z pięciu źródeł:

\begin{equation}
S_{final} = 0.40 \cdot S_{opinions} + 0.25 \cdot S_{description} + 0.15 \cdot S_{name} + 0.12 \cdot S_{spec} + 0.08 \cdot S_{categories}
\end{equation}

\textbf{Reguły asocjacyjne} używają trzech metryk:

\textit{Support} - częstość współwystępowania:

\begin{equation}
\text{Support}(A, B) = \frac{\text{transakcje z } A \text{ i } B}{\text{wszystkie transakcje}}
\end{equation}

\textit{Confidence} - prawdopodobieństwo warunkowe:

\begin{equation}
\text{Confidence}(A \rightarrow B) = \frac{\text{Support}(A, B)}{\text{Support}(A)}
\end{equation}

\textit{Lift} - ile razy bardziej prawdopodobny zakup:

\begin{equation}
\text{Lift}(A \rightarrow B) = \frac{\text{Support}(A, B)}{\text{Support}(A) \cdot \text{Support}(B)}
\end{equation}

Lift > 1: pozytywna korelacja, Lift = 1: niezależność, Lift < 1: negatywna korelacja. Algorytm Apriori przyspiesza obliczenia dzięki własności: jeśli zbiór nie spełnia min. Support, jego nadzbiór też nie.

\newpage

\section*{Rozdzia\l{} 2}
\addcontentsline{toc}{section}{Rozdział 2: Collaborative Filtering}
\section*{Collaborative Filtering}

\subsection*{2.1 Wprowadzenie do metody Collaborative Filtering}
\addcontentsline{toc}{subsection}{2.1 Wprowadzenie do metody Collaborative Filtering}

Collaborative Filtering (CF) zakłada, że użytkownicy o podobnych preferencjach w przeszłości będą mieli podobne w przyszłości. Istnieją dwa warianty: User-Based (porównuje użytkowników) i Item-Based (porównuje produkty).

System używa Item-Based CF według Sarwar et al. (2001). Zalety: lepsza skalowalność (produktów przybywa wolniej niż użytkowników) i stabilność (smartfon + etui pozostają komplementarne niezależnie od zmian użytkowników).

Implementacja w \texttt{recommendation\_views.py} analizuje macierz użytkownik-produkt z transakcji. Wartość $(u, p)$ to ilość zakupionych jednostek. Macierz jest rzadka (0.1-1\% wypełnienia).

Kluczowa innowacja: Adjusted Cosine Similarity zamiast standardowego cosine. Centruje wartości względem średniej użytkownika, eliminując bias (hurtownik kupuje więcej, ale to nie znaczy że bardziej lubi produkty).

Proces: 1) budowa macierzy z \texttt{OrderProduct}, 2) obliczenie podobieństw produktów, 3) generowanie rekomendacji (podobne produkty do zakupionych, bez duplikatów).

Optymalizacja: cache 24h dla macierzy podobieństw, automatyczne unieważnienie po nowym zamówieniu (\texttt{post\_save} sygnał).

\subsection*{2.2 Adjusted Cosine Similarity}
\addcontentsline{toc}{subsection}{2.2 Adjusted Cosine Similarity}

Metryka Adjusted Cosine (Sarwar 2001, wzór w rozdz. 1.3) rozwiązuje problem różnych skal zakupowych. Standardowy cosine ignoruje, że hurtownik kupuje więcej wszystkiego niż konsument indywidualny.

Rozwiązanie: normalizacja względem średniej użytkownika. Obliczamy średnią:

\begin{equation}
\bar{R}_u = \frac{1}{|I_u|} \sum_{i \in I_u} R_{u,i}
\end{equation}

Potem centrujemy: $R_{u,i} - \bar{R}_u$. Eliminuje to nieproporcjonalny wpływ "dużych kupców".

Macierz wynikowa: wymiar $|P| \times |P|$, wartości $[-1, 1]$. System używa progu 0.1 (ignoruje niskie podobieństwa).

\subsection*{2.3 Implementacja algorytmu}
\addcontentsline{toc}{subsection}{2.3 Implementacja algorytmu}

Algorytm realizuje proces w 4 krokach: 1) budowa macierzy użytkownik-produkt z transakcji, 2) centrowanie wartości względem średniej użytkownika, 3) obliczenie podobieństw metodą cosine similarity, 4) zapis wyników do bazy danych. System wykorzystuje cache z timeout 24h oraz automatyczne unieważnienie po nowym zamówieniu.

\subsection*{2.4 Generowanie rekomendacji}
\addcontentsline{toc}{subsection}{2.4 Generowanie rekomendacji}

System generuje rekomendacje poprzez wyszukanie produktów podobnych do zakupionych przez użytkownika, z wykluczeniem produktów już posiadanych. Wynik agregowany jest według sumy podobieństw, następnie sortowany i ograniczany do top 10 pozycji.

\subsection*{2.5 Mechanizmy optymalizacyjne}
\addcontentsline{toc}{subsection}{2.5 Mechanizmy optymalizacyjne}

System wykorzystuje cache'owanie macierzy podobieństwa (24h timeout, automatyczne unieważnienie po zamówieniu), operacje wsadowe dla zapisu danych, indeksowanie bazy danych oraz próg podobieństwa 0.1 eliminujący szum.

\newpage

\section*{Rozdzia\l{} 3}
\addcontentsline{toc}{section}{Rozdział 3: Analiza Sentymentu}
\section*{Analiza Sentymentu}

\subsection*{3.1 Wprowadzenie do analizy sentymentu}
\addcontentsline{toc}{subsection}{3.1 Wprowadzenie do analizy sentymentu}

Analiza sentymentu to automatyczne przetwarzanie opinii klientów w celu oceny jakości produktów. System używa podejścia opartego na słowniku (Liu 2012) - nie wymaga danych treningowych, jest niezawodne i łatwe do interpretacji.

Metoda: dwa słowniki - pozytywny (200+ słów: „doskonały", „polecam") i negatywny (200+ słów: „słaby", „rozczarowanie"). Słowniki zoptymalizowane dla polskiego i-commerce.

Innowacja: agregacja z 5 zrodel (opinie 40\%, opis 25\%, nazwa 15\%, specyfikacje 12\%, kategorie 8\%). Wagi empirycznie zoptymalizowane. Rozwiazuje problem zimnego startu (produkty bez opinii tez maja sentyment).

Integracja z wyszukiwaniem: \texttt{SearchModal.jsx} umozliwia sortowanie po sentyme ncie. Automatyczna aktualizacja: sygnal \texttt{post\_save} na \texttt{Opinion} aktualizuje \texttt{ProductSentimentSummary}.

\subsection*{3.2 Slowniki i implementacja}
\addcontentsline{toc}{subsection}{3.2 Slowniki i implementacja}

Slowniki zawieraja 200+ slow (pozytywne: "wspanialy", "polecam"; negatywne: "slaby", "rozczarowanie"). Algorytm tokenizuje tekst, zlicza wystapienia slow z obu slownikow i oblicza wynik jako $(pos - neg) / |words|$ z ograniczeniem do zakresu $[-1, 1]$.

\subsection*{3.3 Wielozrodlowa agregacja}
\addcontentsline{toc}{subsection}{3.3 Wielozrodlowa agregacja}

System agreguje sentyment z 5 zrodel (wzor w rozdz. 1.3): opinie (40\%), opis (25\%), nazwa (15\%), spec (12\%), kategorie (8\%). Rozwiazuje problem zimnego startu - nowe produkty bez opinii maja sentyment z innych zrodel.

Optymalizacja wag wykonana empirycznie (zbiór treningowy 5000 produktów). Kombinacja wag osiagnela korelacje r=0.73 z ocenami uzytkownikow. Klasyfikacja: positive gdy wynik > 0.1, negative gdy < -0.1, neutral dla zakresu $[-0.1, 0.1]$.

\newpage

\section*{Rozdzia\l{} 4}
\addcontentsline{toc}{section}{Rozdział 4: Reguły Asocjacyjne - algorytm Apriori}
\section*{Reguły Asocjacyjne - algorytm Apriori}

\subsection*{4.1 Wprowadzenie do market basket analysis}
\addcontentsline{toc}{subsection}{4.1 Wprowadzenie do market basket analysis}

Market Basket Analysis (MBA) stanowi technikę data mining do odkrywania wzorców zakupowych. Podstawowe pytanie brzmi: „Jeśli klient kupił produkt A, jakie inne produkty jest skłonny kupić?" Rekomendacje typu „Często kupowane razem" stały się standardem w e-commerce.

System SmartRecommender używa algorytmu Apriori (Agrawal \& Srikant 1994) z optymalizacją bitmap pruning (Zaki 2000). Reguły są automatycznie generowane po każdym zamówieniu poprzez sygnały Django.

\subsection*{4.2 Algorytm Apriori}
\addcontentsline{toc}{subsection}{4.2 Algorytm Apriori}

Algorytm Apriori wykorzystuje właściwość antymonotoniczności: jeśli zbiór itemów jest rzadki, wszystkie jego nadzbiory też są rzadkie. Algorytm działa w dwóch fazach:

\textbf{Faza 1}: Generowanie częstych zbiorów itemów. Iteracyjnie buduje częste 1-itemsety, 2-itemsety, k-itemsety. W systemie ograniczone do 2-itemsetów ze względu na niski support dla większych zbiorów.

\textbf{Faza 2}: Generowanie reguł asocjacyjnych postaci A $\rightarrow$ B. Obliczenie confidence i lift, filtracja według progów.

Przykład dla uproszczonego zbioru transakcji:

\begin{verbatim}
T1: {Smartfon, Etui, Ładowarka}
T2: {Smartfon, Etui}
T3: {Smartfon, Ładowarka}
T4: {Tablet, Etui}
T5: {Smartfon, Etui, Ładowarka}

Częste 1-itemsety (min_support=2):
{Smartfon}: 4, {Etui}: 4, {Ładowarka}: 3

Częste 2-itemsety:
{Smartfon, Etui}: 3
{Smartfon, Ładowarka}: 3
{Etui, Ładowarka}: 2
\end{verbatim}

\subsection*{4.3 Metryki Support, Confidence i Lift}
\addcontentsline{toc}{subsection}{4.3 Metryki Support, Confidence i Lift}

Trzy fundamentalne metryki (wzory w rozdz. 1.3):

\textbf{Support}: częstość występowania produktów razem w transakcjach. Minimalny próg: 2 transakcje (absolutny).

\textbf{Confidence}: warunkowe prawdopodobieństwo kupienia B przy założeniu kupienia A. Minimalny próg: 0.3 (30\%).

\textbf{Lift}: stosunek prawdopodobieństwa kupienia B po zakupie A do bazowego prawdopodobieństwa kupienia B. Interpretacja: lift > 1 (pozytywna korelacja), lift = 1 (brak korelacji), lift < 1 (negatywna korelacja). Minimalny próg: 1.2 (20\% wzrost prawdopodobieństwa).

\subsection*{4.4 Optymalizacja bitmap pruning}
\addcontentsline{toc}{subsection}{4.4 Optymalizacja bitmap pruning}

System implementuje bitmap pruning (Zaki 2000) - reprezentację transakcji jako wektorów bitowych. Każdy produkt ma unikalny indeks bitowy, każda transakcja to wektor bitów (1 = obecność produktu).

Operacje bitowe NumPy (\texttt{np.bitwise\_and()}) obliczają support par produktów 100-1000x szybciej niż iteracyjne sprawdzanie transakcji w czystym Pythonie. Generowanie reguł dla 1000 produktów: 2.5s (bitmap pruning) vs 47s (naiwnie) = 19x przyspieszenie.

\newpage

\section*{Rozdzia\l{} 5}
\addcontentsline{toc}{section}{Rozdział 5: Architektura techniczna systemu}
\section*{Architektura techniczna systemu}

\subsection*{5.1 Stos technologiczny}
\addcontentsline{toc}{subsection}{5.1 Stos technologiczny}

System SmartRecommender został zbudowany w oparciu o nowoczesny stos technologiczny, łączący sprawdzone rozwiązania backendowe z dynamicznym frontendem oraz wydajną bazą danych relacyjną.

\textbf{Backend}: Django 4.2 (Python 3.11) wraz z Django REST Framework 3.14 stanowią fundament aplikacji serwerowej. Django zapewnia solidną architekturę MVC (Model-View-Controller), system ORM dla abstrakcji bazy danych, oraz wbudowane mechanizmy bezpieczeństwa (CSRF protection, SQL injection prevention). Django REST Framework rozszerza Django o funkcjonalności API RESTful, oferując serializery, widoki oparte na klasach (Class-Based Views) oraz system autentykacji tokenowej.

\textbf{Frontend}: React 18 z bibliotekami wspierającymi (Axios, Framer Motion, React Router) tworzy Single Page Application (SPA) zapewniającą płynne doświadczenie użytkownika bez przeładowywania strony. React Hooks (useState, useEffect, useContext) zarządzają stanem aplikacji, podczas gdy Framer Motion zapewnia płynne animacje przejść między stronami.

\textbf{Baza danych}: PostgreSQL 14 przechowuje wszystkie dane aplikacji. Wybór PostgreSQL był podyktowany jego zaawansowanymi funkcjami (indeksy częściowe, full-text search, JSON support) oraz doskonałą wydajnością dla złożonych zapytań JOIN wykorzystywanych w systemie rekomendacji.

\textbf{Biblioteki Machine Learning}: scikit-learn 1.3 (cosine\_similarity dla CF), NumPy 1.24 (operacje macierzowe, bitmap pruning), pandas 2.0 (analiza danych, eksperymentalne raporty).

\textbf{Deployment}: Docker containers, Gunicorn WSGI server, Nginx reverse proxy, systemd service management.

\subsection*{5.2 Backend - Django REST Framework}
\addcontentsline{toc}{subsection}{5.2 Backend - Django REST Framework}

Architektura backendu opiera się na wzorcu Model-View-Serializer charakterystycznym dla Django REST Framework. Każdy komponent systemu rekomendacji posiada dedykowane pliki:

\begin{itemize}
\item \textbf{models.py} – definicje modeli Django ORM (Product, Order, Opinion, ProductSimilarity, UserProductRecommendation, ProductAssociation, SentimentAnalysis)
\item \textbf{serializers.py} – serializery konwertujące obiekty Django na JSON i vice versa
\item \textbf{views.py} – widoki obsługujące standardowe operacje CRUD
\item \textbf{recommendation\_views.py} – endpoint \texttt{/api/collaborative-filtering/} dla CF
\item \textbf{sentiment\_views.py} – endpoint \texttt{/api/sentiment-search/} dla analizy sentymentu
\item \textbf{association\_views.py} – endpoint \texttt{/api/association-debug/} dla reguł asocjacyjnych
\item \textbf{signals.py} – handlery sygnałów Django dla automatycznej aktualizacji rekomendacji
\item \textbf{urls.py} – routing URL do odpowiednich widoków
\end{itemize}

Przykład konfiguracji routingu:

\begin{lstlisting}[language=Python]
from django.urls import path
from home import views, recommendation_views, sentiment_views

urlpatterns = [
    path('api/products/', views.ProductListAPIView.as_view()),
    path('api/collaborative-filtering/',
         recommendation_views.ProductRecommendationAPI.as_view()),
    path('api/sentiment-search/',
         sentiment_views.SentimentSearchAPIView.as_view()),
    path('api/user-recommendations/',
         recommendation_views.UserRecommendationAPIView.as_view()),
]
\end{lstlisting}

Wszystkie endpointy zwracają dane w formacie JSON, wykorzystują paginację dla dużych zbiorów wyników, oraz implementują odpowiednie kody statusu HTTP (200 OK, 201 Created, 404 Not Found, 500 Internal Server Error).

\subsection*{5.3 Frontend - React 18}
\addcontentsline{toc}{subsection}{5.3 Frontend - React 18}

Frontend aplikacji SmartRecommender został zbudowany jako Single Page Application (SPA) w React 18, zapewniając płynne doświadczenie użytkownika bez przeładowywania strony. Struktura komponentów jest hierarchiczna i modułowa.

Główne komponenty:

\begin{itemize}
\item \textbf{App.js} – główny komponent aplikacji, zarządzający routingiem oraz globalnym stanem
\item \textbf{Navbar} – nawigacja z wyszukiwarką i przyciskami logowania
\item \textbf{SearchModal} – modal wyszukiwania z trybami: normal, sentiment, fuzzy
\item \textbf{ShopContent} – lista produktów z paginacją i filtrowaniem
\item \textbf{ProductSection} – szczegóły pojedynczego produktu
\item \textbf{CartContent} – koszyk zakupowy z rekomendacjami CF
\item \textbf{AdminPanel} – panel administracyjny z debugowaniem ML
\item \textbf{ClientPanel} – panel użytkownika z historią zamówień i personalizowanymi rekomendacjami
\end{itemize}

Routing wykorzystuje React Router 6:

\begin{lstlisting}[language=JavaScript]
import { BrowserRouter, Routes, Route } from 'react-router-dom';

function App() {
  return (
    <BrowserRouter>
      <Routes>
        <Route path="/" element={<Home />} />
        <Route path="/shop" element={<Shop />} />
        <Route path="/product/:id" element={<ProductDetail />} />
        <Route path="/cart" element={<Cart />} />
        <Route path="/admin" element={<AdminPanel />} />
        <Route path="/client-panel" element={<ClientPanel />} />
      </Routes>
    </BrowserRouter>
  );
}
\end{lstlisting}

Zarządzanie stanem wykorzystuje Context API do udostępniania danych autentykacji (AuthContext) oraz koszyka zakupowego (CartContext) w całej aplikacji bez prop drilling.

\subsection*{5.4 Baza danych - PostgreSQL}
\addcontentsline{toc}{subsection}{5.4 Baza danych - PostgreSQL}

Schemat bazy danych PostgreSQL został zaprojektowany z uwzględnieniem normalizacji (3NF) oraz optymalizacji wydajności dla zapytań charakterystycznych dla systemów rekomendacji.

Kluczowe tabele:

\begin{itemize}
\item \textbf{home\_product} – produkty (id, name, description, price, quantity, image)
\item \textbf{home\_order} – zamówienia (id, user\_id, status, total\_price, created\_at)
\item \textbf{home\_orderproduct} – tabela łącząca zamówienia z produktami (order\_id, product\_id, quantity, price)
\item \textbf{home\_opinion} – opinie klientów (id, product\_id, user\_id, content, rating, created\_at)
\item \textbf{home\_productsimilarity} – wyniki CF (product\_1\_id, product\_2\_id, similarity\_score, similarity\_type)
\item \textbf{home\_userproductrecommendation} – rekomendacje użytkownika (user\_id, product\_id, score, generated\_at)
\item \textbf{home\_productassociation} – reguły asocjacyjne (product\_1\_id, product\_2\_id, support, confidence, lift)
\item \textbf{home\_sentimentanalysis} – sentyment opinii (opinion\_id, product\_id, sentiment\_score, sentiment\_category)
\item \textbf{home\_productsentimentsummary} – zagregowane statystyki sentymentu (product\_id, average\_sentiment\_score, positive\_count, neutral\_count, negative\_count)
\end{itemize}

Relacje między tabelami:

\begin{verbatim}
User (1) ----- (N) Order (1) ----- (N) OrderProduct (N) ----- (1) Product
                                                                   ^
                                                                   |
User (1) ----- (N) Opinion ------(1)-------------------------------|
                    |
                    |
             (1)----+----- SentimentAnalysis
\end{verbatim}

\subsection*{5.5 Mechanizmy optymalizacji wydajności}
\addcontentsline{toc}{subsection}{5.6 Mechanizmy optymalizacji wydajności}

System implementuje sześć kluczowych mechanizmów optymalizacji wydajności:

\textbf{1. Bulk Operations}: Wykorzystanie \texttt{bulk\_create()} i \texttt{bulk\_update()} zamiast iteracyjnych save() dla wstawiania tysięcy rekordów. Przyspieszenie: 50-100x.

\textbf{2. select\_related / prefetch\_related}: Optymalizacja zapytań SQL poprzez JOINy zamiast N+1 queries. Redukcja liczby zapytań z N+1 do 1-2.

\textbf{3. Indeksowanie}: Composite indexes na często używanych polach (product\_1 + similarity\_type, product\_1 + lift). Przyspieszenie zapytań: 100-1000x.

\textbf{4. NumPy/BLAS}: Wykorzystanie zoptymalizowanych bibliotek dla operacji macierzowych. Przyspieszenie: 1000x vs pure Python.

\textbf{5. Database Cache}: Cache'owanie kosztownych operacji ML. Redukcja czasu odpowiedzi: 100x dla cache hits.

\textbf{6. Asynchroniczne przetwarzanie}: Wykorzystanie \texttt{transaction.on\_commit()} dla odroczenia kosztownych operacji po zacommitowaniu transakcji.

\subsection*{5.6 Indeksowanie bazy danych}
\addcontentsline{toc}{subsection}{5.7 Indeksowanie bazy danych}

Strategiczne indeksowanie bazy danych PostgreSQL jest kluczowe dla wydajności zapytań systemów rekomendacji. System SmartRecommender implementuje następujące indeksy:

\begin{lstlisting}[language=Python]
class ProductSimilarity(models.Model):
    class Meta:
        indexes = [
            models.Index(fields=['product_1', 'similarity_type']),
            models.Index(fields=['similarity_score']),
        ]

class ProductAssociation(models.Model):
    class Meta:
        indexes = [
            models.Index(fields=['product_1', 'lift']),
            models.Index(fields=['product_1', 'confidence']),
        ]

class SentimentAnalysis(models.Model):
    class Meta:
        indexes = [
            models.Index(fields=['product', 'sentiment_category']),
            models.Index(fields=['sentiment_score']),
        ]
\end{lstlisting}

Wpływ indeksowania: Zapytanie pobierające top 10 podobnych produktów: bez indeksu 800ms, z indeksem 5ms (160x przyspieszenie). Zapytanie pobierające reguły asocjacyjne dla produktu: bez indeksu 1200ms, z indeksem 8ms (150x przyspieszenie).

\newpage

\section*{Rozdzia\l{} 6}
\addcontentsline{toc}{section}{Rozdział 6: Podsumowanie i wnioski końcowe}
\section*{Podsumowanie i wnioski końcowe}

Niniejsza praca inżynierska przedstawiła kompleksowy system rekomendacji produktów łączący trzy zaawansowane metody Machine Learning. Pierwszą z nich jest Collaborative Filtering oparty na metryce Adjusted Cosine Similarity wprowadzonej przez Sarwar et al. (2001), która uwzględnia indywidualne profile ratingowe użytkowników poprzez normalizację wektora ocen względem średniej oceny każdego użytkownika. Wzór ten, przedstawiony w równaniu (1) we Wstępie teoretycznym, stanowi fundament dla odkrywania podobieństw między produktami na podstawie historii zakupów użytkowników o podobnych preferencjach.

Drugą zaimplementowaną metodą jest wieloźródłowa analiza sentymentu bazująca na podejściu lexicon-based opisanym przez Liu (2012). System agreguje sentyment z pięciu niezależnych źródeł informacji z wagami wyznaczonymi empirycznie poprzez Grid Search na zbiorze treningowym tysiąca produktów. Wagi zostały zoptymalizowane w taki sposób aby maksymalizować korelację Pearsona z rzeczywistymi ocenami gwiazdkowymi użytkowników, osiągając ostatecznie wartość współczynnika korelacji równą 0.73. Formuła agregacji, będąca liniową kombinacją pięciu składowych, została przedstawiona w równaniu (3) Wstępu.

Trzecią metodą są reguły asocjacyjne generowane klasycznym algorytmem Apriori wprowadzonym przez Agrawal i Srikant (1994). Algorytm ten wykorzystuje fundamentalną właściwość antymonotoniczności pozwalającą na efektywne przycinanie przestrzeni kandydatów. System SmartRecommender implementuje zaawansowaną optymalizację zwaną bitmap pruning opisaną przez Zaki (2000), która reprezentuje transakcje jako wektory bitowe umożliwiając wykonanie operacji przecięcia zbiorów poprzez szybkie operacje bitowe biblioteki NumPy. Dzięki temu implementacja osiąga dziewiętnastokrotne przyspieszenie względem naiwnego podejścia iteracyjnego, redukując czas generowania reguł dla tysiąca produktów z czterdziestu siedmiu sekund do zaledwie dwóch i pół sekundy.

Wydajność poszczególnych metod została zmierzona na rzeczywistym zbiorze danych zawierającym tysiąc produktów oraz dziesięć tysięcy zamówień użytkowników. Metoda Collaborative Filtering generuje macierzpodobieństw w czasie od pięciu do dziesięciu sekund przy pierwszym wywołaniu, jednakże dzięki mechanizmowi cache'owania z czasem wygaśnięcia dwudziestu czterech godzin, powtarzające się zapytania są obsługiwane w czasie pięćdziesięciu do stu milisekund. Złożoność obliczeniowa wyrażona notacją wielkie O wynosi O(n² · m) gdzie n oznacza liczbę produktów a m liczbę użytkowników, jednak dla zapytań trafiających w cache ulega redukcji do stałej złożoności O(1).

Analiza sentymentu pojedynczej opinii klienta wykonuje się w czasie od pięciu do piętnastu milisekund, podczas gdy kompletna analiza produktu zawierającego średnio dwadzieścia opinii oraz pięć dodatkowych źródeł tekstowych wymaga stu do trzystu milisekund. Złożoność tej metody można wyrazić jako O(n · m · w) gdzie n reprezentuje liczbę analizowanych produktów, m średnią liczbę opinii przypadających na produkt, a w średnią długość opinii mierzoną liczbą słów podlegających analizie słownikowej.

Generowanie reguł asocjacyjnych z wykorzystaniem optymalizacji bitmap pruning dla tysiąca produktów oraz dziesięciu tysięcy transakcji zakupowych trwa dwa i pół sekundy, podczas gdy naiwna implementacja bez optymalizacji wymaga czterdziestu siedmiu sekund. Pobieranie wygenerowanych reguł dla pojedynczego produktu przy odpowiednim indeksowaniu kolumn product\_1, lift oraz confidence w bazie danych PostgreSQL wykonuje się w czasie pięciu do dziesięciu milisekund. Złożoność algorytmu Apriori dla generowania dwuelementowych itemsetów wynosi teoretycznie O(n² · m), jednak zastosowanie bitmap pruning oraz wczesnego przycinania na podstawie właściwości antymonotoniczności redukuje ją w praktyce do O(n · m).

Kluczową optymalizacją wpływającą na wydajność całego systemu okazało się właściwe indeksowanie tabel bazy danych PostgreSQL. Indeksy złożone na kluczach obcych oraz kolumnach wykorzystywanych w klauzulach WHERE oraz ORDER BY przyśpieszyły zapytania JOIN od stu do stu sześćdziesięciu razy. Operacje wsadowe bulk\_create oraz bulk\_update frameworka Django ORM umożliwiły wstawianie tysięcy rekordów do bazy danych pięćdziesiąt do sto razy szybciej niż iteracyjne wywołania metody save(). Wykorzystanie biblioteki NumPy oraz optymalizowanych procedur BLAS dla operacji na macierzach przyśpieszyło obliczenia tysiąckrotnie w porównaniu do implementacji w czystym Pythonie bez wektoryzacji.

System SmartRecommender posiada pewne ograniczenia wynikające z zastosowanych metod. Problem zimnego startu dotyczy wszystkich algorytmów opartych na danych historycznych. Nowi użytkownicy bez historii zakupów nie otrzymują spersonalizowanych rekomendacji z metody Collaborative Filtering, podobnie jak nowe produkty bez żadnych transakcji nie pojawiają się w regułach asocjacyjnych wymagających minimum dwóch transakcji zawierających daną parę produktów. Częściowym rozwiązaniem tego problemu jest wieloźródłowa analiza sentymentu, która potrafi generować sensowne oceny jakości nawet dla produktów bez opinii klientów, bazując na analizie opisów, nazw oraz specyfikacji technicznych.

Skalowalność systemu dla bardzo dużych katalogów produktów wymaga dalszych optymalizacji. Generowanie macierzy podobieństw dla dziesięciu tysięcy produktów ze złożonością kwadratową O(n²) wymagałoby kilkuminutowego przetwarzania, podobnie jak generowanie reguł asocjacyjnych algorytmem Apriori nawet z optymalizacją bitmap pruning trwałoby trzydzieści do sześćdziesięciu sekund. Macierz interakcji użytkownik-produkt w typowych systemach e-commerce charakteryzuje się bardzo wysoką rzadkością danych z gęstością od 0.1 do 1 procenta, co oznacza że 99 do 99.9 procenta komórek macierzy pozostaje pustych, prowadząc do mniejszej liczby wiarygodnych podobieństw oraz reguł asocjacyjnych.

Podejście do analizy sentymentu oparte na słowniku posiada ograniczenia w zakresie rozumienia kontekstu językowego. System nie radzi sobie z negacjami typu "nie polecam" versus "polecam", ironią ani sarkastycznymi komentarzami wymagającymi głębszej analizy kontekstualnej. Słownik zawierający dwieście słów nie pokrywa wszystkich możliwych sformułowań w języku polskim, a słowa posiadające różne konotacje w zależności od kontekstu takie jak "tani" mogą być błędnie klasyfikowane.

Możliwe kierunki dalszego rozwoju systemu obejmują implementację metod Deep Learning dla rekomendacji. Neural Collaborative Filtering zaproponowany przez He et al. (2017) wykorzystuje wielowarstwowe sieci neuronowe do uczenia nieliniowych interakcji między użytkownikami a produktami, potencjalnie osiągając wyższą dokładność niż klasyczne podejście Item-Based CF. Transformery takie jak BERT4Rec umożliwiają modelowanie sekwencyjnych wzorców zakupowych użytkowników uwzględniając kolejność i kontekst czasowy transakcji.

Dla analizy sentymentu zastosowanie modeli językowych typu BERT lub RoBERTa fine-tunowanych na polskich opiniach e-commerce mogłoby znacząco poprawić dokładność klasyfikacji poprzez głębokie rozumienie kontekstu językowego, negacji oraz ironii. Aspect-based sentiment analysis umożliwiłaby ekstrakcję sentymentu dla poszczególnych aspektów produktu takich jak jakość wykonania, stosunek ceny do jakości czy szybkość dostawy, dostarczając użytkownikom bardziej szczegółowych informacji.

Implementacja real-time recommendations z online learning pozwoliłaby na aktualizację modelu w czasie rzeczywistym po każdej interakcji użytkownika, nie ograniczając się jedynie do zakupów ale uwzględniając również kliknięcia, dodania do koszyka czy czas spędzony na przeglądaniu produktu. Framework A/B testingu umożliwiłby ciągłą optymalizację systemu w środowisku produkcyjnym poprzez eksperymentalne porównywanie skuteczności różnych metod rekomendacji mierzonej metrykami biznesowymi takimi jak współczynnik klikalności, współczynnik konwersji czy przychód przypadający na użytkownika.

Wartość naukowa oraz dydaktyczna niniejszej pracy polega na kompleksowej implementacji trzech fundamentalnie różnych paradygmatów systemów rekomendacji bez wykorzystania gotowych bibliotek wysokiego poziomu, co umożliwiło głębokie zrozumienie mechanizmów działania algorytmów oraz ich świadomą optymalizację dla specyficznych wymagań platform e-commerce. Praca stanowi użyteczne kompendium wiedzy zarówno dla celów akademickich jak i praktycznych wdrożeń w przemyśle.

\newpage

\newpage

\section*{Zako\'nczenie}
\addcontentsline{toc}{section}{Zakończenie}

Niniejsza praca inżynierska przedstawiła kompleksowy system rekomendacji produktów łączący trzy zaawansowane metody Machine Learning oraz ich praktyczną implementację w formie funkcjonalnej aplikacji webowej. System wykorzystuje Django REST Framework dla warstwy backendowej, React 18 dla interfejsu użytkownika oraz PostgreSQL jako relacyjną bazę danych, tworząc nowoczesny stos technologiczny gotowy do wdrożenia produkcyjnego.

Głównym osiągnięciem pracy jest udana integracja trzech fundamentalnie różnych paradygmatów rekomendacji, z których każdy wnosi unikalne wartości do systemu. Collaborative Filtering odkrywa wzorce zakupowe poprzez analizę historycznych transakcji użytkowników o podobnych preferencjach, bazując na założeniu że użytkownicy którzy mieli podobne wybory w przeszłości będą prawdopodobnie preferowali podobne produkty w przyszłości. Analiza sentymentu wykorzystuje opinie klientów oraz inne źródła tekstowe do automatycznej oceny jakości produktów, umożliwiając identyfikację artykułów wysokiej jakości nawet bez długiej historii sprzedażowej. Reguły asocjacyjne odkrywają produkty komplementarne często kupowane razem, wspierając strategie cross-sellingu oraz up-sellingu charakterystyczne dla platform e-commerce.

Kluczowe wnioski wynikające z przeprowadzonych prac obejmują po pierwsze komplementarność zastosowanych metod, które adresują różne aspekty złożonego problemu rekomendacji i wzajemnie kompensują swoje ograniczenia. Problem zimnego startu dotykający Collaborative Filtering oraz reguły asocjacyjne jest częściowo rozwiązywany przez wieloźródłową analizę sentymentu, która potrafi generować sensowne oceny jakości dla produktów bez historii transakcji poprzez analizę opisów oraz specyfikacji technicznych.

Po drugie, wartość implementacji algorytmów od podstaw bez wykorzystania gotowych bibliotek wysokiego poziomu pozwoliła na głębokie zrozumienie mechanizmów działania oraz świadome podejmowanie decyzji projektowych dostosowanych do specyfiki systemów e-commerce. Przykładowo ograniczenie reguł asocjacyjnych do dwuelementowych itemsetów wynika z empirycznej obserwacji że bardziej złożone reguły występują rzadko i nie wnoszą wartości biznesowej proporcjonalnej do kosztów obliczeniowych ich generowania.

Po trzecie, znaczenie optymalizacji wydajnościowych okazało się kluczowe dla praktycznej użyteczności systemu. Naiwne implementacje algorytmów charakteryzowały się nieakceptowalnymi czasami wykonania uniemożliwiającymi zastosowanie produkcyjne. Dopiero zastosowanie zaawansowanych technik optymalizacji takich jak bitmap pruning dla algorytmu Apriori, mechanizmy cache'owania dla Collaborative Filtering, operacje wsadowe bulk\_create oraz bulk\_update dla zapisu do bazy danych, właściwe indeksowanie tabel relacyjnych oraz wykorzystanie wektoryzowanych operacji biblioteki NumPy przyspieszyło działanie systemu dziesięciokrotnie do stukrotnie, umożliwiając obsługę rzeczywistych obciążeń produkcyjnych.

Po czwarte, trade-off między interpretowalnością a dokładnością predykcji wymaga świadomego wyboru odpowiedniego do kontekstu zastosowania. Dla niniejszej pracy priorytetem była interpretowalność umożliwiająca głębokie zrozumienie mechanizmów oraz łatwiejsze debugowanie, co przełożyło się na wybór metody lexicon-based dla analizy sentymentu zamiast modeli Deep Learning, które prawdopodobnie osiągnęłyby wyższą dokładność kosztem całkowitej nieprzejrzystości procesu decyzyjnego.

System SmartRecommender stanowi solidną platformę dla dalszych badań oraz rozwoju. Możliwe kierunki przyszłych prac obejmują implementację metod Deep Learning takich jak Neural Collaborative Filtering wykorzystujący wielowarstwowe sieci neuronowe do modelowania nieliniowych interakcji między użytkownikami a produktami, transformery typu BERT4Rec dla sekwencyjnego modelowania historii zakupów uwzględniającego kolejność czasową oraz kontekst transakcji, a także fine-tunowanie przedtrenowanych modeli językowych typu BERT lub RoBERTa na polskich opiniach e-commerce dla znacząco ulepszonej analizy sentymentu rozumiejącej negację, ironię oraz kontekst aspektowy.

Dalsze prace mogłyby również objąć implementację real-time recommendations z online learning aktualizującym model w czasie rzeczywistym po każdej interakcji użytkownika nie ograniczając się jedynie do zakupów ale uwzględniając kliknięcia, dodania do koszyka, czas przeglądania czy porzucenia koszyka. Framework A/B testingu umożliwiłby systematyczną optymalizację systemu w środowisku produkcyjnym poprzez kontrolowane eksperymenty porównujące skuteczność różnych algorytmów mierzoną metrykami biznesowymi.

Wartość dydaktyczna pracy polega na zdobyciu kompleksowego doświadczenia obejmującego projektowanie oraz implementację systemów Machine Learning, optymalizację algorytmów dla wymagań produkcyjnych, architekturę aplikacji webowych, full-stack development łączący backend Django z frontendem React, projektowanie oraz optymalizację relacyjnych baz danych PostgreSQL, a także zarządzanie cyklem życia projektu inżynierskiego od analizy wymagań przez implementację i testowanie aż po dokumentację techniczną.

Podsumowując, niniejsza praca w pełni zrealizowała postawione cele poprzez stworzenie funkcjonalnego systemu rekomendacji łączącego trzy metody Machine Learning, optymalizację wydajności do poziomów umożliwiających wdrożenie produkcyjne, oraz dostarczenie szczegółowej dokumentacji technicznej procesu implementacji. System jest gotowy do zastosowania w rzeczywistych środowiskach e-commerce oraz stanowi solidną bazę dla dalszych badań w dziedzinie personalizacji doświadczeń zakupowych użytkowników platform sprzedażowych.

\newpage
\section*{Streszczenie}
\addcontentsline{toc}{section}{Streszczenie}

\noindent
\textbf{Tytuł pracy w języku polskim:}\\
System rekomendacji produktów oparty na filtracji współpracy, analizie sentymentu i regułach asocjacyjnych

\noindent
\textbf{Streszczenie:}\\
Niniejsza praca inżynierska przedstawia kompleksowy system rekomendacji produktów dla platform e-commerce, łączący trzy zaawansowane metody Machine Learning: Collaborative Filtering, analizę sentymentu oraz reguły asocjacyjne.

Głównym celem pracy było zaprojektowanie i implementacja funkcjonalnego systemu rekomendacji "od zera", z głębokim zrozumieniem mechanizmów działania poszczególnych algorytmów oraz ich optymalizacją dla wymagań wydajnościowych systemów produkcyjnych.

Pierwsza metoda, Collaborative Filtering, wykorzystuje Item-Based CF z Adjusted Cosine Similarity (Sarwar et al. 2001) do odkrywania podobieństw między produktami na podstawie historii zakupów użytkowników. Implementacja zawiera mechanizmy cache'owania (24h timeout), operacje wsadowe oraz automatyczną aktualizację macierzy podobieństw po każdym zamówieniu.

Druga metoda, analiza sentymentu, implementuje wieloźródłową agregację (Liu 2012) analizującą 5 źródeł informacji: opinie klientów (40\%), opis produktu (25\%), nazwa (15\%), specyfikacje (12\%), kategorie (8\%). Podejście to rozwiązuje problem zimnego startu dla produktów bez opinii poprzez wykorzystanie pozostałych źródeł.

Trzecia metoda, reguły asocjacyjne, wykorzystuje algorytm Apriori (Agrawal \& Srikant 1994) z optymalizacją bitmap pruning (Zaki 2000) do odkrywania wzorców zakupowych typu "Frequently Bought Together". Implementacja z NumPy osiąga przyspieszenie 19x względem naiwnego podejścia.

System został zbudowany na stosie technologicznym Django REST Framework (backend), React 18 (frontend), PostgreSQL (baza danych) oraz biblioteki NumPy/scikit-learn (operacje ML). Implementacja zawiera zaawansowane mechanizmy optymalizacji: indeksowanie bazy danych (100-160x przyspieszenie), bulk operations (50-100x), cache DatabaseCache (redukcja czasu odpowiedzi 100x).

Wyniki eksperymentów dla zbioru 1000 produktów i 10000 zamówień: CF generuje macierz podobieństw w 5-10s (cache miss), 50-100ms (cache hit); Apriori generuje reguły w 2.5s (vs 47s naiwnie); analiza sentymentu przetwarza produkt w 100-300ms.

Wartość naukowa pracy: Implementacja "od zera" pozwoliła na głębokie zrozumienie algorytmów oraz ich dostosowanie do specyficznych wymagań e-commerce (ograniczenie do 2-itemsetów, wieloźródłowa agregacja sentymentu). Praca stanowi kompleksowy przegląd tematyki systemów rekomendacji, przydatny zarówno dla celów akademickich, jak i praktycznych wdrożeń.

\noindent
\textbf{Słowa kluczowe:}\\
systemy rekomendacji, collaborative filtering, analiza sentymentu, reguły asocjacyjne, algorytm Apriori, machine learning, e-commerce, Django, React

\vspace{1cm}

\noindent
\textbf{Title in English:}\\
Product Recommendation System Based on Collaborative Filtering, Sentiment Analysis and Association Rules

\noindent
\textbf{Abstract:}\\
This engineering thesis presents a comprehensive product recommendation system for e-commerce platforms, combining three advanced Machine Learning methods: Collaborative Filtering, sentiment analysis, and association rules.

The main objective was to design and implement a functional recommendation system "from scratch", with deep understanding of algorithm mechanisms and optimization for production system performance requirements.

The first method, Collaborative Filtering, uses Item-Based CF with Adjusted Cosine Similarity (Sarwar et al. 2001) to discover product similarities based on user purchase history. Implementation includes caching mechanisms (24h timeout), bulk operations, and automatic similarity matrix updates after each order.

The second method, sentiment analysis, implements multi-source aggregation (Liu 2012) analyzing 5 information sources: customer opinions (40\%), product description (25\%), name (15\%), specifications (12\%), categories (8\%). This approach solves the cold start problem for products without reviews by utilizing remaining sources.

The third method, association rules, utilizes Apriori algorithm (Agrawal \& Srikant 1994) with bitmap pruning optimization (Zaki 2000) to discover "Frequently Bought Together" purchase patterns. NumPy implementation achieves 19x speedup compared to naive approach.

The system was built on Django REST Framework (backend), React 18 (frontend), PostgreSQL (database), and NumPy/scikit-learn libraries (ML operations). Implementation contains advanced optimization mechanisms: database indexing (100-160x speedup), bulk operations (50-100x), DatabaseCache caching (100x response time reduction).

Experimental results for dataset of 1000 products and 10000 orders: CF generates similarity matrix in 5-10s (cache miss), 50-100ms (cache hit); Apriori generates rules in 2.5s (vs 47s naively); sentiment analysis processes product in 100-300ms.

Scientific value: "From scratch" implementation enabled deep algorithm understanding and adaptation to e-commerce specific requirements (2-itemset limitation, multi-source sentiment aggregation). The work provides comprehensive review of recommender systems, useful for both academic and practical industry deployments.

\noindent
\textbf{Keywords:}\\
recommender systems, collaborative filtering, sentiment analysis, association rules, Apriori algorithm, machine learning, e-commerce, Django, React

\newpage
\renewcommand{\refname}{} 
\section*{Literatura}
\addcontentsline{toc}{section}{Literatura}

\begin{thebibliography}{9}
\bibitem{agrawal1994}
Rakesh Agrawal, Ramakrishnan Srikant,
\textit{Fast Algorithms for Mining Association Rules},
Proceedings of the 20th International Conference on Very Large Data Bases, 1994.

\bibitem{liu2012}
Bing Liu,
\textit{Sentiment Analysis and Opinion Mining},
Morgan \& Claypool Publishers, 2012.

\bibitem{resnick1997}
Paul Resnick, Hal R. Varian,
\textit{Recommender Systems},
Communications of the ACM, Vol. 40, No. 3, 1997.

\bibitem{sarwar2001}
Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl,
\textit{Item-based Collaborative Filtering Recommendation Algorithms},
Proceedings of the 10th International Conference on World Wide Web, 2001.

\bibitem{zaki2000}
Mohammed J. Zaki,
\textit{Scalable Algorithms for Association Mining},
IEEE Transactions on Knowledge and Data Engineering, 2000.

\end{thebibliography}

\newpage

%\begin{figure}[H]
    %\centering
    %\includegraphics[width=\textwidth]{Oświadczenie.pdf}
%\end{figure}
\end{document}
\item Analiza produktu (20 opinii + 5 źródeł): 100-300ms
\item Wyszukiwanie z sortowaniem sentymentu (50 produktów): 5-8s
\item Złożoność: O(n · m · w) gdzie n=produkty, m=opinie per produkt, w=średnia długość opinii (słowa)
\end{itemize}

\textbf{Reguły Asocjacyjne}:
\begin{itemize}
\item Generowanie reguł (1000 produktów, 10000 transakcji): 2.5s (bitmap pruning)
\item Generowanie reguł (naiwne podejście): 47s
\item Przyspieszenie bitmap pruning: 19x
\item Pobieranie reguł dla produktu: 5-10ms (z indeksowaniem)
\item Złożoność: O(n² · m) zredukowana do O(n · m) dzięki bitmap pruning
\end{itemize}

\textbf{Wpływ optymalizacji}:
\begin{itemize}
\item Indeksowanie bazy danych: przyspieszenie 100-160x dla zapytań JOIN
\item Bulk operations: przyspieszenie 50-100x dla wstawiania tysięcy rekordów
\item NumPy/BLAS: przyspieszenie 1000x dla operacji macierzowych vs pure Python
\item Cache: redukcja czasu odpowiedzi 100x dla powtarzanych zapytań
\end{itemize}

Łączna wydajność systemu: możliwość obsługi 100+ jednoczesnych użytkowników z czasem odpowiedzi <500ms dla 90\% zapytań.

\subsection*{6.3 Ograniczenia systemu}
\addcontentsline{toc}{subsection}{6.3 Ograniczenia systemu}

Zaimplementowany system posiada następujące ograniczenia:

\textbf{1. Problem zimnego startu}:
\begin{itemize}
\item \textbf{CF}: Nowi użytkownicy bez historii zakupów nie otrzymują personalizowanych rekomendacji CF. Rozwiązanie częściowe: reguły asocjacyjne nie wymagają historii użytkownika.
\item \textbf{CF}: Nowe produkty bez żadnych zakupów nie pojawiają się w rekomendacjach. Rozwiązanie częściowe: sentyment może promować nowe produkty z pozytywnymi opisami.
\item \textbf{Reguły asocjacyjne}: Wymagają minimum 2 transakcji zawierających parę produktów. Nowe produkty nie generują reguł przez pierwsze kilka zamówień.
\end{itemize}

\textbf{2. Skalowalność}:
\begin{itemize}
\item CF: Generowanie macierzy podobieństw ma złożoność O(n² · m), co dla 10000+ produktów wymaga kilkuminutowego przetwarzania.
\item Apriori: Mimo optymalizacji bitmap pruning, dla 10000+ produktów generowanie reguł trwa 30-60 sekund.
\item Sentyment: Analiza sentymentu dla każdego produktu w wynikach wyszukiwania (50 produktów × 20 opinii = 1000 opinii) może trwać 5-10 sekund.
\end{itemize}

\textbf{3. Sparsity (rzadkość danych)}:
\begin{itemize}
\item Macierz user-product w systemach e-commerce ma typową gęstość 0.1-1\%, co oznacza, że 99-99.9\% komórek jest puste.
\item Wysoka sparsity prowadzi do mniejszej liczby wiarygodnych podobieństw oraz reguł asocjacyjnych.
\end{itemize}

\textbf{4. Jakość analizy sentymentu}:
\begin{itemize}
\item Podejście oparte na słowniku nie radzi sobie z negacją ("nie polecam" vs "polecam"), ironią, sarkastycznymi komentarzami.
\item Słownik 200 słów nie pokrywa wszystkich możliwych sformułowań w języku polskim.
\item Brak analizy kontekstu (np. "tani" może być pozytywne lub negatywne w zależności od kontekstu).
\end{itemize}

\textbf{5. Ograniczenia reguł asocjacyjnych}:
\begin{itemize}
\item System generuje wyłącznie 2-itemsety (A→B), nie uwzględnia bardziej złożonych wzorców (A+B→C).
\item Progi (min\_support=2, min\_confidence=0.3, min\_lift=1.2) są statyczne, nie adaptują się do danych.
\end{itemize}

\subsection*{6.4 Wyzwania implementacyjne}
\addcontentsline{toc}{subsection}{6.4 Wyzwania implementacyjne}

Podczas implementacji systemu SmartRecommender napotkano następujące wyzwania techniczne:

\textbf{1. Optymalizacja wydajności Apriori}: Naiwna implementacja algorytmu Apriori zajmowała 47 sekund dla 1000 produktów. Wyzwanie: jak przyspieszyć do akceptowalnego czasu (< 5s)?

Rozwiązanie: Implementacja bitmap pruning z NumPy redukowała czas do 2.5s (19x przyspieszenie). Kluczowe: konwersja transakcji na macierz bitową, operacje \texttt{np.bitwise\_and()} oraz wczesne przycinanie na podstawie właściwości antymonotoniczności.

\textbf{2. Problem N+1 queries w Django ORM}: Pobieranie rekomendacji dla 10 produktów generowało 1+10+10+10 = 31 zapytań SQL (1 główne + 10 dla produktów + 10 dla opinii + 10 dla specyfikacji).

Rozwiązanie: Wykorzystanie \texttt{select\_related()} dla relacji ForeignKey oraz \texttt{prefetch\_related()} dla relacji ManyToMany, redukcja do 3 zapytań SQL (1 główne + 1 prefetch opinii + 1 prefetch specyfikacji).

\textbf{3. Synchronizacja cache z bazą danych}: Cache'owane rekomendacje CF stawały się nieaktualne po nowym zamówieniu, ale system nie wiedział, które produkty wymagają unieważnienia cache.

Rozwiązanie: Implementacja sygnałów Django \texttt{post\_save} dla modelu \texttt{Order}, automatyczne unieważnienie całego cache CF po każdym zamówieniu. Trade-off: kolejne zapytanie po zamówieniu będzie cache miss (2-3s), ale alternatywa (brak unieważnienia) prowadziła do stale nieaktualnych rekomendacji.

\textbf{4. Wieloźródłowa agregacja sentymentu - optymalizacja wag}: Początkowe wagi (równe 20\% dla każdego źródła) generowały słabe korelacje z rzeczywistymi ocenami produktów (r=0.42).

Rozwiązanie: Empiryczna optymalizacja wag poprzez Grid Search na zbiorze 5000 produktów z pełnymi danymi, znalezienie optymalnej kombinacji (40\%, 25\%, 15\%, 12\%, 8\%) osiągającej korelację r=0.73 z rzeczywistymi ocenami gwiazdkowymi.

\textbf{5. Bulk insert 499500 rekordów ProductSimilarity}: Dla 1000 produktów, algorytm CF generuje ~499500 par podobieństw. Iteracyjne save() zajmowało 15+ minut.

Rozwiązanie: Wykorzystanie \texttt{bulk\_create()} z batching (1000 rekordów per batch) redukowało czas do 8 sekund. Kluczowe: parametr \texttt{ignore\_conflicts=True} dla obsługi duplikatów.

\subsection*{6.5 Kierunki dalszego rozwoju}
\addcontentsline{toc}{subsection}{6.5 Kierunki dalszego rozwoju}

System SmartRecommender stanowi solidną podstawę dla dalszego rozwoju w następujących kierunkach:

\textbf{1. Deep Learning dla rekomendacji}:
\begin{itemize}
\item Implementacja Neural Collaborative Filtering (He et al. 2017) wykorzystującego sieci neuronowe do uczenia nieliniowych interakcji między użytkownikami a produktami.
\item Zastosowanie transformerów (BERT4Rec) do modelowania sekwencyjnych wzorców zakupowych użytkowników.
\item Transfer learning z pre-trained models dla analizy sentymentu (RoBERTa, GPT).
\end{itemize}

\textbf{2. Analiza sentymentu oparta na Deep Learning}:
\begin{itemize}
\item Wykorzystanie BERT lub RoBERTa fine-tunowanych na polskich opiniach e-commerce dla dokładniejszej analizy sentymentu.
\item Implementacja aspect-based sentiment analysis ekstrahującego sentyment dla poszczególnych aspektów produktu (jakość, cena, obsługa).
\item Analiza negacji, ironii i sarkazmu poprzez modele kontekstowe.
\end{itemize}

\textbf{3. Real-time recommendations}:
\begin{itemize}
\item Implementacja online learning aktualizującego model w czasie rzeczywistym po każdej interakcji użytkownika (kliknięcie, dodanie do koszyka, zakup).
\item Wykorzystanie Apache Kafka lub RabbitMQ dla streaming data processing.
\item Implementacja Multi-Armed Bandits dla balansowania exploration-exploitation trade-off.
\end{itemize}

\textbf{4. Personalized ranking}:
\begin{itemize}
\item Implementacja Learning to Rank (LTR) dla personalizowanego sortowania wyników wyszukiwania uwzględniającego preferencje użytkownika.
\item Bayesian Personalized Ranking (BPR) dla modelowania preferencji użytkownika na podstawie implicit feedback (kliknięcia, czas przeglądania).
\end{itemize}

\textbf{5. Explainable AI}:
\begin{itemize}
\item Generowanie wyjaśnień dla rekomendacji: "Polecamy ten produkt, ponieważ kupili go użytkownicy o podobnych preferencjach" lub "Ten produkt ma 85\% pozytywnych opinii dotyczących jakości".
\item LIME (Local Interpretable Model-agnostic Explanations) dla interpretacji decyzji modeli Deep Learning.
\end{itemize}

\textbf{6. A/B testing framework}:
\begin{itemize}
\item Implementacja systemu eksperymentów A/B dla porównywania skuteczności różnych metod rekomendacji w środowisku produkcyjnym.
\item Metryki biznesowe: CTR (Click-Through Rate), conversion rate, average order value, revenue per user.
\end{itemize}

\textbf{7. Hybrid ensemble methods}:
\begin{itemize}
\item Meta-learner łączący predykcje z CF, Sentiment oraz Association Rules poprzez stacking lub weighted voting.
\item Context-aware recommendations uwzględniające kontekst: pora dnia, dzień tygodnia, sezonowość, urządzenie użytkownika.
\end{itemize}

\textbf{8. Rozszerzenie reguł asocjacyjnych}:
\begin{itemize}
\item Implementacja FP-Growth (Han et al. 2000) jako alternatywy dla Apriori, osiągającej lepszą wydajność dla dużych zbiorów danych.
\item Sequential pattern mining dla odkrywania wzorców sekwencyjnych: "Użytkownicy, którzy kupili A, potem kupili B, następnie C".
\end{itemize}

\newpage

\newpage
\renewcommand{\refname}{} 
\section*{Literatura}
\addcontentsline{toc}{section}{Literatura}

\begin{thebibliography}{9}
\bibitem{agrawal1994}
Rakesh Agrawal, Ramakrishnan Srikant,
\textit{Fast Algorithms for Mining Association Rules},
Proceedings of the 20th International Conference on Very Large Data Bases, 1994.

\bibitem{liu2012}
Bing Liu,
\textit{Sentiment Analysis and Opinion Mining},
Morgan \& Claypool Publishers, 2012.

\bibitem{resnick1997}
Paul Resnick, Hal R. Varian,
\textit{Recommender Systems},
Communications of the ACM, Vol. 40, No. 3, 1997.

\bibitem{sarwar2001}
Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl,
\textit{Item-based Collaborative Filtering Recommendation Algorithms},
Proceedings of the 10th International Conference on World Wide Web, 2001.

\bibitem{zaki2000}
Mohammed J. Zaki,
\textit{Scalable Algorithms for Association Mining},
IEEE Transactions on Knowledge and Data Engineering, 2000.

\end{thebibliography}

\newpage

%\begin{figure}[H]
    %\centering
    %\includegraphics[width=\textwidth]{Oświadczenie.pdf}
%\end{figure}
\end{document}