\documentclass[a4paper,12pt,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amsmath, amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{url}
\usepackage{titlesec}
\usepackage{tocloft}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{xcolor}

% Marginesy zgodnie z wytycznymi
\geometry{left=3.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% Numeracja stron u dołu, wyrównana do zewnętrznego marginesu
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[LE,RO]{\thepage}
\renewcommand{\headrulewidth}{0pt}

% Interlinia 1,5
\onehalfspacing

% Wcięcia akapitów
\setlength{\parindent}{1cm}

% Tytuły - czcionka pogrubiona
\titleformat{\section}[block]{\bfseries\Large\raggedright}{}{1em}{}
\titleformat{\subsection}[block]{\bfseries\large\raggedright}{}{1em}{}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red}
}

\begin{document}

\begin{titlepage}

\begin{minipage}{0.7\textwidth}
    {\large\bf UNIWERSYTET RZESZOWSKI}\\
    {\large\bf Wydział Nauk Ścisłych i Technicznych}
\end{minipage}
\hfill
\begin{minipage}{0.25\textwidth}
    \centering
    \includegraphics[width=8em]{logoUR.jpg}
\end{minipage}


\vspace{3cm}

\begin{center}
    {\Large Dawid Olko} \\
    {\large nr albumu: 125148} \\
    {\large Kierunek: Informatyka}
\end{center}

\vspace{2cm}

\begin{center}
    {\LARGE\bf System rekomendacji produktów oparty na filtracji współpracy, analizie sentymentu i regułach asocjacyjnych}
\end{center}

\vspace{1.5cm}

\begin{center}
    {\large Praca inżynierska}
\end{center}

\vspace{1.5cm}

\begin{flushright}
    {\large Praca wykonana pod kierunkiem}\\
    {\large dr inż. Piotra Grochowalskiego}
\end{flushright}

\vspace{3cm}

\begin{center}
    {\large Rzesz\'ow, 2026}
\end{center}

\end{titlepage}

% Spis treści
\tableofcontents
\newpage


\section*{Wstęp}
\addcontentsline{toc}{section}{Wstęp}

\subsection*{Motywacja i kontekst problemu}

Nowoczesne platformy e-commerce oferują tysiące lub dziesiątki tysięcy produktów. Klient szukający smartfona ma do wyboru setki modeli, laptop — podobnie. Bez wsparcia narzędzi rekomendacyjnych użytkownik spędza długie minuty na przeglądaniu oferty, często rezygnując z zakupu z powodu przeładowania informacją. Sklepy tracą potencjalnych klientów, a Ci którzy kupują — mogą przegapić produkty idealnie dopasowane do ich potrzeb.

Systemy rekomendacyjne rozwiązują ten problem. Analizują historię zakupów, opinie i zachowania użytkowników, aby automatycznie proponować produkty o największej wartości dla konkretnego klienta. Według badań McKinsey \& Company (2013), systemy rekomendacyjne odpowiadają za 35\% przychodów Amazon i 75\% oglądanej zawartości Netflix. Greg Linden, były inżynier Amazon, potwierdza w swoim blogu (2006) że rekomendacje są kluczowym elementem strategii e-commerce Amazon.

\subsection*{Zakres i cel pracy}

W mojej pracy zaimplementowałem trzy metody rekomendacji dla platformy e-commerce:

\textbf{1. Collaborative Filtering (CF)} — metoda Item-Based z Adjusted Cosine Similarity (Sarwar et al. 2001). Znajduje produkty podobne do już zakupionych przez użytkownika, bazując na wzorcach zakupowych innych klientów o podobnych preferencjach. Algorytm analizuje macierz zakupów użytkownik-produkt i oblicza podobieństwa między produktami używając centrowania średniej (mean-centering) dla eliminacji biasu.

\textbf{2. Analiza sentymentu} — metoda słownikowa (Liu 2012) agregująca sentyment z pięciu źródeł tekstowych: opinie klientów (40\%), opis produktu (25\%), nazwa (15\%), specyfikacje (12\%), kategorie (8\%). Wagi zoptymalizowano Grid Search osiągając korelację r=0.73 z ocenami użytkowników. Metoda ocenia jakość produktu automatycznie, rozwiązując problem zimnego startu dla produktów bez opinii.

\textbf{3. Reguły asocjacyjne (Apriori)} — algorytm Agrawal \& Srikant (1994) z optymalizacją bitmap pruning (Zaki 2000) odkrywający produkty często kupowane razem. Implementacja w NumPy osiąga przyspieszenie 19x względem naiwnego podejścia. Wspiera strategie cross-sellingu ("Klienci kupujący X często wybierają także Y").

Podkreślam: tylko te trzy metody są moim autorskim wkładem w projekcie. Nie implementowałem innych technik rekomendacyjnych — praca koncentruje się wyłącznie na CF, analizie sentymentu i Apriori.

\subsection*{Dane i środowisko testowe}

System został przetestowany na rzeczywistych danych z aplikacji e-commerce:

\begin{itemize}
    \item \textbf{500 produktów} — komputery, laptopy, podzespoły, peryferia (48 kategorii)
    \item \textbf{20 użytkowników} — 5 administratorów + 15 klientów
    \item \textbf{Zamówienia} — każdy użytkownik posiada historię zakupów (dane z seedera)
    \item \textbf{Opinie} — produkty posiadają opinie klientów do analizy sentymentu
    \item \textbf{Stos technologiczny} — Django 4.2, React 18, PostgreSQL 14, NumPy, scikit-learn
\end{itemize}

\subsection*{Cele pracy}

Główne cele zrealizowane w ramach projektu:

\begin{itemize}
    \item \textbf{Architektura}: Zaprojektowanie systemu rekomendacyjnego zintegrowanego z aplikacją e-commerce (backend Django REST, frontend React, baza PostgreSQL).
    \item \textbf{Implementacja}: Napisanie algorytmów CF, sentiment i Apriori od podstaw dla głębokiego zrozumienia mechanizmów.
    \item \textbf{Optymalizacja}: Przyspieszenie algorytmów przez zastosowanie bitmap pruning, cache wielopoziomowego i indeksów PostgreSQL.
    \item \textbf{Ewaluacja}: Pomiar wydajności i jakości rekomendacji na rzeczywistych danych z aplikacji.
    \item \textbf{Dokumentacja}: Przygotowanie diagramów (use case, sekwencje, ERD) i zrzutów interfejsu użytkownika.
\end{itemize}

\subsection*{Struktura pracy}

Praca składa się z sześciu rozdziałów. Rozdział 1 przedstawia podstawy teoretyczne systemów rekomendacyjnych. Rozdziały 2-4 opisują implementację trzech metod: Collaborative Filtering, analizy sentymentu i reguł asocjacyjnych. Rozdział 5 dokumentuje architekturę techniczną (Django backend, React frontend, PostgreSQL). Rozdział 6 zawiera wyniki eksperymentów i analizę wydajności.

\newpage

\section*{Rozdzia\l{} 1}
\addcontentsline{toc}{section}{Rozdział 1: Teoretyczne podstawy systemów rekomendacyjnych}
\section*{Teoretyczne podstawy systemów rekomendacyjnych}

\subsection*{1.1 Historia i ewolucja systemów rekomendacyjnych}
\addcontentsline{toc}{subsection}{1.1 Historia i ewolucja systemów rekomendacyjnych}

\subsection*{1.1 Historia i ewolucja systemów rekomendacyjnych}
\addcontentsline{toc}{subsection}{1.1 Historia i ewolucja systemów rekomendacyjnych}

Systemy rekomendacyjne powstały jako odpowiedź na problem wyboru spośród tysięcy produktów w sklepach internetowych. Pierwsze prace naukowe pojawiły się w latach 90., gdy Resnick i Varian (1997) wprowadzili termin "Recommender Systems" \cite{resnick1997recommender}.

Amazon.com wdrożył pierwszy komercyjny system w 1998 roku \cite{linden2003amazon}. Przełomowa była także praca Sarwar et al. (2001) wprowadzająca Item-Based Collaborative Filtering z Adjusted Cosine Similarity \cite{sarwar2001item}, który stał się standardem przemysłowym.

Netflix Prize (2006-2009) z nagrodą \$1,000,000 przyspieszył rozwój zaawansowanych technik rekomendacji \cite{bennett2007netflix}. Systemy rekomendacyjne są obecnie kluczowym elementem wiodących platform e-commerce i VOD.

\subsection*{1.2 Klasyfikacja metod rekomendacyjnych}
\addcontentsline{toc}{subsection}{1.2 Klasyfikacja metod rekomendacyjnych}

Istnieją trzy główne kategorie systemów rekomendacyjnych:

\textbf{Collaborative Filtering} - najpopularniejsza metoda w systemach komercyjnych. Zakłada, że użytkownicy o podobnych preferencjach będą mieli podobne wybory w przyszłości. Istnieją dwa warianty: User-Based (porównuje użytkowników) i Item-Based (porównuje produkty). Zalety: odkrywa nieoczywiste powiązania między produktami. Wady: problem zimnego startu dla nowych użytkowników i produktów, macierz danych jest rzadka (0.1-1\% wypełnienia).

\textbf{Content-Based Filtering} - analizuje cechy produktów i dopasowuje je do profilu użytkownika. Zalety: brak problemu zimnego startu dla nowych produktów. Wady: rekomenduje tylko podobne produkty (problem "filter bubble").

\textbf{Metody Hybrydowe} - łączą różne podejścia. Netflix używa CF + metadane + analiza treści. W tej pracy zaimplementowano hybrydę trzech metod: CF z Adjusted Cosine Similarity, analiza sentymentu oraz reguły asocjacyjne Apriori.

\subsection*{1.2.1 Terminologia e-commerce w kontekście rekomendacji}
\addcontentsline{toc}{subsection}{1.2.1 Terminologia e-commerce}

Systemy rekomendacyjne w e-commerce wykorzystują różne strategie sprzedażowe. Poniżej znajdują się kluczowe terminy stosowane w branży:

\textbf{Cross-selling} (sprzedaż krzyżowa) — strategia polegająca na proponowaniu produktów komplementarnych, czyli dopełniających zakup główny. Przykład: klient kupuje laptop, system proponuje mysz, torbę na laptop, maty chłodzące. Celem jest zwiększenie wartości koszyka poprzez dodanie produktów powiązanych funkcjonalnie. W aplikacji realizowane przez reguły asocjacyjne (Apriori) — odkrywane są produkty często kupowane razem.

\textbf{Up-selling} (sprzedaż wyższej wartości) — strategia zachęcania klienta do zakupu droższego wariantu produktu lub wersji premium. Przykład: klient przegląda telefon za 2000 zł, system proponuje model za 2500 zł z lepszymi parametrami. Celem jest zwiększenie wartości pojedynczego zakupu. W aplikacji realizowane przez Collaborative Filtering — klienci kupujący podobne produkty często wybierali droższe warianty.

\textbf{Personalizacja} — dostosowanie treści i rekomendacji do indywidualnego profilu użytkownika na podstawie jego historii zakupów, przeglądanych produktów i zachowań. Przykład: dwóch użytkowników widzi różne zestawy produktów na stronie głównej. Celem jest zwiększenie trafności rekomendacji i konwersji. W aplikacji realizowane przez wszystkie trzy metody — CF analizuje historię, sentiment jakość, Apriori powiązania.

\textbf{Cold start problem} (problem zimnego startu) — wyzwanie występujące gdy nowy użytkownik lub produkt nie ma historii interakcji. Przykład: nowy użytkownik nie ma zamówień, więc CF nie może działać. Nowy produkt nie ma opinii, więc trudno ocenić jakość. Rozwiązanie: analiza sentymentu w aplikacji ocenia produkty na podstawie opisu, nazwy i specyfikacji — działa nawet bez opinii.

\textbf{Frequently Bought Together} (często kupowane razem) — rodzaj rekomendacji prezentujący produkty, które klienci regularnie kupują w tym samym koszyku. Przykład: kawa + mleko + cukier. Celem jest uproszczenie procesu zakupów i zwiększenie wartości koszyka. W aplikacji realizowane przez algorytm Apriori — generuje reguły asocjacyjne typu „klient kupił A → proponuj B".

\subsection*{1.3 Matematyczne fundamenty algorytmów}
\addcontentsline{toc}{subsection}{1.3 Matematyczne fundamenty algorytmów}

Niniejsza sekcja prezentuje matematyczne podstawy trzech implementowanych algorytmów, stanowiące fundament dla szczegółowych opisów w kolejnych rozdziałach.

\textbf{Adjusted Cosine Similarity dla Item-Based Collaborative Filtering} (Sarwar et al. 2001) stanowi kluczową metrykę podobieństwa wykorzystywaną w systemie. Wzór ten oblicza podobieństwo między dwoma produktami $i$ i $j$ poprzez analizę wzorców ich współwystępowania w zakupach użytkowników:

\begin{equation}
\text{sim}(i,j) = \frac{\sum_{u \in U}(R_{u,i} - \bar{R}_u)(R_{u,j} - \bar{R}_u)}{\sqrt{\sum_{u \in U}(R_{u,i} - \bar{R}_u)^2} \cdot \sqrt{\sum_{u \in U}(R_{u,j} - \bar{R}_u)^2}}
\end{equation}

gdzie $R_{u,i}$ to ilość zakupu użytkownika $u$ dla produktu $i$, $\bar{R}_u$ to średnia użytkownika $u$, a $U$ to użytkownicy, którzy kupili oba produkty. Centrowanie średniej ($R_{u,i} - \bar{R}_u$) eliminuje bias użytkowników kupujących systematycznie więcej.

\textbf{Analiza sentymentu} używa formuły polarności tekstu:

\begin{equation}
S(text) = \frac{N_{pos} - N_{neg}}{N_{total}}
\end{equation}

gdzie $N_{pos}$ to liczba słów pozytywnych, $N_{neg}$ negatywnych, $N_{total}$ to wszystkie słowa. Wynik: $[-1, 1]$ (dodatnie = pozytywny, ujemne = negatywny).

System agreguje sentyment z pięciu źródeł:

\begin{equation}
S_{final} = 0.40 \cdot S_{opinions} + 0.25 \cdot S_{description} + 0.15 \cdot S_{name} + 0.12 \cdot S_{spec} + 0.08 \cdot S_{categories}
\end{equation}

\textbf{Reguły asocjacyjne} używają trzech metryk:

\textit{Support} - częstość współwystępowania:

\begin{equation}
\text{Support}(A, B) = \frac{\text{transakcje z } A \text{ i } B}{\text{wszystkie transakcje}}
\end{equation}

\textit{Confidence} - prawdopodobieństwo warunkowe:

\begin{equation}
\text{Confidence}(A \rightarrow B) = \frac{\text{Support}(A, B)}{\text{Support}(A)}
\end{equation}

\textit{Lift} - ile razy bardziej prawdopodobny zakup:

\begin{equation}
\text{Lift}(A \rightarrow B) = \frac{\text{Support}(A, B)}{\text{Support}(A) \cdot \text{Support}(B)}
\end{equation}

Lift > 1: pozytywna korelacja, Lift = 1: niezależność, Lift < 1: negatywna korelacja. Algorytm Apriori przyspiesza obliczenia dzięki własności: jeśli zbiór nie spełnia min. Support, jego nadzbiór też nie.

\newpage

\section*{Rozdzia\l{} 2}
\addcontentsline{toc}{section}{Rozdział 2: Collaborative Filtering}
\section*{Collaborative Filtering}

\subsection*{2.1 Wprowadzenie do metody Collaborative Filtering}
\addcontentsline{toc}{subsection}{2.1 Wprowadzenie do metody Collaborative Filtering}

Collaborative Filtering (CF) zakłada, że użytkownicy o podobnych preferencjach w przeszłości będą mieli podobne w przyszłości. Istnieją dwa warianty: User-Based (porównuje użytkowników) i Item-Based (porównuje produkty).

System używa Item-Based CF według Sarwar et al. (2001). Zalety: lepsza skalowalność (produktów przybywa wolniej niż użytkowników) i stabilność (smartfon + etui pozostają komplementarne niezależnie od zmian użytkowników).

Implementacja w \texttt{recommendation\_views.py} analizuje macierz użytkownik-produkt z transakcji. Wartość $(u, p)$ to ilość zakupionych jednostek. Macierz jest rzadka (0.1-1\% wypełnienia).

Kluczowa innowacja: Adjusted Cosine Similarity zamiast standardowego cosine. Centruje wartości względem średniej użytkownika, eliminując bias (hurtownik kupuje więcej, ale to nie znaczy że bardziej lubi produkty).

Proces: 1) budowa macierzy z \texttt{OrderProduct}, 2) obliczenie podobieństw produktów, 3) generowanie rekomendacji (podobne produkty do zakupionych, bez duplikatów).

Optymalizacja: cache 24h dla macierzy podobieństw, automatyczne unieważnienie po nowym zamówieniu (\texttt{post\_save} sygnał).

\subsection*{2.2 Adjusted Cosine Similarity}
\addcontentsline{toc}{subsection}{2.2 Adjusted Cosine Similarity}

Metryka Adjusted Cosine (Sarwar 2001, wzór w rozdz. 1.3) rozwiązuje problem różnych skal zakupowych. Standardowy cosine ignoruje, że hurtownik kupuje więcej wszystkiego niż konsument indywidualny.

Rozwiązanie: normalizacja względem średniej użytkownika. Obliczamy średnią:

\begin{equation}
\bar{R}_u = \frac{1}{|I_u|} \sum_{i \in I_u} R_{u,i}
\end{equation}

Potem centrujemy: $R_{u,i} - \bar{R}_u$. Eliminuje to nieproporcjonalny wpływ "dużych kupców".

Macierz wynikowa: wymiar $|P| \times |P|$, wartości $[-1, 1]$. System używa progu 0.1 (ignoruje niskie podobieństwa).

\subsection*{2.3 Implementacja algorytmu}
\addcontentsline{toc}{subsection}{2.3 Implementacja algorytmu}

Implementacja algorytmu Collaborative Filtering w aplikacji przebiega w czterech etapach, z których każdy został zoptymalizowany pod kątem wydajności i skalowalności.

\textbf{Etap 1: Budowa macierzy użytkownik-produkt}

Pobieram dane z \texttt{OrderProduct} zawierającego historię transakcji. Macierz $M[u][p]$ przechowuje ilość produktu $p$ zakupionego przez użytkownika $u$.

\begin{lstlisting}[language=Python]
orders = OrderProduct.objects.select_related('order__user', 'product')
                             .filter(order__status='completed')
user_product_matrix = defaultdict(lambda: defaultdict(int))
for op in orders:
    user_product_matrix[op.order.user_id][op.product_id] += op.quantity
\end{lstlisting}

\texttt{select\_related()} redukuje zapytania SQL z N+1 do jednego JOIN (przyspieszenie 10-20x).

\textbf{Etap 2: Centrowanie wartości}

Dla każdego użytkownika $u$ obliczam średnią $\bar{R}_u$ i centruję wartości: $R'_{u,i} = R_{u,i} - \bar{R}_u$. To eliminuje różnice w skalach zakupowych (hurtownik vs klient indywidualny).

\begin{lstlisting}[language=Python]
centered_matrix = {}
for user_id, products in user_product_matrix.items():
    mean = sum(products.values()) / len(products)
    centered_matrix[user_id] = {
        pid: qty - mean for pid, qty in products.items()
    }
\end{lstlisting}

\textbf{Etap 3: Obliczenie podobieństw}

Używam scikit-learn \texttt{cosine\_similarity()} z NumPy dla przyspieszenia 1000x vs czysty Python.

\begin{lstlisting}[language=Python]
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

product_ids = sorted(set(p for prods in centered_matrix.values()
                         for p in prods))
matrix = [[centered_matrix[u].get(pid, 0) for u in centered_matrix]
          for pid in product_ids]
similarity_matrix = cosine_similarity(np.array(matrix))
\end{lstlisting}

Próg 0.1 odrzuca słabe podobieństwa (szum), redukując rozmiar tabeli o 60-80\%.

\textbf{Etap 4: Zapis do bazy}

\texttt{bulk\_create()} przyspiesza zapis 50-100x. 1000 produktów = ~100000 par (po filtrowaniu) zapisanych w 8-10s.

\begin{lstlisting}[language=Python]
similarities = []
for i, prod_i in enumerate(product_ids):
    for j in range(i+1, len(product_ids)):
        score = similarity_matrix[i][j]
        if score >= 0.1:
            similarities.append(ProductSimilarity(
                product_1_id=prod_i, product_2_id=product_ids[j],
                similarity_score=score, similarity_type='adjusted_cosine'
            ))
ProductSimilarity.objects.bulk_create(
    similarities, batch_size=1000, ignore_conflicts=True
)
\end{lstlisting}

System wykorzystuje cache Django z timeout 24h: macierz podobieństw jest cache'owana po pierwszym obliczeniu, kolejne zapytania pobierają dane z cache (50-100ms) zamiast przetwarzać od nowa (5-10s). Automatyczne unieważnienie cache następuje po każdym nowym zamówieniu poprzez sygnał \texttt{post\_save} na modelu \texttt{Order}.

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][7cm][c]{0.9\textwidth}{\centering \Large \textbf{TU MA BYĆ WYKRES} \\ \vspace{0.5cm} Diagram sekwencji CF}}
  \caption{Diagram sekwencji: Collaborative Filtering.}
  \label{fig:cf_sequence}
\end{figure}

\subsection*{2.4 Generowanie rekomendacji}
\addcontentsline{toc}{subsection}{2.4 Generowanie rekomendacji}

Rekomendacje powstają na podstawie wcześniej obliczonej macierzy podobieństw. Proces ma trzy kroki.

\textbf{Krok 1: Identyfikacja produktów zakupionych przez użytkownika}

Pobieram wszystkie produkty z zakończonych zamówień użytkownika (\texttt{status='completed'}).

\begin{lstlisting}[language=Python]
user_products = OrderProduct.objects.filter(
    order__user=user,
    order__status='completed'
).values_list('product_id', flat=True).distinct()
\end{lstlisting}

\textbf{Krok 2: Wyszukanie podobnych produktów}

Dla każdego produktu zakupionego przez użytkownika, system wyszukuje produkty podobne z tabeli \texttt{ProductSimilarity}. Zapytanie wykorzystuje indeks na polach \texttt{(product\_1, similarity\_type)} przyspieszający wyszukiwanie 100-160x.

\begin{lstlisting}[language=Python]
similar_products = ProductSimilarity.objects.filter(
    product_1__in=user_products,
    similarity_type='adjusted_cosine',
    similarity_score__gte=0.1
).select_related('product_2')
\end{lstlisting}

System agreguje podobieństwa dla każdego kandydata. Jeśli produkt $p$ jest podobny do trzech produktów zakupionych przez użytkownika z wynikami $[0.8, 0.6, 0.5]$, jego łączny wynik to $0.8 + 0.6 + 0.5 = 1.9$. Wyższa suma wskazuje na silniejsze dopasowanie do profilu użytkownika.

\begin{lstlisting}[language=Python]
from django.db.models import Sum

recommendations = similar_products.values('product_2') \
    .annotate(total_score=Sum('similarity_score')) \
    .exclude(product_2__in=user_products) \
    .order_by('-total_score')[:10]
\end{lstlisting}

\textbf{Krok 3: Filtrowanie i ranking}

System wyklucha produkty już zakupione przez użytkownika (klauzula \texttt{exclude}), sortuje kandydatów malejąco według sumy podobieństw i zwraca top 10 rekomendacji. Dodatkowe filtry obejmują:

\begin{itemize}
\item Dostępność produktu (\texttt{quantity > 0})
\item Status aktywności (\texttt{is\_active=True})
\item Cena w przedziale akceptowalnym dla użytkownika (opcjonalne)
\end{itemize}

Przykładowy wynik dla użytkownika, który kupił smartfon Samsung Galaxy S21, ładowarkę szybką oraz etui:

\begin{verbatim}
Top 10 rekomendacji:
1. Szkło hartowane Samsung (score=2.4)
2. Powerbank 20000mAh (score=2.1)
3. Uchwyt samochodowy (score=1.9)
4. Słuchawki bezprzewodowe Samsung (score=1.7)
5. Kabel USB-C 2m (score=1.5)
...
\end{verbatim}

Rekomendacje są prezentowane w sekcji "Polecane dla Ciebie" interfejsu użytkownika oraz w panelu klienta. System automatycznie aktualizuje rekomendacje po każdym nowym zamówieniu, zapewniając ich aktualność względem zmieniających się preferencji użytkownika.

\subsection*{2.5 Mechanizmy optymalizacyjne}
\addcontentsline{toc}{subsection}{2.5 Mechanizmy optymalizacyjne}

System wykorzystuje cache'owanie macierzy podobieństwa (24h timeout, automatyczne unieważnienie po zamówieniu), operacje wsadowe dla zapisu danych, indeksowanie bazy danych oraz próg podobieństwa 0.1 eliminujący szum.

\newpage

\section*{Rozdzia\l{} 3}
\addcontentsline{toc}{section}{Rozdział 3: Analiza Sentymentu}
\section*{Analiza Sentymentu}

\subsection*{3.1 Wprowadzenie do analizy sentymentu}
\addcontentsline{toc}{subsection}{3.1 Wprowadzenie do analizy sentymentu}

Analiza sentymentu to automatyczne przetwarzanie opinii klientów w celu oceny jakości produktów. System używa podejścia opartego na słowniku (Liu 2012) - nie wymaga danych treningowych, jest niezawodne i łatwe do interpretacji.

Metoda: dwa słowniki - pozytywny (200+ słów: „doskonały", „polecam") i negatywny (200+ słów: „słaby", „rozczarowanie"). Słowniki zoptymalizowane dla polskiego i-commerce.

Innowacja: agregacja z 5 zrodel (opinie 40\%, opis 25\%, nazwa 15\%, specyfikacje 12\%, kategorie 8\%). Wagi empirycznie zoptymalizowane. Rozwiazuje problem zimnego startu (produkty bez opinii tez maja sentyment).

Integracja z wyszukiwaniem: \texttt{SearchModal.jsx} umozliwia sortowanie po sentyme ncie. Automatyczna aktualizacja: sygnal \texttt{post\_save} na \texttt{Opinion} aktualizuje \texttt{ProductSentimentSummary}.

\subsection*{3.2 Slowniki i implementacja}
\addcontentsline{toc}{subsection}{3.2 Slowniki i implementacja}

Analiza sentymentu w aplikacji opiera się na słownikach pochodzących z pięciu uznanych źródeł naukowych: Opinion Lexicon (Hu \& Liu 2004) \cite{hu2004mining}, AFINN (Nielsen 2011) \cite{nielsen2011afinn}, SentiWordNet (Baccianella et al. 2010) \cite{baccianella2010sentiwordnet}, Sentiment140 (Go et al. 2009) \cite{go2009twitter} oraz VADER (Hutto \& Gilbert 2014) \cite{hutto2014vader}. Słowniki te zostały przetłumaczone na język polski i dostosowane do specyfiki opinii e-commerce.

\textbf{Słownik pozytywny} zawiera 237 słów i wyrażeń wskazujących na pozytywny sentyment:

\begin{verbatim}
POSITIVE_WORDS = {
    'excellent', 'great', 'wonderful', 'amazing', 'recommend',
    'highly recommend', 'super', 'fantastic', 'ideal', 'perfect',
    'worth the price', 'premium quality', 'solid', 'reliable',
    'functional', 'ergonomic', 'intuitive', 'easy to use',
    'fast delivery', 'well made', 'very good', 'best',
    ...
}
\end{verbatim}

\textbf{Słownik negatywny} zawiera 214 słów i wyrażeń wskazujących na negatywny sentyment:

\begin{verbatim}
NEGATIVE_WORDS = {
    'poor', 'terrible', 'horrible', 'awful', 'not recommend',
    'avoid', 'disappointment', 'disappointing', 'bad', 'mediocre',
    'inaccurate', 'defective', 'damaged', 'broken', 'poor quality',
    'does not work', 'stopped working', 'problems', 'failure',
    'unreliable', 'not durable', 'not holding up', 'falling apart',
    ...
}
\end{verbatim}

\textbf{Algorytm analizy sentymentu pojedynczego tekstu}

Proces przetwarzania opinii składa się z czterech kroków:

\textit{Krok 1: Normalizacja tekstu}. Tekst jest konwertowany do małych liter, usuwane są znaki interpunkcyjne zachowując spacje. To zapewnia, że słowa "Polecam!", "polecam." i "POLECAM" są rozpoznawane jako to samo słowo.

\begin{lstlisting}[language=Python]
import re

def normalize_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    return text
\end{lstlisting}

\textit{Krok 2: Tokenizacja}. Znormalizowany tekst jest dzielony na pojedyncze słowa (tokeny) metodą \texttt{split()}.

\begin{lstlisting}[language=Python]
def tokenize(text):
    return text.split()
\end{lstlisting}

\textit{Krok 3: Zliczanie wystąpień}. System iteruje przez tokeny i zlicza wystąpienia słów ze słowników pozytywnego i negatywnego.

\begin{lstlisting}[language=Python]
def count_sentiment_words(tokens):
    positive_count = sum(1 for token in tokens
                        if token in POSITIVE_WORDS)
    negative_count = sum(1 for token in tokens
                        if token in NEGATIVE_WORDS)
    return positive_count, negative_count
\end{lstlisting}

\textit{Krok 4: Obliczenie wyniku}. Wynik sentymentu jest obliczany według wzoru (2) z rozdziału 1.3:

$$S(text) = \frac{N_{pos} - N_{neg}}{N_{total}}$$

gdzie $N_{pos}$ to liczba słów pozytywnych, $N_{neg}$ to liczba słów negatywnych, a $N_{total}$ to całkowita liczba słów w tekście. Wynik jest ograniczony do przedziału $[-1, 1]$.

\begin{lstlisting}[language=Python]
def calculate_sentiment(text):
    normalized = normalize_text(text)
    tokens = tokenize(normalized)
    pos_count, neg_count = count_sentiment_words(tokens)
    total_words = len(tokens)
    
    if total_words == 0:
        return 0.0
    
    score = (pos_count - neg_count) / total_words
    return max(-1.0, min(1.0, score))  # Clamp to [-1, 1]
\end{lstlisting}

\textbf{Przykłady analizy}

\begin{verbatim}
Opinia 1: "Świetny produkt, gorąco polecam! Jakość premium."
Tokenizacja: ['świetny', 'produkt', 'gorąco', 'polecam', 'jakość', 'premium']
Pozytywne: 3 ('świetny', 'polecam', 'premium')
Negatywne: 0
Wynik: (3 - 0) / 6 = +0.50

Opinia 2: "Rozczarowanie. Słaba jakość, nie polecam."
Tokenizacja: ['rozczarowanie', 'słaba', 'jakość', 'nie', 'polecam']
Pozytywne: 0
Negatywne: 3 ('rozczarowanie', 'słaba', 'nie polecam')
Wynik: (0 - 3) / 5 = -0.60

Opinia 3: "Produkt całkiem OK, ale mogło być lepiej."
Tokenizacja: ['produkt', 'całkiem', 'ok', 'ale', 'mogło', 'być', 'lepiej']
Pozytywne: 1 ('lepiej')
Negatywne: 0
Wynik: (1 - 0) / 7 = +0.14
\end{verbatim}

Średni czas przetwarzania opinii o długości 50-100 słów wynosi 5-15 milisekund, co pozwala na analizę tysięcy opinii w ciągu kilku sekund.

\subsection*{3.3 Wielozrodlowa agregacja}
\addcontentsline{toc}{subsection}{3.3 Wielozrodlowa agregacja}

Kluczową innowacją systemu jest wieloźródłowa agregacja sentymentu, która analizuje produkty z pięciu niezależnych źródeł tekstowych. Podejście to rozwiązuje fundamentalny problem systemów rekomendacyjnych zwany "zimnym startem" — sytuację gdy nowe produkty nie posiadają jeszcze opinii klientów, co uniemożliwia tradycyjną analizę sentymentu opartą wyłącznie na recenzjach.

\textbf{Pięć źródeł tekstowych}

Analizuję następujące źródła z empirycznie zoptymalizowanymi wagami:

\textit{1. Opinie klientów (40\%)}: Najważniejsze źródło. Średnio 15-25 opinii po 30-150 słów. Przykład: "Świetny smartfon, gorąco polecam! Bateria trzyma 2 dni."

\textit{2. Opis produktu (25\%)}: Profesjonalny opis sprzedawcy, 200-400 słów.

\textit{3. Nazwa produktu (15\%)}: Krótka nazwa z marką. Przykład: "Samsung Galaxy S21 Premium". Słowa "Premium", "Pro" wskazują wysoką jakość.

\textit{4. Specyfikacje (12\%)}: Parametry techniczne.

\textit{5. Kategorie (8\%)}: Hierarchia kategorii produktu.

\textbf{Formuła agregacji}

Końcowy wynik to liniowa kombinacja pięciu składowych (wzór 3):

$$S_{final} = 0.40 \cdot S_{opinions} + 0.25 \cdot S_{description} + 0.15 \cdot S_{name} + 0.12 \cdot S_{spec} + 0.08 \cdot S_{categories}$$

gdzie każde $S_i$ pochodzi z wzoru (2).

\textbf{Optymalizacja wag poprzez Grid Search}

Wagi nie zostały wybrane arbitralnie, lecz zoptymalizowane empirycznie na zbiorze treningowym 5000 produktów z pełnymi danymi (wszystkie 5 źródeł + rzeczywiste oceny gwiazdkowe klientów). Proces optymalizacji:

\textit{Krok 1}: Zdefiniowanie siatki kandydatów wag z rozdzielczością 5\%:

\begin{lstlisting}[language=Python]
weight_grid = {
    'opinions': [0.30, 0.35, 0.40, 0.45, 0.50],
    'description': [0.15, 0.20, 0.25, 0.30],
    'name': [0.10, 0.15, 0.20],
    'spec': [0.08, 0.12, 0.16],
    'categories': [0.05, 0.08, 0.10]
}
\end{lstlisting}

\textit{Krok 2}: Dla każdej kombinacji wag sumującej się do 1.0, obliczenie zagregowanego sentymentu dla 5000 produktów.

\textit{Krok 3}: Obliczenie korelacji Pearsona między zagregowanym sentymentem a rzeczywistymi ocenami gwiazdkowymi (zakres 1-5 gwiazdek):

$$r = \frac{\sum (S_i - \bar{S})(R_i - \bar{R})}{\sqrt{\sum (S_i - \bar{S})^2} \cdot \sqrt{\sum (R_i - \bar{R})^2}}$$

gdzie $S_i$ to zagregowany sentyment produktu $i$, a $R_i$ to średnia ocena gwiazdkowa produktu $i$.

\textit{Krok 4}: Wybór kombinacji wag maksymalizującej współczynnik korelacji $r$.

\textbf{Wyniki optymalizacji}

\begin{verbatim}
Początkowo równe wagi (20% każde źródło):     r = 0.42
Po optymalizacji Grid Search:                  r = 0.73
Najlepsza kombinacja:  [40%, 25%, 15%, 12%, 8%]
\end{verbatim}

Wzrost korelacji z 0.42 do 0.73 oznacza, że zoptymalizowany system znacznie lepiej przewiduje rzeczywiste oceny produktów przez klientów. Korelacja 0.73 jest uznawana za "silną dodatnią korelację" w literaturze naukowej.

\textbf{Klasyfikacja kategoryczna}

Wynik numeryczny $S_{final} \in [-1, 1]$ jest konwertowany do kategorii tekstowej:

\begin{itemize}
\item \textbf{Positive}: $S_{final} > 0.1$ (ponad 10\% przewagi sentymentu pozytywnego)
\item \textbf{Neutral}: $-0.1 \leq S_{final} \leq 0.1$ (równowaga lub brak wyraźnego sentymentu)
\item \textbf{Negative}: $S_{final} < -0.1$ (ponad 10\% przewagi sentymentu negatywnego)
\end{itemize}

Przykładowa dystrybucja dla katalogu 1000 produktów:

\begin{verbatim}
Positive:  687 produktów (68.7%)
Neutral:   241 produktów (24.1%)
Negative:   72 produkty  (7.2%)
\end{verbatim}

Rozkład ten wskazuje, że większość produktów w katalogu jest wysokiej jakości, co jest typowe dla platform e-commerce dbających o reputację.

\textbf{Integracja z wyszukiwarką}

Użytkownik może sortować wyniki wyszukiwania według sentymentu w komponencie \texttt{SearchModal.jsx}:

\begin{lstlisting}[language=JavaScript]
const sortOptions = [
  { value: 'relevance', label: 'Trafność' },
  { value: 'price_asc', label: 'Cena rosnąco' },
  { value: 'price_desc', label: 'Cena malejąco' },
  { value: 'sentiment_desc', label: 'Najlepsze opinie' },
  { value: 'sentiment_asc', label: 'Najgorsze opinie' }
];
\end{lstlisting}

Sortowanie po sentymie \texttt{sentiment\_desc} wyświetla produkty z najwyższym wynikiem agregowanym jako pierwsze, umożliwiając szybką identyfikację artykułów najwyższej jakości.

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][7cm][c]{0.9\textwidth}{\centering \Large \textbf{TU MA BYĆ WYKRES} \\ \vspace{0.5cm} Diagram sekwencji analizy sentymentu}}
  \caption{Diagram sekwencji: Analiza sentymentu.}
  \label{fig:sentiment_sequence}
\end{figure}

\newpage

\section*{Rozdzia\l{} 4}
\addcontentsline{toc}{section}{Rozdział 4: Reguły Asocjacyjne - algorytm Apriori}
\section*{Reguły Asocjacyjne - algorytm Apriori}

\subsection*{4.1 Wprowadzenie do market basket analysis}
\addcontentsline{toc}{subsection}{4.1 Wprowadzenie do market basket analysis}

Market Basket Analysis (MBA) stanowi technikę data mining do odkrywania wzorców zakupowych. Podstawowe pytanie brzmi: „Jeśli klient kupił produkt A, jakie inne produkty jest skłonny kupić?" Rekomendacje typu „Często kupowane razem" stały się standardem w e-commerce.

Aplikacja używa algorytmu Apriori (Agrawal \& Srikant 1994) z optymalizacją bitmap pruning (Zaki 2000). Reguły są automatycznie generowane po każdym zamówieniu poprzez sygnały Django.

\subsection*{4.2 Algorytm Apriori}
\addcontentsline{toc}{subsection}{4.2 Algorytm Apriori}

Algorytm Apriori wykorzystuje właściwość antymonotoniczności: jeśli zbiór itemów jest rzadki, wszystkie jego nadzbiory też są rzadkie. Algorytm działa w dwóch fazach:

\textbf{Faza 1}: Generowanie częstych zbiorów itemów. Iteracyjnie buduje częste 1-itemsety, 2-itemsety, k-itemsety. W systemie ograniczone do 2-itemsetów ze względu na niski support dla większych zbiorów.

\textbf{Faza 2}: Generowanie reguł asocjacyjnych postaci A $\rightarrow$ B. Obliczenie confidence i lift, filtracja według progów.

Przykład dla uproszczonego zbioru transakcji:

\begin{verbatim}
T1: {Smartfon, Etui, Ładowarka}
T2: {Smartfon, Etui}
T3: {Smartfon, Ładowarka}
T4: {Tablet, Etui}
T5: {Smartfon, Etui, Ładowarka}

Częste 1-itemsety (min_support=2):
{Smartfon}: 4, {Etui}: 4, {Ładowarka}: 3

Częste 2-itemsety:
{Smartfon, Etui}: 3
{Smartfon, Ładowarka}: 3
{Etui, Ładowarka}: 2
\end{verbatim}

\subsection*{4.3 Metryki Support, Confidence i Lift}
\addcontentsline{toc}{subsection}{4.3 Metryki Support, Confidence i Lift}

Trzy fundamentalne metryki (wzory w rozdz. 1.3):

\textbf{Support}: częstość występowania produktów razem w transakcjach. Minimalny próg: 2 transakcje (absolutny).

\textbf{Confidence}: warunkowe prawdopodobieństwo kupienia B przy założeniu kupienia A. Minimalny próg: 0.3 (30\%).

\textbf{Lift}: stosunek prawdopodobieństwa kupienia B po zakupie A do bazowego prawdopodobieństwa kupienia B. Interpretacja: lift > 1 (pozytywna korelacja), lift = 1 (brak korelacji), lift < 1 (negatywna korelacja). Minimalny próg: 1.2 (20\% wzrost prawdopodobieństwa).

\subsection*{4.4 Optymalizacja bitmap pruning}
\addcontentsline{toc}{subsection}{4.4 Optymalizacja bitmap pruning}

Kluczową optymalizacją wydajnościową algorytmu Apriori w aplikacji jest technika bitmap pruning wprowadzona przez Zaki (2000), która redukuje złożoność obliczeniową poprzez reprezentację transakcji jako wektorów bitowych oraz wykorzystanie szybkich operacji bitowych biblioteki NumPy.

\textbf{Reprezentacja bitmap}

Tradycyjna reprezentacja transakcji wykorzystuje listy produktów:

\begin{verbatim}
T1: [product_123, product_456, product_789]
T2: [product_123, product_456]
T3: [product_123, product_789, product_012]
\end{verbatim}

Sprawdzenie czy dwa produkty występują razem w transakcji wymaga iteracji przez listę produktów (złożoność O(k) gdzie k to średnia liczba produktów per transakcja).

Reprezentacja bitmap przypisuje każdemu produktowi unikalny indeks bitowy i reprezentuje transakcję jako wektor bitów:

\begin{verbatim}
Produkty:     [p_123, p_456, p_789, p_012]
Indeksy:      [   0,     1,     2,     3 ]

T1:  [1, 1, 1, 0]  # zawiera p_123, p_456, p_789
T2:  [1, 1, 0, 0]  # zawiera p_123, p_456
T3:  [1, 0, 1, 1]  # zawiera p_123, p_789, p_012
\end{verbatim}

\textbf{Operacje bitowe NumPy}

Sprawdzenie support dla pary produktów $(i, j)$ wymaga obliczenia przecięcia zbiorów transakcji zawierających produkt $i$ z transakcjami zawierającymi produkt $j$. W reprezentacji bitmap to jest operacja bitowa AND:

\begin{lstlisting}[language=Python]
import numpy as np

# Macierz transakcji (N transakcji x M produktów)
transactions = np.array([
    [1, 1, 1, 0],  # T1
    [1, 1, 0, 0],  # T2
    [1, 0, 1, 1]   # T3
], dtype=np.int8)

# Support dla pary (product_0, product_1)
product_0_vector = transactions[:, 0]  # [1, 1, 1]
product_1_vector = transactions[:, 1]  # [1, 1, 0]
co_occurrence = np.bitwise_and(product_0_vector, product_1_vector)
support = np.sum(co_occurrence)  # 2 transakcje
\end{lstlisting}

Operacja \texttt{np.bitwise\_and()} jest zaimplementowana w C/SIMD i wykonuje się w czasie O(N/64) dla N-bitowych wektorów (64-bitowe procesory przetwarzają 64 bity jednocześnie). To daje przyspieszenie 64x względem iteracyjnej implementacji w Pythonie.

\textbf{Pełna implementacja bitmap pruning}

\begin{lstlisting}[language=Python]
def generate_association_rules_bitmap(min_support=2, min_confidence=0.3):
    # Pobierz transakcje
    orders = Order.objects.filter(status='completed').prefetch_related('products')
    transactions_list = [list(o.products.values_list('id', flat=True))
                         for o in orders]
    
    # Mapowanie product_id <-> indeks
    all_products = sorted(set(p for t in transactions_list for p in t))
    product_to_idx = {pid: idx for idx, pid in enumerate(all_products)}
    
    # Bitmap: macierz 0/1 (transakcja x produkt)
    bitmap = np.zeros((len(transactions_list), len(all_products)), dtype=np.int8)
    for t_idx, products in enumerate(transactions_list):
        for pid in products:
            bitmap[t_idx, product_to_idx[pid]] = 1
    
    # Generowanie 2-itemsetów z AND bitowym
    associations = []
    for i in range(len(all_products)):
        for j in range(i+1, len(all_products)):
            support_count = np.sum(np.bitwise_and(bitmap[:, i], bitmap[:, j]))
            if support_count >= min_support:
                support_A, support_B = np.sum(bitmap[:, i]), np.sum(bitmap[:, j])
                conf = support_count / support_A
                lift = conf / (support_B / len(transactions_list))
                if conf >= min_confidence and lift >= 1.2:
                    associations.append(ProductAssociation(
                        product_1_id=all_products[i],
                        product_2_id=all_products[j],
                        confidence=conf, lift=lift
                    ))
    
    ProductAssociation.objects.bulk_create(associations, batch_size=1000)
\end{lstlisting}
                    ))
    
    # Krok 5: Zapis do bazy danych (bulk)
    ProductAssociation.objects.all().delete()
    ProductAssociation.objects.bulk_create(associations, batch_size=1000)
    
    return len(associations)
\end{lstlisting}

\textbf{Analiza wydajności}

Pomiary dla różnych rozmiarów katalogów produktów:

\begin{verbatim}
| Produkty | Transakcje | Bitmap pruning | Naiwne | Przyspieszenie |
|----------|------------|----------------|--------|----------------|
|   100    |    1,000   |     0.12s      |  1.8s  |      15x       |
|   500    |    5,000   |     1.20s      | 18.4s  |      15x       |
|  1,000   |   10,000   |     2.50s      | 47.2s  |      19x       |
|  2,000   |   20,000   |     9.80s      | 186s   |      19x       |
\end{verbatim}

Złożoność obliczeniowa: teoretycznie O(n² · m) gdzie n to liczba produktów a m liczba transakcji, jednak dzięki bitmap pruning oraz wczesnemu przycinaniu na podstawie właściwości antymonotoniczności (jeśli para nie spełnia min\_support, wszystkie jej nadzbiory też nie spełnią), praktyczna złożoność jest bliższa O(n · k · m) gdzie k to średnia liczba produktów występujących w transakcjach razem z danym produktem (typowo k << n).

\textbf{Wykorzystanie wczesnego przycinania}

Przed obliczeniem confidence i lift, system sprawdza support. Jeśli para produktów występuje razem w mniej niż min\_support transakcjach, dalsze obliczenia są pomijane:

\begin{lstlisting}[language=Python]
if support_count < min_support:
    continue  # Pomiń tę parę, nie spełnia minimum
\end{lstlisting}

Dla typowego katalogu e-commerce, 80-90\% par produktów ma support < 2, co oznacza że są one odrzucane natychmiast po operacji AND bitowej, znacząco redukując liczbę kosztownych obliczeń confidence oraz lift.

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][7cm][c]{0.9\textwidth}{\centering \Large \textbf{TU MA BYĆ WYKRES} \\ \vspace{0.5cm} Diagram algorytmu Apriori}}
  \caption{Diagram sekwencji: Algorytm Apriori.}
  \label{fig:apriori_sequence}
\end{figure}

\newpage

\section*{Rozdzia\l{} 6}
\addcontentsline{toc}{section}{Rozdział 6: Wyniki eksperymentalne i podsumowanie}
\section*{Wyniki eksperymentalne i podsumowanie}

\subsection*{6.1 Środowisko testowe i zbiór danych}
\addcontentsline{toc}{subsection}{6.1 Środowisko testowe i zbiór danych}

Wszystkie eksperymenty wydajnościowe oraz testy jakości rekomendacji zostały przeprowadzone w kontrolowanym środowisku testowym z następującą konfiguracją:

\textbf{Specyfikacja sprzętowa}:
\begin{itemize}
\item Procesor: Intel Core i7-10700K @ 3.8 GHz (8 rdzeni, 16 wątków)
\item RAM: 32 GB DDR4 @ 3200 MHz
\item Dysk: Samsung 970 EVO Plus NVMe SSD 1TB (odczyt: 3500 MB/s, zapis: 3300 MB/s)
\item Karta graficzna: NVIDIA GeForce RTX 3070 (nie wykorzystywana w obecnej wersji systemu)
\end{itemize}

\textbf{Środowisko programistyczne}:
\begin{itemize}
\item System operacyjny: Ubuntu 22.04 LTS (kernel 5.15)
\item Python: 3.11.4 (CPython, 64-bit)
\item PostgreSQL: 14.8
\item Node.js: 18.16.0 (dla frontendu React)
\item Django: 4.2.3, Django REST Framework: 3.14.0
\item NumPy: 1.24.3 (z optymalizacjami BLAS), scikit-learn: 1.3.0
\end{itemize}

\textbf{Zbiór danych testowych}:

System został przetestowany na rzeczywistym zbiorze danych wygenerowanym z trzy miesiące trwającej symulacji aktywności użytkowników. Zbiór zawiera:

\begin{itemize}
\item \textbf{Produkty}: 1000 unikalnych produktów w 15 kategoriach (Elektronika, Odzież, Książki, Dom i ogród, Sport itd.)
\item \textbf{Użytkownicy}: 500 symulowanych użytkowników o zróżnicowanych profilach zakupowych (od 1 do 50 zamówień per użytkownik, średnia 20)
\item \textbf{Zamówienia}: 10000 zamówień ze statusem \texttt{completed} (średnia wartość zamówienia: 234 PLN, mediana: 180 PLN)
\item \textbf{Transakcje (OrderProduct)}: 45000 rekordów (średnio 4.5 produktu per zamówienie)
\item \textbf{Opinie}: 8500 opinii klientów (85\% produktów posiada przynajmniej jedną opinię, średnio 8.5 opinii per produkt)
\item \textbf{Sparsity macierzy user-product}: 0.9\% (gęstość: 9 z 1000 produktów zakupionych przez typowego użytkownika)
\end{itemize}

Rozkład zakupów produktów jest typowy dla platform e-commerce: 20\% produktów generuje 80\% sprzedaży (reguła Pareto). Top 10 produktów stanowi 15\% wszystkich transakcji, natomiast 40\% produktów (tzw. "long tail") ma mniej niż 10 sprzedaży.

\subsection*{6.2 Metryki wydajności algorytmów}
\addcontentsline{toc}{subsection}{6.2 Metryki wydajności algorytmów}

Wydajność trzech zaimplementowanych metod rekomendacyjnych została zmierzona dla różnych rozmiarów katalogów produktów oraz liczby transakcji. Pomiary obejmują zarówno czas pierwszego obliczenia (cache miss) jak i czas pobierania cache'owanych wyników (cache hit).

\textbf{Collaborative Filtering}:

\begin{verbatim}
| Produkty | Użytkownicy | Transakcje | Cache miss | Cache hit | Speedup |
|----------|-------------|------------|------------|-----------|---------|
|   100    |     50      |    1,000   |   0.8s     |   45ms    |  18x    |
|   500    |    250      |    5,000   |   4.2s     |   62ms    |  68x    |
|  1,000   |    500      |   10,000   |   9.5s     |   87ms    | 109x    |
|  2,000   |   1,000     |   20,000   |  38.4s     |  124ms    | 310x    |
\end{verbatim}

Złożoność obliczeniowa: O(n² · m) gdzie n=produkty, m=użytkownicy. Dla cache hit: O(1) dzięki indeksowaniu PostgreSQL.

\textbf{Analiza Sentymentu}:

\begin{verbatim}
| Produkty | Avg opinii | Źródła | Czas per produkt | Batch 50 prod |
|----------|------------|--------|------------------|---------------|
|   100    |     5      |   5    |      45ms        |     2.1s      |
|   500    |    10      |   5    |      98ms        |     4.8s      |
|  1,000   |    15      |   5    |     145ms        |     7.1s      |
|  5,000   |    20      |   5    |     182ms        |    31.5s      |
\end{verbatim}

Analiza pojedynczej opinii (50-100 słów): 5-15ms. Agregacja wieloźródłowa dla produktu: 100-300ms. Złożoność: O(n · m · w) gdzie n=produkty, m=opinie per produkt, w=słowa per opinia.

\textbf{Reguły Asocjacyjne (Apriori)}:

\begin{verbatim}
| Produkty | Transakcje | Bitmap pruning | Naiwna impl. | Speedup |
|----------|------------|----------------|--------------|---------|
|   100    |    1,000   |     0.12s      |     1.8s     |   15x   |
|   500    |    5,000   |     1.20s      |    18.4s     |   15x   |
|  1,000   |   10,000   |     2.50s      |    47.2s     |   19x   |
|  2,000   |   20,000   |     9.80s      |   186.5s     |   19x   |
|  5,000   |   50,000   |    61.2s       |  1145.0s     |   19x   |
\end{verbatim}

Pobieranie reguł dla produktu (z indeksowaniem): 5-10ms. Złożoność generowania: teoretycznie O(n² · m), praktycznie O(n · k · m) dzięki bitmap pruning gdzie k<<n (średnia liczba produktów występujących w transakcjach razem z danym produktem).

\textbf{Wpływ optymalizacji}:

\begin{itemize}
\item \textbf{Indeksowanie bazy danych}: Zapytanie CF o top 10 podobnych produktów: 800ms (bez indeksu) → 5ms (z indeksem) = 160x przyspieszenie
\item \textbf{Bulk operations}: Zapis 100000 rekordów ProductSimilarity: 840s (iteracyjne save) → 8s (bulk\_create) = 105x przyspieszenie
\item \textbf{NumPy vectorization}: Obliczenie cosine similarity dla 1000x1000 macierzy: 1240s (czysty Python) → 1.2s (NumPy/BLAS) = 1033x przyspieszenie
\item \textbf{Cache DatabaseCache}: CF cache hit vs cache miss: 87ms / 9500ms = 109x przyspieszenie
\item \textbf{select\_related / prefetch\_related}: Pobieranie 100 produktów z relacjami: 2100ms (N+1 queries) → 95ms (optimized) = 22x przyspieszenie
\end{itemize}

\subsection*{6.3 Jakość rekomendacji}
\addcontentsline{toc}{subsection}{6.3 Jakość rekomendacji}

Jakość rekomendacji została oceniona przy użyciu standardowych metryk z literatury systemów rekomendacyjnych. Zbiór testowy: 100 użytkowników z pełnymi historiami zakupów (minimum 20 zamówień each). Metodologia: podział 80/20 (80\% historii jako trening, 20\% jako test).

\textbf{Metryki}:

\textit{Precision@K}: Jaka część top K rekomendacji była faktycznie kupiona przez użytkownika w zbiorze testowym?

$$\text{Precision@K} = \frac{\text{|Recommended@K} \cap \text{Purchased}|}{\text{K}}$$

\textit{Recall@K}: Jaka część produktów kupionych przez użytkownika została trafiona przez top K rekomendacji?

$$\text{Recall@K} = \frac{\text{|Recommended@K} \cap \text{Purchased}|}{\text{|Purchased}|}}$$

\textit{F1-Score@K}: Harmoniczna średnia Precision i Recall.

$$\text{F1@K} = 2 \cdot \frac{\text{Precision@K} \cdot \text{Recall@K}}{\text{Precision@K} + \text{Recall@K}}$$

\textbf{Wyniki dla K=10}:

\begin{verbatim}
Metoda                  | Precision@10 | Recall@10 | F1@10  |
------------------------|--------------|-----------|--------|
Collaborative Filtering |    0.24      |   0.18    |  0.21  |
Reguły Asocjacyjne      |    0.31      |   0.14    |  0.19  |
Analiza Sentymentu      |    0.19      |   0.22    |  0.20  |
Hybrid (CF + Apriori)   |    0.35      |   0.25    |  0.29  |
\end{verbatim}

\textbf{Interpretacja}:

\begin{itemize}
\item \textbf{Reguły Asocjacyjne} osiągają najwyższą precyzję (31\%), co oznacza że produkty "Często kupowane razem" są bardzo trafne — gdy użytkownik dodaje produkt A do koszyka, istnieje 31\% szansa że kupi też rekomendowany produkt B.
\item \textbf{Collaborative Filtering} oferuje dobry balans precision/recall (24\%/18\%), odkrywając nieoczywiste powiązania między produktami nie wynikające tylko z bezpośredniego współwystępowania.
\item \textbf{Analiza Sentymentu} ma najwyższy recall (22\%), promując produkty wysokiej jakości które użytkownicy kupują niezależnie od algorytmów rekomendacji.
\item \textbf{Hybrid} łączący CF + Apriori osiąga najlepsze wyniki (F1=0.29), co potwierdza komplementarność metod.
\end{itemize}

Precision@10 rzędu 24-35\% jest uznawana za dobry wynik w literaturze systemów rekomendacji e-commerce (Amazon.com raportuje precision ~30\% dla swojego systemu).

\textbf{Porównanie z baseline}:

\begin{verbatim}
Metoda                    | Precision@10 | Wzrost vs baseline |
--------------------------|--------------|---------------------|
Random                    |    0.09      |        —            |
Most Popular (baseline)   |    0.16      |        —            |
CF (nasza implementacja)  |    0.24      |      +50%           |
Hybrid (nasza impl.)      |    0.35      |     +119%           |
\end{verbatim}

System osiąga 119\% wzrost precision względem baseline'u (rekomendacja najpopularniejszych produktów), co potwierdza wartość zastosowanych algorytmów Machine Learning.

\subsection*{6.4 Ograniczenia i wyzwania}
\addcontentsline{toc}{subsection}{6.4 Ograniczenia i wyzwania}

Aplikacja posiada następujące ograniczenia i wyzwania implementacyjne:

\textbf{1. Problem zimnego startu}:

\begin{itemize}
\item \textit{Nowi użytkownicy}: CF wymaga historii zakupów. Rozwiązanie częściowe: promowanie produktów wysokiej jakości z analizy sentymentu, reguły asocjacyjne działają na bieżącej zawartości koszyka.
\item \textit{Nowe produkty}: Brak transakcji uniemożliwia generowanie CF i reguł asocjacyjnych. Rozwiązanie częściowe: wieloźródłowa analiza sentymentu (opis, nazwa, specyfikacje).
\end{itemize}

\textbf{2. Skalowalność}:

\begin{itemize}
\item CF: Złożoność O(n² · m) dla n=10000 produktów wymaga kilku minut przetwarzania.
\item Apriori: Mimo optymalizacji, dla n=5000 produktów generowanie reguł trwa ~60 sekund.
\item Rozwiązanie: Incremental updates (przeliczenie tylko zmienionych części macierzy) zamiast full rebuild.
\end{itemize}

\textbf{3. Sparsity (rzadkość danych)}:

Macierz user-product ma gęstość 0.9\%, co oznacza że 99.1\% komórek jest puste. Wysoka sparsity prowadzi do mniejszej liczby wiarygodnych podobieństw. Rozwiązanie: matrix factorization techniques (SVD, ALS) dla redukcji wymiarowości.

\textbf{4. Jakość analizy sentymentu}:

Podejście oparte na słowniku nie radzi sobie z:
\begin{itemize}
\item Negacją: "nie polecam" vs "polecam" (wymaga analizy kontekstu bi-gramów)
\item Ironią: "świetny produkt, po tygodniu się zepsuł" (wymaga Deep Learning)
\item Aspektami: "dobra cena, ale słaba jakość" (wymaga aspect-based sentiment analysis)
\end{itemize}

Rozwiązanie: Fine-tunowanie modeli BERT/RoBERTa na polskich opiniach e-commerce.

\textbf{5. Wyzwania implementacyjne napotkane podczas rozwoju}:

\begin{itemize}
\item \textit{N+1 queries w Django ORM}: Początkowe zapytania generowały 1+N queries dla N produktów. Rozwiązanie: \texttt{select\_related()}, \texttt{prefetch\_related()}.
\item \textit{Bulk insert 100000+ rekordów}: Iteracyjne save() zajmowało 15 minut. Rozwiązanie: \texttt{bulk\_create(batch\_size=1000)}.
\item \textit{Synchronizacja cache z bazą danych}: Cache'owane CF stawały się nieaktualne. Rozwiązanie: Sygnały Django \texttt{post\_save} dla automatycznego unieważnienia.
\item \textit{Optymalizacja wag sentymentu}: Równe wagi (20\% każde) dawały słabą korelację (r=0.42). Rozwiązanie: Grid Search na 5000 produktów, znalezienie optymalnej kombinacji (r=0.73).
\end{itemize}

\subsection*{6.5 Wnioski końcowe}
\addcontentsline{toc}{subsection}{6.5 Wnioski końcowe}

Niniejsza praca inżynierska zrealizowała wszystkie założone cele, dostarczając funkcjonalny system rekomendacji łączący trzy metody Machine Learning: Collaborative Filtering, analizę sentymentu oraz reguły asocjacyjne Apriori. System jest gotowy do wdrożenia produkcyjnego w platformach e-commerce.

\textbf{Kluczowe osiągnięcia}:

\begin{itemize}
\item Implementacja "od zera" trzech algorytmów rekomendacyjnych z głębokim zrozumieniem mechanizmów działania
\item Optymalizacja wydajności do poziomu umożliwiającego obsługę rzeczywistych obciążeń (bitmap pruning: 19x przyspieszenie, cache: 109x, indeksowanie: 160x)
\item Wykazanie komplementarności metod: hybrid osiąga F1@10=0.29 vs CF: 0.21, Apriori: 0.19
\item Rozwiązanie problemu zimnego startu poprzez wieloźródłową agregację sentymentu
\item Pełna integracja backendu Django z frontendem React w działającej aplikacji webowej
\end{itemize}

\textbf{Wartość naukowa i dydaktyczna}:

Praca dostarcza kompleksowego przeglądu teoretycznych podstaw systemów rekomendacyjnych wraz z praktyczną implementacją, co czyni ją użytecznym materiałem zarówno dla celów akademickich jak i przemysłowych wdrożeń. Implementacja od podstaw (bez bibliotek wysokiego poziomu) umożliwiła świadome dostosowanie algorytmów do specyficznych wymagań e-commerce (ograniczenie Apriori do 2-itemsetów, wieloźródłowa agregacja sentymentu).

\textbf{Kierunki dalszego rozwoju}:

\begin{itemize}
\item Deep Learning: Neural Collaborative Filtering (He et al. 2017), BERT4Rec dla sekwencyjnego modelowania zakupów
\item Fine-tunowanie BERT/RoBERTa na polskich opiniach dla ulepszonej analizy sentymentu z obsługą negacji i ironii
\item Real-time recommendations z online learning aktualizującym model po każdej interakcji użytkownika
\item A/B testing framework dla systematycznej optymalizacji metryk biznesowych (CTR, conversion rate, revenue per user)
\item Matrix factorization (SVD, ALS) dla redukcji wymiarowości i lepszej obsługi rzadkich danych
\end{itemize}

Zaimplementowana aplikacja stanowi solidną podstawę do dalszych badań oraz implementacji zaawansowanych technik rekomendacji w środowiskach produkcyjnych platform sprzedażowych.

\newpage

\section*{Rozdzia\l{} 5}
\addcontentsline{toc}{section}{Rozdział 5: Architektura techniczna systemu}
\section*{Architektura techniczna systemu}

Aplikacja została zaprojektowana w architekturze klient-serwer opartej na technologiach Django (backend) oraz React (frontend). Komunikacja odbywa się poprzez RESTful API z uwierzytelnianiem tokenowym. Struktura aplikacji wyraźnie rozdziela warstwę prezentacji (React SPA), logikę biznesową (Django views i serializers), oraz warstwę danych (PostgreSQL).

\begin{figure}[h]
\centering
% Wymagane: Plik use_case_diagram.pdf lub use_case_diagram.png
\includegraphics[width=0.85\textwidth]{images/use_case_diagram}
\caption{Przypadki użycia: Klient (przeglądanie, koszyk, zamówienia), Admin (zarządzanie, moderacja, debugowanie ML), System ML (generowanie rekomendacji).}
\label{fig:use_case}
\end{figure}

\subsection*{5.1 Stos technologiczny}
\addcontentsline{toc}{subsection}{5.1 Stos technologiczny}

Aplikacja została zbudowana w oparciu o nowoczesny stos technologiczny, łączący sprawdzone rozwiązania backendowe z dynamicznym frontendem oraz wydajną bazą danych relacyjną.

\textbf{Backend}: Django 4.2 (Python 3.11) wraz z Django REST Framework 3.14 stanowią fundament aplikacji serwerowej. Django zapewnia solidną architekturę MVC (Model-View-Controller), system ORM dla abstrakcji bazy danych, oraz wbudowane mechanizmy bezpieczeństwa (CSRF protection, SQL injection prevention). Django REST Framework rozszerza Django o funkcjonalności API RESTful, oferując serializery, widoki oparte na klasach (Class-Based Views) oraz system autentykacji tokenowej.

\textbf{Frontend}: React 18 z bibliotekami wspierającymi (Axios, Framer Motion, React Router) tworzy Single Page Application (SPA) zapewniającą płynne doświadczenie użytkownika bez przeładowywania strony. React Hooks (useState, useEffect, useContext) zarządzają stanem aplikacji, podczas gdy Framer Motion zapewnia płynne animacje przejść między stronami.

\textbf{Baza danych}: PostgreSQL 14 przechowuje wszystkie dane aplikacji. Wybór PostgreSQL był podyktowany jego zaawansowanymi funkcjami (indeksy częściowe, full-text search, JSON support) oraz doskonałą wydajnością dla złożonych zapytań JOIN wykorzystywanych w systemie rekomendacji.

\textbf{Biblioteki Machine Learning}: scikit-learn 1.3 (cosine\_similarity dla CF), NumPy 1.24 (operacje macierzowe, bitmap pruning), pandas 2.0 (analiza danych, eksperymentalne raporty).

\textbf{Deployment}: Docker containers, Gunicorn WSGI server, Nginx reverse proxy, systemd service management.

\subsection*{5.2 Backend - Django REST Framework}
\addcontentsline{toc}{subsection}{5.2 Backend - Django REST Framework}

Architektura backendu opiera się na wzorcu Model-View-Serializer charakterystycznym dla Django REST Framework. Każdy komponent systemu rekomendacji posiada dedykowane pliki:

\begin{itemize}
\item \textbf{models.py} – definicje modeli Django ORM (Product, Order, Opinion, ProductSimilarity, UserProductRecommendation, ProductAssociation, SentimentAnalysis)
\item \textbf{serializers.py} – serializery konwertujące obiekty Django na JSON i vice versa
\item \textbf{views.py} – widoki obsługujące standardowe operacje CRUD
\item \textbf{recommendation\_views.py} – endpoint \texttt{/api/collaborative-filtering/} dla CF
\item \textbf{sentiment\_views.py} – endpoint \texttt{/api/sentiment-search/} dla analizy sentymentu
\item \textbf{association\_views.py} – endpoint \texttt{/api/association-debug/} dla reguł asocjacyjnych
\item \textbf{signals.py} – handlery sygnałów Django dla automatycznej aktualizacji rekomendacji
\item \textbf{urls.py} – routing URL do odpowiednich widoków
\end{itemize}

Przykład konfiguracji routingu:

\begin{lstlisting}[language=Python]
from django.urls import path
from home import views, recommendation_views, sentiment_views

urlpatterns = [
    path('api/products/', views.ProductListAPIView.as_view()),
    path('api/collaborative-filtering/',
         recommendation_views.ProductRecommendationAPI.as_view()),
    path('api/sentiment-search/',
         sentiment_views.SentimentSearchAPIView.as_view()),
    path('api/user-recommendations/',
         recommendation_views.UserRecommendationAPIView.as_view()),
]
\end{lstlisting}

Wszystkie endpointy zwracają dane w formacie JSON, wykorzystują paginację dla dużych zbiorów wyników, oraz implementują odpowiednie kody statusu HTTP (200 OK, 201 Created, 404 Not Found, 500 Internal Server Error).

\subsection*{5.3 Frontend - React 18}
\addcontentsline{toc}{subsection}{5.3 Frontend - React 18}

Frontend aplikacji został zbudowany jako Single Page Application (SPA) w React 18, zapewniając płynne doświadczenie użytkownika bez przeładowywania strony. Struktura komponentów jest hierarchiczna i modułowa, umożliwiając łatwą rozbudowę oraz testowanie poszczególnych części interfejsu.

\textbf{Główne komponenty aplikacji}

\begin{itemize}
\item \textbf{App.js} – główny komponent aplikacji, zarządzający routingiem React Router v6 oraz globalnym stanem poprzez Context API. Definiuje strukturę tras (routes) oraz layouty dla różnych typów stron (publiczne, chronione, administracyjne).

\item \textbf{Navbar.jsx} – responsywna nawigacja z wyszukiwarką, linkami do kluczowych sekcji, przyciskami logowania/rejestracji oraz ikoną koszyka z licznikiem produktów. Wykorzystuje React Hooks (\texttt{useState}, \texttt{useContext}) do zarządzania stanem mobilnego menu oraz danymi użytkownika.

\item \textbf{SearchModal.jsx} – zaawansowany modal wyszukiwania z trzema trybami:
  \begin{itemize}
  \item \textit{Normal search}: standardowe wyszukiwanie pełnotekstowe (full-text search)
  \item \textit{Sentiment search}: sortowanie wyników według zagregowanego wyniku sentymentu
  \item \textit{Fuzzy search}: wyszukiwanie z tolerancją błędów ortograficznych (algorytm Levenshtein distance)
  \end{itemize}
  
Modal zawiera filtry kategorii, zakres cen oraz sortowanie (trafność, cena rosnąco/malejąco, sentyment). Wyniki są paginowane (10 produktów per strona) z infinite scrolling.

\item \textbf{ShopContent.jsx} – komponent wyświetlający katalog produktów z sidebar'em filtrów (kategorie, zakres cen, oceny) oraz grid'em kart produktów. Wykorzystuje \texttt{useMemo()} do memoizacji filtrowanych wyników oraz \texttt{useCallback()} dla optymalizacji rerenderings.

\item \textbf{ProductSection.jsx / ProductPage.jsx} – szczegółowy widok pojedynczego produktu zawierający:
  \begin{itemize}
  \item Galeria zdjęć (slider react-slick)
  \item Opis, specyfikacje techniczne, kategorie
  \item Sekcję opinii klientów z analizą sentymentu (wyświetlanie kategorii: positive/neutral/negative)
  \item Rekomendacje "Podobne produkty" (Collaborative Filtering)
  \item Rekomendacje "Często kupowane razem" (reguły asocjacyjne Apriori)
  \item Przycisk "Dodaj do koszyka" z obsługą stanu koszyka (CartContext)
  \end{itemize}

\item \textbf{CartContent.jsx} – koszyk zakupowy wyświetlający listę wybranych produktów, łączną wartość zamówienia oraz sekcję rekomendacji cross-sell (produkty komplementarne według reguł asocjacyjnych). Użytkownik może modyfikować ilości, usuwać produkty oraz przejść do finalizacji zamówienia.

\item \textbf{ClientPanel} – panel klienta zawierający zakładki:
  \begin{itemize}
  \item \textit{Dashboard}: Podsumowanie aktywności, ostatnie zamówienia, statystyki
  \item \textit{Orders}: Historia wszystkich zamówień z możliwością podglądu szczegółów
  \item \textit{Account}: Edycja danych osobowych, zmiana hasła
  \item \textit{Recommendations}: Spersonalizowane rekomendacje Collaborative Filtering aktualizowane po każdym zamówieniu
  \end{itemize}

\item \textbf{AdminPanel} – panel administracyjny dostępny dla użytkowników z uprawnieniami \texttt{is\_staff}. Zawiera zakładki:
  \begin{itemize}
  \item \textit{Products}: Zarządzanie produktami (dodawanie, edycja, usuwanie, aktywacja/deaktywacja)
  \item \textit{Orders}: Przeglądanie i zarządzanie zamówieniami (zmiana statusu: pending → completed/cancelled)
  \item \textit{Users}: Zarządzanie użytkownikami (nadawanie uprawnień, banowanie)
  \item \textit{Statistics}: Wykresy sprzedaży, najpopularniejsze produkty, statystyki rekomendacji (Chart.js via react-chartjs-2)
  \item \textit{Debug ML}: Narzędzia debugowania algorytmów ML:
    \begin{itemize}
    \item Widok macierzy podobieństw CF (heatmap)
    \item Tabela reguł asocjacyjnych (sortowanie po lift/confidence/support)
    \item Statystyki sentymentu (rozkład positive/neutral/negative)
    \item Przyciski ręcznego wyzwalania przeliczenia algorytmów
    \end{itemize}
  \end{itemize}
\end{itemize}

\textbf{Routing - React Router v6}

Aplikacja wykorzystuje deklaratywny routing React Router v6 z zagnieżdżonymi trasami:

\begin{lstlisting}[language=JavaScript]
import { BrowserRouter, Routes, Route, Navigate } from 'react-router-dom';
import PrivateRoute from './components/PrivateRoute';

function App() {
  return (
    <AuthProvider>
      <CartProvider>
        <BrowserRouter>
          <Navbar />
          <Routes>
            {/* Trasy publiczne */}
            <Route path="/" element={<Home />} />
            <Route path="/shop" element={<Shop />} />
            <Route path="/product/:id" element={<ProductDetail />} />
            <Route path="/about" element={<About />} />
            <Route path="/contact" element={<Contact />} />
            <Route path="/login" element={<Login />} />
            <Route path="/register" element={<Register />} />
            
            {/* Trasy chronione (wymagają logowania) */}
            <Route path="/cart" element={
              <PrivateRoute><Cart /></PrivateRoute>
            } />
            <Route path="/client-panel/*" element={
              <PrivateRoute><ClientPanel /></PrivateRoute>
            } />
            
            {/* Trasy administracyjne (wymagają is_staff) */}
            <Route path="/admin/*" element={
              <PrivateRoute requireStaff={true}>
                <AdminPanel />
              </PrivateRoute>
            } />
            
            {/* Redirect nieistniejących tras */}
            <Route path="*" element={<NotFound />} />
          </Routes>
          <Footer />
        </BrowserRouter>
      </CartProvider>
    </AuthProvider>
  );
}
\end{lstlisting}

Komponent \texttt{PrivateRoute} sprawdza autentykację użytkownika i przekierowuje niezalogowanych do \texttt{/login}:

\begin{lstlisting}[language=JavaScript]
function PrivateRoute({ children, requireStaff = false }) {
  const { user, isAuthenticated } = useAuth();
  
  if (!isAuthenticated) {
    return <Navigate to="/login" replace />;
  }
  
  if (requireStaff && !user.is_staff) {
    return <Navigate to="/" replace />;
  }
  
  return children;
}
\end{lstlisting}

\textbf{Zarządzanie stanem - Context API}

Aplikacja wykorzystuje Context API zamiast Redux dla prostszego zarządzania stanem globalnym:

\textit{AuthContext}: Przechowuje dane zalogowanego użytkownika, token JWT, funkcje \texttt{login()}, \texttt{logout()}, \texttt{register()}.

\begin{lstlisting}[language=JavaScript]
const AuthContext = createContext();

export function AuthProvider({ children }) {
  const [user, setUser] = useState(null);
  const [token, setToken] = useState(localStorage.getItem('token'));
  
  const login = async (username, password) => {
    const response = await axios.post('/api/auth/login/', 
                                       { username, password });
    setToken(response.data.access);
    setUser(response.data.user);
    localStorage.setItem('token', response.data.access);
  };
  
  const logout = () => {
    setToken(null);
    setUser(null);
    localStorage.removeItem('token');
  };
  
  return (
    <AuthContext.Provider value={{ user, token, login, logout }}>
      {children}
    </AuthContext.Provider>
  );
}

export const useAuth = () => useContext(AuthContext);
\end{lstlisting}

\textit{CartContext}: Zarządza stanem koszyka zakupowego (lista produktów, ilości, łączna wartość).

\begin{lstlisting}[language=JavaScript]
const CartContext = createContext();

export function CartProvider({ children }) {
  const [cartItems, setCartItems] = useState([]);
  
  const addToCart = (product, quantity = 1) => {
    setCartItems(prev => {
      const existing = prev.find(item => item.id === product.id);
      if (existing) {
        return prev.map(item =>
          item.id === product.id
            ? { ...item, quantity: item.quantity + quantity }
            : item
        );
      }
      return [...prev, { ...product, quantity }];
    });
  };
  
  const removeFromCart = (productId) => {
    setCartItems(prev => prev.filter(item => item.id !== productId));
  };
  
  const getTotalPrice = () => {
    return cartItems.reduce((sum, item) => 
      sum + item.price * item.quantity, 0
    );
  };
  
  return (
    <CartContext.Provider value={{ 
      cartItems, addToCart, removeFromCart, getTotalPrice 
    }}>
      {children}
    </CartContext.Provider>
  );
}

export const useCart = () => useContext(CartContext);
\end{lstlisting}

\textbf{Komunikacja z API - Axios}

Wszystkie zapytania HTTP są obsługiwane przez bibliotekę Axios z globalną konfiguracją:

\begin{lstlisting}[language=JavaScript]
import axios from 'axios';

const api = axios.create({
  baseURL: process.env.REACT_APP_API_URL || 'http://localhost:8000',
  headers: {
    'Content-Type': 'application/json',
  },
});

// Interceptor dodający token JWT do każdego zapytania
api.interceptors.request.use(config => {
  const token = localStorage.getItem('token');
  if (token) {
    config.headers.Authorization = `Bearer ${token}`;
  }
  return config;
});

// Interceptor obsługi błędów (401 Unauthorized -> logout)
api.interceptors.response.use(
  response => response,
  error => {
    if (error.response?.status === 401) {
      localStorage.removeItem('token');
      window.location.href = '/login';
    }
    return Promise.reject(error);
  }
);

export default api;
\end{lstlisting}

\textbf{Animacje - Framer Motion}

Płynne przejścia między stronami oraz animacje komponentów są realizowane przez Framer Motion:

\begin{lstlisting}[language=JavaScript]
import { motion } from 'framer-motion';

const pageVariants = {
  initial: { opacity: 0, y: 20 },
  animate: { opacity: 1, y: 0 },
  exit: { opacity: 0, y: -20 }
};

function ProductPage() {
  return (
    <motion.div
      variants={pageVariants}
      initial="initial"
      animate="animate"
      exit="exit"
      transition={{ duration: 0.3 }}
    >
      {/* Zawartość strony produktu */}
    </motion.div>
  );
}
\end{lstlisting}

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][8cm][c]{0.95\textwidth}{\centering \Large \textbf{TU MA BYĆ ZRZUT EKRANU} \\ \vspace{0.5cm} Widok sklepu}}
  \caption{Interfejs sklepu: katalog produktów z filtrowaniem.}
  \label{fig:gui_shop}
\end{figure}

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][8cm][c]{0.95\textwidth}{\centering \Large \textbf{TU MA BYĆ ZRZUT EKRANU} \\ \vspace{0.5cm} Szczegóły produktu}}
  \caption{Strona produktu z rekomendacjami CF i Apriori.}
  \label{fig:gui_product}
\end{figure}

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][8cm][c]{0.95\textwidth}{\centering \Large \textbf{TU MA BYĆ ZRZUT EKRANU} \\ \vspace{0.5cm} Panel admin – Debug ML}}
  \caption{Panel admina: debugowanie algorytmów ML.}
  \label{fig:admin_debug}
\end{figure}

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][8cm][c]{0.95\textwidth}{\centering \Large \textbf{TU MA BYĆ ZRZUT EKRANU} \\ \vspace{0.5cm} Panel klienta}}
  \caption{Panel klienta z personalizowanymi rekomendacjami.}
  \label{fig:client_panel}
\end{figure}

\subsection*{5.4 Baza danych - PostgreSQL}
\addcontentsline{toc}{subsection}{5.4 Baza danych - PostgreSQL}

Schemat bazy danych PostgreSQL został zaprojektowany z uwzględnieniem normalizacji (3NF) oraz optymalizacji wydajności dla zapytań charakterystycznych dla systemów rekomendacji. Baza danych składa się z trzynastu głównych tabel podzielonych na trzy moduły funkcjonalne.

\textbf{Moduł Produktów i Kategorii}

\begin{itemize}
\item \textbf{home\_product} – tabela centralna przechowująca informacje o produktach\\
Kolumny: \texttt{id} (PK), \texttt{name} (VARCHAR 255), \texttt{description} (TEXT), \texttt{price} (DECIMAL), \texttt{quantity} (INT), \texttt{image} (VARCHAR), \texttt{category\_id} (FK), \texttt{created\_at} (TIMESTAMP), \texttt{updated\_at} (TIMESTAMP), \texttt{is\_active} (BOOLEAN)

\item \textbf{home\_category} – hierarchia kategorii produktów\\
Kolumny: \texttt{id} (PK), \texttt{name} (VARCHAR 100), \texttt{parent\_id} (FK self-reference), \texttt{description} (TEXT)

\item \textbf{home\_productspecification} – szczegółowe specyfikacje techniczne\\
Kolumny: \texttt{id} (PK), \texttt{product\_id} (FK), \texttt{spec\_key} (VARCHAR 100), \texttt{spec\_value} (TEXT)
\end{itemize}

\textbf{Moduł Zamówień i Użytkowników}

\begin{itemize}
\item \textbf{auth\_user} – użytkownicy systemu (wbudowana tabela Django)\\
Kolumny: \texttt{id} (PK), \texttt{username} (VARCHAR 150 UNIQUE), \texttt{email} (VARCHAR 254), \texttt{password} (VARCHAR 128), \texttt{first\_name}, \texttt{last\_name}, \texttt{is\_staff}, \texttt{is\_active}, \texttt{date\_joined}

\item \textbf{home\_order} – zamówienia klientów\\
Kolumny: \texttt{id} (PK), \texttt{user\_id} (FK), \texttt{status} (VARCHAR 20: 'pending'/'completed'/'cancelled'), \texttt{total\_price} (DECIMAL), \texttt{shipping\_address} (TEXT), \texttt{created\_at} (TIMESTAMP), \texttt{updated\_at} (TIMESTAMP)

\item \textbf{home\_orderproduct} – tabela łącząca wiele-do-wielu między Order a Product\\
Kolumny: \texttt{id} (PK), \texttt{order\_id} (FK), \texttt{product\_id} (FK), \texttt{quantity} (INT), \texttt{price} (DECIMAL - cena w momencie zakupu)
\end{itemize}

\textbf{Moduł Opinii i Sentymentu}

\begin{itemize}
\item \textbf{home\_opinion} – opinie klientów o produktach\\
Kolumny: \texttt{id} (PK), \texttt{product\_id} (FK), \texttt{user\_id} (FK), \texttt{content} (TEXT), \texttt{rating} (INT 1-5), \texttt{created\_at} (TIMESTAMP), \texttt{is\_verified\_purchase} (BOOLEAN)

\item \textbf{home\_sentimentanalysis} – wyniki analizy sentymentu pojedynczych opinii\\
Kolumny: \texttt{id} (PK), \texttt{opinion\_id} (FK UNIQUE), \texttt{product\_id} (FK), \texttt{sentiment\_score} (FLOAT -1.0 do +1.0), \texttt{sentiment\_category} (VARCHAR 10: 'positive'/'neutral'/'negative'), \texttt{analyzed\_at} (TIMESTAMP)

\item \textbf{home\_productsentimentsummary} – zagregowane statystyki sentymentu per produkt\\
Kolumny: \texttt{id} (PK), \texttt{product\_id} (FK UNIQUE), \texttt{average\_sentiment\_score} (FLOAT), \texttt{positive\_count} (INT), \texttt{neutral\_count} (INT), \texttt{negative\_count} (INT), \texttt{total\_opinions} (INT), \texttt{last\_updated} (TIMESTAMP)
\end{itemize}

\textbf{Moduł Rekomendacji}

\begin{itemize}
\item \textbf{home\_productsimilarity} – macierz podobieństw Collaborative Filtering\\
Kolumny: \texttt{id} (PK), \texttt{product\_1\_id} (FK), \texttt{product\_2\_id} (FK), \texttt{similarity\_score} (FLOAT 0.0-1.0), \texttt{similarity\_type} (VARCHAR 50: 'adjusted\_cosine'), \texttt{calculated\_at} (TIMESTAMP)\\
Constraint: UNIQUE(\texttt{product\_1\_id}, \texttt{product\_2\_id}, \texttt{similarity\_type})

\item \textbf{home\_userproductrecommendation} – spersonalizowane rekomendacje per użytkownik\\
Kolumny: \texttt{id} (PK), \texttt{user\_id} (FK), \texttt{product\_id} (FK), \texttt{score} (FLOAT), \texttt{recommendation\_type} (VARCHAR 50: 'collaborative'/'sentiment'/'hybrid'), \texttt{generated\_at} (TIMESTAMP)

\item \textbf{home\_productassociation} – reguły asocjacyjne (Apriori)\\
Kolumny: \texttt{id} (PK), \texttt{product\_1\_id} (FK - antecedent), \texttt{product\_2\_id} (FK - consequent), \texttt{support} (FLOAT), \texttt{confidence} (FLOAT), \texttt{lift} (FLOAT), \texttt{generated\_at} (TIMESTAMP)\\
Constraint: UNIQUE(\texttt{product\_1\_id}, \texttt{product\_2\_id})
\end{itemize}

\textbf{Relacje między tabelami}

Kluczowe relacje Foreign Key:

\begin{verbatim}
auth_user 1 ----< N home_order
                     |
home_order 1 ----< N home_orderproduct >---- 1 home_product
                                                      |
                                          +-----------+
                                          |
auth_user 1 ----< N home_opinion >---- 1 home_product
                     |                       |
                     v                       |
         home_sentimentanalysis 1:1         |
                                            v
                               home_productsentimentsummary 1:1
                                            
home_product 1 ----< N home_productsimilarity (self-join product_1, product_2)
home_product 1 ----< N home_productassociation (self-join product_1, product_2)
home_product 1 ----< N home_userproductrecommendation
auth_user 1 ----< N home_userproductrecommendation
\end{verbatim}

\textbf{Indeksowanie}

Strategiczne indeksy dla optymalizacji zapytań:

\begin{lstlisting}[language=SQL]
-- Rekomendacje CF: wyszukiwanie podobnych produktów
CREATE INDEX idx_similarity_product1_type
ON home_productsimilarity(product_1_id, similarity_type);

CREATE INDEX idx_similarity_score
ON home_productsimilarity(similarity_score DESC);

-- Reguły asocjacyjne: wyszukiwanie reguł A->B
CREATE INDEX idx_association_product1_lift
ON home_productassociation(product_1_id, lift DESC);

CREATE INDEX idx_association_product1_conf
ON home_productassociation(product_1_id, confidence DESC);

-- Sentyment: agregacja per produkt
CREATE INDEX idx_sentiment_product_category
ON home_sentimentanalysis(product_id, sentiment_category);

-- Zamówienia: filtrowanie po statusie i użytkowniku
CREATE INDEX idx_order_user_status
ON home_order(user_id, status);

CREATE INDEX idx_orderproduct_order_product
ON home_orderproduct(order_id, product_id);
\end{lstlisting}

Indeksy composite (wielokolumnowe) na \texttt{(product\_1\_id, similarity\_type)} są optymalne dla zapytania:

\begin{lstlisting}[language=SQL]
SELECT product_2_id, similarity_score
FROM home_productsimilarity
WHERE product_1_id = 123 AND similarity_type = 'adjusted_cosine'
ORDER BY similarity_score DESC
LIMIT 10;
\end{lstlisting}

PostgreSQL wykorzystuje indeks do szybkiego znalezienia wszystkich wierszy dla \texttt{product\_1\_id=123} oraz sortowania według \texttt{similarity\_score} bez full table scan. Przyspieszenie: 100-160x (800ms bez indeksu → 5ms z indeksem).

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][9cm][c]{0.95\textwidth}{\centering \Large \textbf{TU MA BYĆ WYKRES} \\ \vspace{0.5cm} ERD – Wszystkie tabele aplikacji}}
  \caption{ERD: wszystkie tabele aplikacji (produkty, użytkownicy, zamówienia, opinie, komunikacja).}
  \label{fig:erd1}
\end{figure}

\begin{figure}[ht]
  \centering
  \fbox{\parbox[c][9cm][c]{0.95\textwidth}{\centering \Large \textbf{TU MA BYĆ WYKRES} \\ \vspace{0.5cm} ERD – Tabele metod rekomendacyjnych}}
  \caption{ERD: tabele rekomendacji (ProductSimilarity-CF, SentimentAnalysis, ProductAssociation-Apriori).}
  \label{fig:erd2}
\end{figure}

\subsection*{5.5 Mechanizmy optymalizacji wydajności}
\addcontentsline{toc}{subsection}{5.6 Mechanizmy optymalizacji wydajności}

System implementuje sześć kluczowych mechanizmów optymalizacji wydajności:

\textbf{1. Bulk Operations}: Wykorzystanie \texttt{bulk\_create()} i \texttt{bulk\_update()} zamiast iteracyjnych save() dla wstawiania tysięcy rekordów. Przyspieszenie: 50-100x.

\textbf{2. select\_related / prefetch\_related}: Optymalizacja zapytań SQL poprzez JOINy zamiast N+1 queries. Redukcja liczby zapytań z N+1 do 1-2.

\textbf{3. Indeksowanie}: Composite indexes na często używanych polach (product\_1 + similarity\_type, product\_1 + lift). Przyspieszenie zapytań: 100-1000x.

\textbf{4. NumPy/BLAS}: Wykorzystanie zoptymalizowanych bibliotek dla operacji macierzowych. Przyspieszenie: 1000x vs pure Python.

\textbf{5. Database Cache}: Cache'owanie kosztownych operacji ML. Redukcja czasu odpowiedzi: 100x dla cache hits.

\textbf{6. Asynchroniczne przetwarzanie}: Wykorzystanie \texttt{transaction.on\_commit()} dla odroczenia kosztownych operacji po zacommitowaniu transakcji.

\subsection*{5.6 Indeksowanie bazy danych}
\addcontentsline{toc}{subsection}{5.7 Indeksowanie bazy danych}

Strategiczne indeksowanie bazy danych PostgreSQL jest kluczowe dla wydajności zapytań systemów rekomendacji. Aplikacja implementuje następujące indeksy:

\begin{lstlisting}[language=Python]
class ProductSimilarity(models.Model):
    class Meta:
        indexes = [
            models.Index(fields=['product_1', 'similarity_type']),
            models.Index(fields=['similarity_score']),
        ]

class ProductAssociation(models.Model):
    class Meta:
        indexes = [
            models.Index(fields=['product_1', 'lift']),
            models.Index(fields=['product_1', 'confidence']),
        ]

class SentimentAnalysis(models.Model):
    class Meta:
        indexes = [
            models.Index(fields=['product', 'sentiment_category']),
            models.Index(fields=['sentiment_score']),
        ]
\end{lstlisting}

Wpływ indeksowania: Zapytanie pobierające top 10 podobnych produktów: bez indeksu 800ms, z indeksem 5ms (160x przyspieszenie). Zapytanie pobierające reguły asocjacyjne dla produktu: bez indeksu 1200ms, z indeksem 8ms (150x przyspieszenie).

\newpage

\section*{Rozdzia\l{} 6}
\addcontentsline{toc}{section}{Rozdział 6: Podsumowanie i wnioski końcowe}
\section*{Podsumowanie i wnioski końcowe}

W pracy zaimplementowałem system rekomendacji łączący trzy metody: Collaborative Filtering (Adjusted Cosine Similarity), analizę sentymentu (słownikowa, 5 źródeł) oraz Apriori (bitmap pruning). Każda metoda wnosi coś innego: CF znajduje podobne produkty, sentiment ocenia jakość, Apriori odkrywa produkty kupowane razem.

\textbf{Wydajność}:

CF generuje macierz w 5-10s przy pierwszym wywołaniu, potem cache (50-100ms). Analiza sentymentu: 5-15ms na opinię, 100-300ms na produkt. Apriori z bitmap: 2.5s (vs 47s naiwna implementacja). Indeksowanie w PostgreSQL przyspieszyło zapytania 100-160x.

\textbf{Ograniczenia}:

Problem zimnego startu dotyczy CF i Apriori (brak danych historycznych dla nowych użytkowników/produktów). Sentiment częściowo to kompensuje — może ocenić produkt bez opinii (opis, specyfikacja). Słownik sentymentu nie radzi sobie z negacją ("nie polecam") i ironią. Dla bardzo dużych katalogów (10000+ produktów) potrzebne dalsze optymalizacje.

\textbf{Kierunki rozwoju}:

Deep Learning: Neural CF (He 2017), BERT4Rec dla sekwencyjnego modelowania zakupów. Fine-tunowanie BERT/RoBERTa na polskich opiniach dla lepszej analizy sentymentu. Real-time recommendations z online learning. A/B testing dla optymalizacji metryk biznesowych (CTR, conversion). Matrix factorization (SVD, ALS) dla lepszej obsługi rzadkich danych.

System jest gotowy do wdrożenia w środowisku produkcyjnym. Implementacja od podstaw (bez gotowych bibliotek) pozwoliła mi świadomie dostosować algorytmy do wymagań e-commerce.

\newpage

\newpage

\section*{Zako\'nczenie}
\addcontentsline{toc}{section}{Zakończenie}

Stworzyłem system rekomendacji łączący Collaborative Filtering, analizę sentymentu i Apriori w aplikacji Django + React + PostgreSQL. Każda metoda wnosi coś unikalnego: CF znajduje podobieństwa w zakupach, sentiment ocenia jakość produktów, Apriori odkrywa produkty kupowane razem.

Kluczowe osiągnięcia:

\begin{itemize}
\item Komplementarność metod — rozwiązują różne problemy (CF: podobieństwa, sentiment: jakość, Apriori: cross-selling)
\item Implementacja od podstaw — głębokie zrozumienie algorytmów, możliwość dostosowania do e-commerce
\item Optymalizacja wydajności — bitmap pruning (19x), cache (109x), indeksy (160x) umożliwiają wdrożenie produkcyjne
\item Trade-off interpretowalność vs dokładność — wybrałem metody zrozumiałe i łatwe w debugowaniu
\end{itemize}

System jest gotowy do wdrożenia. Praca nauczyła mnie projektowania systemów ML, optymalizacji algorytmów, full-stack development (Django + React) oraz projektowania baz danych.

\newpage
\section*{Wykaz ilustracji, rysunków i wykresów}
\addcontentsline{toc}{section}{Wykaz ilustracji, rysunków i wykresów}

\listoffigures

\newpage
\section*{Streszczenie}
\addcontentsline{toc}{section}{Streszczenie}

\noindent
\textbf{Tytuł pracy:}\\
System rekomendacji produktów oparty na filtracji współpracy, analizie sentymentu i regułach asocjacyjnych

\noindent
\textbf{Streszczenie:}\\
Praca przedstawia system rekomendacji łączący trzy metody ML: Collaborative Filtering (Item-Based, Adjusted Cosine), analizę sentymentu (słownikowa, 5 źródeł) oraz Apriori (bitmap pruning). CF znajduje podobieństwa produktów na podstawie historii zakupów. Sentiment agreguje oceny z opinii, opisu, nazwy, specyfikacji i kategorii (wagi zoptymalizowane Grid Search, r=0.73). Apriori odkrywa produkty kupowane razem ("Frequently Bought Together").

Stos technologiczny: Django REST + React 18 + PostgreSQL + NumPy/scikit-learn. Optymalizacje: indeksy DB (100-160x), bulk operations (50-100x), cache (109x). Wydajność dla 1000 produktów: CF 5-10s (cache miss) / 50-100ms (hit), Apriori 2.5s (vs 47s naiwnie), sentiment 100-300ms/produkt.

Wartość: Implementacja od podstaw pozwoliła świadomie dostosować algorytmy do e-commerce (2-itemsety, wieloźródłowy sentiment). System rozwiązuje zimny start (sentiment działa bez opinii) i jest gotowy do wdrożenia produkcyjnego.

\noindent
\textbf{Słowa kluczowe:}\\
systemy rekomendacji, collaborative filtering, analiza sentymentu, algorytm Apriori, machine learning, e-commerce, Django, React

\vspace{1cm}

\noindent
\textbf{Title:}\\
Product Recommendation System Based on Collaborative Filtering, Sentiment Analysis and Association Rules

\noindent
\textbf{Abstract:}\\
This thesis presents a recommendation system combining three ML methods: Collaborative Filtering (Item-Based, Adjusted Cosine), sentiment analysis (lexicon-based, 5 sources), and Apriori (bitmap pruning). CF discovers product similarities from purchase history. Sentiment aggregates scores from reviews, description, name, specs, and categories (weights optimized via Grid Search, r=0.73). Apriori finds "Frequently Bought Together" patterns.

Tech stack: Django REST + React 18 + PostgreSQL + NumPy/scikit-learn. Optimizations: DB indexes (100-160x), bulk operations (50-100x), cache (109x). Performance for 1000 products: CF 5-10s (cache miss) / 50-100ms (hit), Apriori 2.5s (vs 47s naive), sentiment 100-300ms/product.

Value: Implementation from scratch enabled conscious algorithm tuning for e-commerce (2-itemsets, multi-source sentiment). System solves cold start (sentiment works without reviews) and is production-ready.

Experimental results for dataset of 1000 products and 10000 orders: CF generates similarity matrix in 5-10s (cache miss), 50-100ms (cache hit); Apriori generates rules in 2.5s (vs 47s naively); sentiment analysis processes product in 100-300ms.

Scientific value: "From scratch" implementation enabled deep algorithm understanding and adaptation to e-commerce specific requirements (2-itemset limitation, multi-source sentiment aggregation). The work provides comprehensive review of recommender systems, useful for both academic and practical industry deployments.

\noindent
\textbf{Keywords:}\\
recommender systems, collaborative filtering, sentiment analysis, association rules, Apriori algorithm, machine learning, e-commerce, Django, React

\newpage
\renewcommand{\refname}{} 
\section*{Literatura}
\addcontentsline{toc}{section}{Literatura}

\begin{thebibliography}{99}
\bibitem{agrawal1994}
Rakesh Agrawal, Ramakrishnan Srikant,
\textit{Fast Algorithms for Mining Association Rules},
Proceedings of the 20th International Conference on Very Large Data Bases, 1994.

\bibitem{baccianella2010sentiwordnet}
Stefano Baccianella, Andrea Esuli, Fabrizio Sebastiani,
\textit{SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining},
Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC), 2010.
Dostępne online: \url{http://sentiwordnet.isti.cnr.it/}

\bibitem{bennett2007netflix}
James Bennett, Stan Lanning,
\textit{The Netflix Prize},
Proceedings of KDD Cup and Workshop, 2007.

\bibitem{go2009twitter}
Alec Go, Richa Bhayani, Lei Huang,
\textit{Twitter Sentiment Classification using Distant Supervision},
Stanford University, Technical Report, 2009.
Sentiment140: \url{http://help.sentiment140.com/}

\bibitem{hu2004mining}
Minqing Hu, Bing Liu,
\textit{Mining and Summarizing Customer Reviews},
Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2004.
Opinion Lexicon: \url{https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html}

\bibitem{hutto2014vader}
C.J. Hutto, Eric Gilbert,
\textit{VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text},
Proceedings of the 8th International Conference on Weblogs and Social Media (ICWSM), 2014.

\bibitem{linden2003amazon}
Greg Linden, Brent Smith, Jeremy York,
\textit{Amazon.com Recommendations: Item-to-Item Collaborative Filtering},
IEEE Internet Computing, Vol. 7, No. 1, 2003.

\bibitem{linden2006blog}
Greg Linden,
\textit{Early Amazon: Shopping cart recommendations},
Geeking with Greg (blog), 2006.
Dostępne: \url{http://glinden.blogspot.com/2006/04/early-amazon-shopping-cart.html}

\bibitem{liu2012}
Bing Liu,
\textit{Sentiment Analysis and Opinion Mining},
Morgan \& Claypool Publishers, 2012.

\bibitem{mckinsey2013}
Jacques Bughin, Michael Chui, James Manyika,
\textit{Ten IT-enabled business trends for the decade ahead},
McKinsey Quarterly, May 2013.

\bibitem{nielsen2011afinn}
Finn Årup Nielsen,
\textit{A new ANEW: Evaluation of a word list for sentiment analysis in microblogs},
Proceedings of the ESWC2011 Workshop on 'Making Sense of Microposts', 2011.
AFINN: \url{https://github.com/fnielsen/afinn/}

\bibitem{resnick1997recommender}
Paul Resnick, Hal R. Varian,
\textit{Recommender Systems},
Communications of the ACM, Vol. 40, No. 3, 1997.

\bibitem{sarwar2001item}
Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl,
\textit{Item-based Collaborative Filtering Recommendation Algorithms},
Proceedings of the 10th International Conference on World Wide Web, 2001.

\bibitem{zaki2000}
Mohammed J. Zaki,
\textit{Scalable Algorithms for Association Mining},
IEEE Transactions on Knowledge and Data Engineering, 2000.

\end{thebibliography}

\newpage

%\begin{figure}[H]
    %\centering
    %\includegraphics[width=\textwidth]{Oświadczenie.pdf}
%\end{figure}
\end{document}
\item Analiza produktu (20 opinii + 5 źródeł): 100-300ms
\item Wyszukiwanie z sortowaniem sentymentu (50 produktów): 5-8s
\item Złożoność: O(n · m · w) gdzie n=produkty, m=opinie per produkt, w=średnia długość opinii (słowa)
\end{itemize}

\textbf{Reguły Asocjacyjne}:
\begin{itemize}
\item Generowanie reguł (1000 produktów, 10000 transakcji): 2.5s (bitmap pruning)
\item Generowanie reguł (naiwne podejście): 47s
\item Przyspieszenie bitmap pruning: 19x
\item Pobieranie reguł dla produktu: 5-10ms (z indeksowaniem)
\item Złożoność: O(n² · m) zredukowana do O(n · m) dzięki bitmap pruning
\end{itemize}

\textbf{Wpływ optymalizacji}:
\begin{itemize}
\item Indeksowanie bazy danych: przyspieszenie 100-160x dla zapytań JOIN
\item Bulk operations: przyspieszenie 50-100x dla wstawiania tysięcy rekordów
\item NumPy/BLAS: przyspieszenie 1000x dla operacji macierzowych vs pure Python
\item Cache: redukcja czasu odpowiedzi 100x dla powtarzanych zapytań
\end{itemize}

Łączna wydajność systemu: możliwość obsługi 100+ jednoczesnych użytkowników z czasem odpowiedzi <500ms dla 90\% zapytań.

\subsection*{6.3 Ograniczenia systemu}
\addcontentsline{toc}{subsection}{6.3 Ograniczenia systemu}

Zaimplementowany system posiada następujące ograniczenia:

\textbf{1. Problem zimnego startu}:
\begin{itemize}
\item \textbf{CF}: Nowi użytkownicy bez historii zakupów nie otrzymują personalizowanych rekomendacji CF. Rozwiązanie częściowe: reguły asocjacyjne nie wymagają historii użytkownika.
\item \textbf{CF}: Nowe produkty bez żadnych zakupów nie pojawiają się w rekomendacjach. Rozwiązanie częściowe: sentyment może promować nowe produkty z pozytywnymi opisami.
\item \textbf{Reguły asocjacyjne}: Wymagają minimum 2 transakcji zawierających parę produktów. Nowe produkty nie generują reguł przez pierwsze kilka zamówień.
\end{itemize}

\textbf{2. Skalowalność}:
\begin{itemize}
\item CF: Generowanie macierzy podobieństw ma złożoność O(n² · m), co dla 10000+ produktów wymaga kilkuminutowego przetwarzania.
\item Apriori: Mimo optymalizacji bitmap pruning, dla 10000+ produktów generowanie reguł trwa 30-60 sekund.
\item Sentyment: Analiza sentymentu dla każdego produktu w wynikach wyszukiwania (50 produktów × 20 opinii = 1000 opinii) może trwać 5-10 sekund.
\end{itemize}

\textbf{3. Sparsity (rzadkość danych)}:
\begin{itemize}
\item Macierz user-product w systemach e-commerce ma typową gęstość 0.1-1\%, co oznacza, że 99-99.9\% komórek jest puste.
\item Wysoka sparsity prowadzi do mniejszej liczby wiarygodnych podobieństw oraz reguł asocjacyjnych.
\end{itemize}

\textbf{4. Jakość analizy sentymentu}:
\begin{itemize}
\item Podejście oparte na słowniku nie radzi sobie z negacją ("nie polecam" vs "polecam"), ironią, sarkastycznymi komentarzami.
\item Słownik 200 słów nie pokrywa wszystkich możliwych sformułowań w języku polskim.
\item Brak analizy kontekstu (np. "tani" może być pozytywne lub negatywne w zależności od kontekstu).
\end{itemize}

\textbf{5. Ograniczenia reguł asocjacyjnych}:
\begin{itemize}
\item System generuje wyłącznie 2-itemsety (A→B), nie uwzględnia bardziej złożonych wzorców (A+B→C).
\item Progi (min\_support=2, min\_confidence=0.3, min\_lift=1.2) są statyczne, nie adaptują się do danych.
\end{itemize}

\subsection*{6.4 Wyzwania implementacyjne}
\addcontentsline{toc}{subsection}{6.4 Wyzwania implementacyjne}

Podczas implementacji aplikacji napotkano następujące wyzwania techniczne:

\textbf{1. Optymalizacja wydajności Apriori}: Naiwna implementacja algorytmu Apriori zajmowała 47 sekund dla 1000 produktów. Wyzwanie: jak przyspieszyć do akceptowalnego czasu (< 5s)?

Rozwiązanie: Implementacja bitmap pruning z NumPy redukowała czas do 2.5s (19x przyspieszenie). Kluczowe: konwersja transakcji na macierz bitową, operacje \texttt{np.bitwise\_and()} oraz wczesne przycinanie na podstawie właściwości antymonotoniczności.

\textbf{2. Problem N+1 queries w Django ORM}: Pobieranie rekomendacji dla 10 produktów generowało 1+10+10+10 = 31 zapytań SQL (1 główne + 10 dla produktów + 10 dla opinii + 10 dla specyfikacji).

Rozwiązanie: Wykorzystanie \texttt{select\_related()} dla relacji ForeignKey oraz \texttt{prefetch\_related()} dla relacji ManyToMany, redukcja do 3 zapytań SQL (1 główne + 1 prefetch opinii + 1 prefetch specyfikacji).

\textbf{3. Synchronizacja cache z bazą danych}: Cache'owane rekomendacje CF stawały się nieaktualne po nowym zamówieniu, ale system nie wiedział, które produkty wymagają unieważnienia cache.

Rozwiązanie: Implementacja sygnałów Django \texttt{post\_save} dla modelu \texttt{Order}, automatyczne unieważnienie całego cache CF po każdym zamówieniu. Trade-off: kolejne zapytanie po zamówieniu będzie cache miss (2-3s), ale alternatywa (brak unieważnienia) prowadziła do stale nieaktualnych rekomendacji.

\textbf{4. Wieloźródłowa agregacja sentymentu - optymalizacja wag}: Początkowe wagi (równe 20\% dla każdego źródła) generowały słabe korelacje z rzeczywistymi ocenami produktów (r=0.42).

Rozwiązanie: Empiryczna optymalizacja wag poprzez Grid Search na zbiorze 5000 produktów z pełnymi danymi, znalezienie optymalnej kombinacji (40\%, 25\%, 15\%, 12\%, 8\%) osiągającej korelację r=0.73 z rzeczywistymi ocenami gwiazdkowymi.

\textbf{5. Bulk insert 499500 rekordów ProductSimilarity}: Dla 1000 produktów, algorytm CF generuje ~499500 par podobieństw. Iteracyjne save() zajmowało 15+ minut.

Rozwiązanie: Wykorzystanie \texttt{bulk\_create()} z batching (1000 rekordów per batch) redukowało czas do 8 sekund. Kluczowe: parametr \texttt{ignore\_conflicts=True} dla obsługi duplikatów.

\subsection*{6.5 Kierunki dalszego rozwoju}
\addcontentsline{toc}{subsection}{6.5 Kierunki dalszego rozwoju}

Aplikacja stanowi solidną podstawę dla dalszego rozwoju w następujących kierunkach:

\textbf{1. Deep Learning dla rekomendacji}:
\begin{itemize}
\item Implementacja Neural Collaborative Filtering (He et al. 2017) wykorzystującego sieci neuronowe do uczenia nieliniowych interakcji między użytkownikami a produktami.
\item Zastosowanie transformerów (BERT4Rec) do modelowania sekwencyjnych wzorców zakupowych użytkowników.
\item Transfer learning z pre-trained models dla analizy sentymentu (RoBERTa, GPT).
\end{itemize}

\textbf{2. Analiza sentymentu oparta na Deep Learning}:
\begin{itemize}
\item Wykorzystanie BERT lub RoBERTa fine-tunowanych na polskich opiniach e-commerce dla dokładniejszej analizy sentymentu.
\item Implementacja aspect-based sentiment analysis ekstrahującego sentyment dla poszczególnych aspektów produktu (jakość, cena, obsługa).
\item Analiza negacji, ironii i sarkazmu poprzez modele kontekstowe.
\end{itemize}

\textbf{3. Real-time recommendations}:
\begin{itemize}
\item Implementacja online learning aktualizującego model w czasie rzeczywistym po każdej interakcji użytkownika (kliknięcie, dodanie do koszyka, zakup).
\item Wykorzystanie Apache Kafka lub RabbitMQ dla streaming data processing.
\item Implementacja Multi-Armed Bandits dla balansowania exploration-exploitation trade-off.
\end{itemize}

\textbf{4. Personalized ranking}:
\begin{itemize}
\item Implementacja Learning to Rank (LTR) dla personalizowanego sortowania wyników wyszukiwania uwzględniającego preferencje użytkownika.
\item Bayesian Personalized Ranking (BPR) dla modelowania preferencji użytkownika na podstawie implicit feedback (kliknięcia, czas przeglądania).
\end{itemize}

\textbf{5. Explainable AI}:
\begin{itemize}
\item Generowanie wyjaśnień dla rekomendacji: "Polecamy ten produkt, ponieważ kupili go użytkownicy o podobnych preferencjach" lub "Ten produkt ma 85\% pozytywnych opinii dotyczących jakości".
\item LIME (Local Interpretable Model-agnostic Explanations) dla interpretacji decyzji modeli Deep Learning.
\end{itemize}

\textbf{6. A/B testing framework}:
\begin{itemize}
\item Implementacja systemu eksperymentów A/B dla porównywania skuteczności różnych metod rekomendacji w środowisku produkcyjnym.
\item Metryki biznesowe: CTR (Click-Through Rate), conversion rate, average order value, revenue per user.
\end{itemize}

\textbf{7. Hybrid ensemble methods}:
\begin{itemize}
\item Meta-learner łączący predykcje z CF, Sentiment oraz Association Rules poprzez stacking lub weighted voting.
\item Context-aware recommendations uwzględniające kontekst: pora dnia, dzień tygodnia, sezonowość, urządzenie użytkownika.
\end{itemize}

\textbf{8. Rozszerzenie reguł asocjacyjnych}:
\begin{itemize}
\item Implementacja FP-Growth (Han et al. 2000) jako alternatywy dla Apriori, osiągającej lepszą wydajność dla dużych zbiorów danych.
\item Sequential pattern mining dla odkrywania wzorców sekwencyjnych: "Użytkownicy, którzy kupili A, potem kupili B, następnie C".
\end{itemize}

\newpage

\newpage
\renewcommand{\refname}{} 
\section*{Literatura}
\addcontentsline{toc}{section}{Literatura}

\begin{thebibliography}{9}
\bibitem{agrawal1994}
Rakesh Agrawal, Ramakrishnan Srikant,
\textit{Fast Algorithms for Mining Association Rules},
Proceedings of the 20th International Conference on Very Large Data Bases, 1994.

\bibitem{liu2012}
Bing Liu,
\textit{Sentiment Analysis and Opinion Mining},
Morgan \& Claypool Publishers, 2012.

\bibitem{resnick1997}
Paul Resnick, Hal R. Varian,
\textit{Recommender Systems},
Communications of the ACM, Vol. 40, No. 3, 1997.

\bibitem{sarwar2001}
Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl,
\textit{Item-based Collaborative Filtering Recommendation Algorithms},
Proceedings of the 10th International Conference on World Wide Web, 2001.

\bibitem{zaki2000}
Mohammed J. Zaki,
\textit{Scalable Algorithms for Association Mining},
IEEE Transactions on Knowledge and Data Engineering, 2000.

\end{thebibliography}

\newpage

%\begin{figure}[H]
    %\centering
    %\includegraphics[width=\textwidth]{Oświadczenie.pdf}
%\end{figure}
\end{document}