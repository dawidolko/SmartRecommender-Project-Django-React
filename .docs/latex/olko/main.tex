% filepath: /SmartRecommender-Project-Django-React/.docs/latex/olko/main.tex

% Czcionka, wielkość, rozmiar
\documentclass[a4paper,12pt,twoside]{article}

% Zaimportowane zależności
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amsmath, amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{url}
\usepackage{titlesec}
\usepackage{tocloft}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{placeins}
\usepackage{float}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}

% Marginesy zgodnie z wytycznymi
\geometry{left=3.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% Numeracja stron u dołu, wyrównana do zewnętrznego marginesu
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[LE,RO]{\thepage}
\renewcommand{\headrulewidth}{0pt}

% Interlinia 1,5
\onehalfspacing

% Wcięcia akapitów
\setlength{\parindent}{1cm}

% Tytuły - czcionka pogrubiona
\titleformat{\section}[block]{\bfseries\Large\raggedright}{}{1em}{}
\titleformat{\subsection}[block]{\bfseries\large\raggedright}{}{1em}{}

% Zmniejszenie odstępów w spisie treści
\setlength{\cftbeforesecskip}{3pt}
\setlength{\cftbeforesubsecskip}{2pt}

% Zależności do fragmentów kodu JavaScript
\lstdefinelanguage{JavaScript}{
  keywords={const, let, var, function, return, if, else, for, while, switch, case, break, default, true, false, null, undefined, typeof, new, this, class, extends, import, export, from, async, await, try, catch, throw, finally},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={document, window, console, Math, Array, Object, String, Number, Boolean, JSON},
  ndkeywordstyle=\color{purple}\bfseries,
  sensitive=true,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  morestring=[b]',
  morestring=[b]''
}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red}
}

% % Zależności do fragmentów pseudokodu
\lstdefinelanguage{Pseudocode}{
  morekeywords={FUNKCJA, ZWROC, DLA, KAZDEGO, KAZDEJ, W, JEZELI, WTEDY, INACZEJ, KONIEC, LUB, ORAZ, NIE, DOPOKI, WYKONUJ, GDZIE, OD, DO, KROK, AND, function, return, for, in, if, then, else, or, and, not, while, where, from, to, step, end},
  sensitive=false,
  morecomment=[l]{//},
  morestring=[b]"
}

\lstdefinestyle{pseudocode}{
  language=Pseudocode,
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  breaklines=true,
  xleftmargin=2em,
  framexleftmargin=1.5em,
  literate={ą}{{\k{a}}}1 {ć}{{\'c}}1 {ę}{{\k{e}}}1 {ł}{{\l{}}}1 {ń}{{\'n}}1 {ó}{{\'o}}1 {ś}{{\'s}}1 {ź}{{\'z}}1 {ż}{{\.z}}1
           {Ą}{{\k{A}}}1 {Ć}{{\'C}}1 {Ę}{{\k{E}}}1 {Ł}{{\L{}}}1 {Ń}{{\'N}}1 {Ó}{{\'O}}1 {Ś}{{\'S}}1 {Ź}{{\'Z}}1 {Ż}{{\.Z}}1
}

% Zmiana nazwy "Listing" na "Algorytm"
\renewcommand{\lstlistingname}{Algorytm}

\begin{document}

\begin{titlepage}

\begin{minipage}{0.7\textwidth}
    {\large\bf UNIWERSYTET RZESZOWSKI}\\
    {\large\bf Wydział Nauk Ścisłych i Technicznych}
\end{minipage}
\hfill
\begin{minipage}{0.25\textwidth}
    \centering
    \includegraphics[width=8em]{logoUR.jpg}
\end{minipage}

\vspace{3cm}

\begin{center}
    {\Large Dawid Olko} \\
    {\large nr albumu: 125148} \\
    {\large Kierunek: Informatyka}
\end{center}

\vspace{2cm}

\begin{center}
    {\LARGE\bf 
    \begin{tabular}{@{}c@{}}
    System rekomendacji produktów oparty na\\
    filtracji współpracy, analizie sentymentu\\
    i regułach asocjacyjnych
    \end{tabular}}
\end{center}

\vspace{1.5cm}

\begin{center}
    {\large Praca inżynierska}
\end{center}

\vspace{1.5cm}

\begin{flushright}
    {\large Praca wykonana pod kierunkiem}\\
    {\large dr inż. Piotra Grochowalskiego}
\end{flushright}

\vspace{3cm}

\begin{center}
    {\large Rzesz\'ow, 2026}
\end{center}

\end{titlepage}

\newpage
% Spis treści
\tableofcontents


\newpage
\section*{Wstęp}
\addcontentsline{toc}{section}{Wstęp}

Nowoczesne platformy e-commerce oferują tysiące lub dziesiątki tysięcy produktów, co stanowi istotne wyzwanie zarówno dla klientów, jak i właścicieli sklepów internetowych. Użytkownik poszukujący smartfona staje przed wyborem setek modeli, w przypadku laptopów sytuacja wygląda podobnie. Bez wsparcia inteligentnych systemów rekomendacyjnych proces zakupowy staje się czasochłonny i frustrujący, co często prowadzi do rezygnacji z zakupu. Z perspektywy biznesowej oznacza to utratę potencjalnych klientów oraz sytuacje, w których nabywcy nie odkrywają produktów optymalnie dopasowanych do ich potrzeb.

Systemy rekomendacyjne stanowią rozwiązanie tego problemu poprzez automatyczną analizę historii zakupów, opinii oraz zachowań użytkowników w celu proponowania produktów o najwyższej wartości dla konkretnego klienta.

\subsection*{Cel pracy}

Celem niniejszej pracy jest zaprojektowanie, implementacja oraz analiza kompletnego systemu e-commerce wyposażonego w mechanizmy rekomendacji produktów. Aplikacja została opracowana od podstaw we współpracy dwuosobowej, w ramach której części frontendu, backendu oraz bazy danych zostały zrealizowane wspólnie, natomiast metody rekomendacyjne były implementowane przez każdego z osobna. Zaimplementowano łącznie
sześć różnych metod rekomendacyjnych, niniejsza praca koncentruje się na trzech spośród nich: Collaborative Filtering, analizie sentymentu oraz regułach asocjacyjnych. Mechanizmy rekomendacyjne zostały zaprojektowane i zaimplementowane samodzielnie na podstawie literatury naukowej, bez wykorzystania gotowych bibliotek rekomendacyjnych, co umożliwiło pełną kontrolę nad logiką algorytmów oraz ich świadome dostosowanie do specyfiki branży handlu elektronicznego.

\subsection*{Zakres pracy}

\noindent
Zakres funkcjonalny systemu obejmuje:

\noindent
\textbf{Implementację trzech metod rekomendacyjnych:}
\begin{itemize}
\item Collaborative Filtering w wariancie Item-Based z metryką Adjusted Cosine Similarity \cite{sarwar2001item} — metoda analizuje wzorce zakupowe użytkowników w celu identyfikacji produktów podobnych do wcześniej nabytych,
\item Analizę sentymentu opartą na podejściu słownikowym \cite{liu2012} — metoda agreguje ocenę jakości produktu z pięciu źródeł tekstowych (opinie, opis, nazwa, specyfikacje, kategorie), rozwiązując problem zimnego startu dla produktów bez historii opinii,
\item Reguły asocjacyjne wykorzystujące algorytm Apriori \cite{agrawal1994} — metoda odkrywa wzorce współwystępowania produktów w koszyku zakupowym, wspierając strategie cross-sellingu.
\end{itemize}

\noindent
\textbf{Opracowanie kompletnej aplikacji webowej:}
\begin{itemize}
\item Backend oparty na Django REST Framework zapewniający API dla wszystkich funkcjonalności systemu,
\item Frontend w technologii React 18 oferujący responsywny interfejs użytkownika,
\item Baza danych PostgreSQL z odpowiednio zaprojektowanym schematem przechowującym dane produktów, użytkowników, zamówień oraz wyniki algorytmów rekomendacyjnych.
\end{itemize}

\newpage
\section*{Rozdzia\l{} 1}
\addcontentsline{toc}{section}{Rozdział 1: Teoretyczne podstawy systemów rekomendacyjnych}
\section*{Teoretyczne podstawy systemów rekomendacyjnych}

\subsection*{Historia i ewolucja systemów rekomendacyjnych}

Systemy rekomendacyjne powstały jako odpowiedź na problem wyboru spośród tysięcy produktów w sklepach internetowych. Rozwój tej dziedziny rozpoczął się w latach 90. XX wieku wraz z pojawieniem się pierwszych platform e-commerce. Wczesne zastosowania komercyjne systemów rekomendacji obejmowały m.in. mechanizm ,,klienci którzy kupili ten produkt, kupili również'' zastosowany przez Amazon.com, który analizował historię zakupów w celu sugerowania powiązanych produktów, co skutkowało znaczącym wzrostem sprzedaży krzyżowej (cross-selling) oraz poprawą doświadczenia użytkowników \cite{linden2003amazon}. Istotnym przełomem była również publikacja wprowadzająca metodę Item-Based Collaborative Filtering z metryką Adjusted Cosine Similarity \cite{sarwar2001item}, która zyskała szerokie zastosowanie w praktyce przemysłowej, szczególnie w platformach e-commerce o dużej liczbie produktów. Konkursy i inicjatywy badawcze, takie jak Netflix Prize w latach 2006-2009, w którym fundusz nagród wynosił około miliona dolarów dla zwycięzcy, znacząco przyspieszyły rozwój zaawansowanych technik rekomendacji \cite{bennett2007netflix}, przyciągając uwagę zarówno środowiska akademickiego, jak i przemysłowego. Obecnie systemy rekomendacyjne stanowią kluczowy element wiodących platform e-commerce (handlu elektronicznego) oraz serwisów VOD (Video on Demand - wideo na żądanie).

\subsection*{Klasyfikacja metod rekomendacyjnych}

\noindent
Istnieją trzy główne kategorie systemów rekomendacyjnych:

\textbf{Collaborative Filtering} — jedna z najpopularniejszych metod w systemach komercyjnych. Zakłada, że użytkownicy o podobnych preferencjach będą mieli podobne wybory w przyszłości. Istnieją dwa warianty: oparty na użytkownikach (User-Based, porównuje użytkowników) oraz oparty na produktach (Item-Based, porównuje produkty). Zalety: odkrywa nieoczywiste powiązania między produktami. Wady: problem zimnego startu (ang. cold start) dla nowych użytkowników i produktów, macierz danych jest zazwyczaj rzadka (stopień wypełnienia zależy od liczby produktów, użytkowników oraz częstotliwości transakcji).

\textbf{Content-Based Filtering} — analizuje cechy produktów i dopasowuje je do profilu użytkownika. Zalety: brak problemu zimnego startu dla nowych produktów. Wady: rekomenduje tylko podobne produkty, co może prowadzić do zjawiska tzw. filter bubble (bańki filtrującej).

\textbf{Metody Hybrydowe} — łączą różne podejścia rekomendacyjne w celu wykorzystania zalet poszczególnych metod oraz kompensacji ich wad. Przykładem może być połączenie Collaborative Filtering z analizą metadanych produktów oraz analizą treści tekstowych.

Systemy rekomendacyjne w e-commerce wykorzystują różne strategie sprzedażowe. Poniżej znajdują się kluczowe terminy stosowane w branży:

\textbf{Cross-selling (sprzedaż krzyżowa)} — strategia polegająca na proponowaniu produktów komplementarnych, czyli dopełniających zakup główny. Przykład: klient kupuje laptop, system proponuje mysz, torbę na laptop, podkładkę pod mysz. Celem jest zwiększenie wartości koszyka poprzez dodanie produktów powiązanych funkcjonalnie.

\textbf{Up-selling (sprzedaż wyższej wartości)} — strategia zachęcania klienta do zakupu droższego wariantu produktu lub wersji premium. Przykład: klient przegląda telefon za 2000 zł, system proponuje model za 2500 zł z lepszymi parametrami. Celem jest zwiększenie wartości pojedynczego zakupu, przy czym skuteczność tej strategii zależy od indywidualnych preferencji i możliwości finansowych użytkownika.

\textbf{Personalizacja} — dostosowanie treści i rekomendacji do indywidualnego profilu użytkownika na podstawie jego historii zakupów, przeglądanych produktów i zachowań. Przykład: dwóch użytkowników widzi różne zestawy produktów na stronie głównej. Celem jest zwiększenie trafności rekomendacji i konwersji.

\textbf{Cold start problem (problem zimnego startu)} — sytuacja występująca gdy nowy użytkownik lub produkt nie ma historii interakcji. Przykład: nowy użytkownik nie ma zamówień, więc Collaborative Filtering nie może efektywnie generować rekomendacji. Nowy produkt nie ma opinii, co utrudnia ocenę jego jakości. Rozwiązaniem tego problemu może być wykorzystanie metod opartych na analizie treści produktu, takich jak analiza sentymentu opisów, nazw i specyfikacji technicznych.

\textbf{Frequently Bought Together (często kupowane razem)} — rodzaj rekomendacji prezentujący produkty, które klienci regularnie kupują w tym samym koszyku. Przykład: laptop + mysz + podkładka pod mysz. Celem jest uproszczenie procesu zakupów i zwiększenie wartości koszyka.

\newpage
\section*{Rozdzia\l{} 2}
\addcontentsline{toc}{section}{Rozdział 2: Weryfikacja i analiza rozwiązań alternatywnych}
\section*{Weryfikacja i analiza rozwiązań alternatywnych}

W celu uzasadnienia sensowności tworzenia dedykowanego systemu rekomendacji przeprowadzono analizę trzech reprezentatywnych rozwiązań rynkowych. Celem weryfikacji było zidentyfikowanie ograniczeń istniejących narzędzi oraz określenie wymagań dla planowanej aplikacji e-commerce wykorzystującej trzy metody: Collaborative Filtering \cite{sarwar2001item}, analizę sentymentu \cite{liu2012} oraz reguły asocjacyjne \cite{agrawal1994}.

\subsection*{Amazon Personalize}

Amazon Personalize to zarządzana usługa AWS oferująca systemy rekomendacji oparte na algorytmach stosowanych w Amazon.com \cite{linden2003amazon}. System wykorzystuje deep learning (głębokie uczenie - wielowarstwowe sieci neuronowe) oraz collaborative filtering, oferując trzy typy rekomendacji: User Personalization (personalizacja użytkownika), Similar Items (podobne produkty) oraz Personalized Ranking (spersonalizowane rankowanie).

\textbf{Możliwości systemu:} Amazon Personalize oferuje automatyczne skalowanie infrastruktury dostosowujące się do obciążenia, co pozwala obsługiwać zarówno małe sklepy internetowe, jak i platformy o skali Amazon.com. System automatycznie przetwarza dane użytkowników (kliknięcia, zakupy, wyświetlenia produktów) i generuje modele predykcyjne bez konieczności ręcznej optymalizacji hiperparametrów. Platforma zapewnia integrację z pozostałymi usługami AWS poprzez SDK dostępne w językach Python, Java, JavaScript oraz .NET, co umożliwia szybkie wdrożenie w istniejących aplikacjach. System automatycznie aktualizuje modele w czasie rzeczywistym na podstawie nowych interakcji użytkowników, zapewniając aktualność rekomendacji.

\noindent
\textbf{Kluczowe ograniczenia w kontekście planowanego rozwiązania:}

\begin{itemize}
\item \textbf{Wysokie koszty operacyjne} - rozwiązania chmurowe wiążą się z regularnymi opłatami licencyjnymi, które mogą być znaczące dla małych i średnich platform e-commerce. Dla porównania, własna implementacja eliminuje te koszty przy zachowaniu kontroli nad funkcjonalnościami,
\item \textbf{Brak natywnej analizy sentymentu} - Amazon Personalize koncentruje się wyłącznie na collaborative filtering i nie oferuje analizy opinii produktów. Wieloźródłowa agregacja sentymentu (opinie + opis + nazwa + specyfikacje + kategorie) zastosowana w niniejszej pracy wymaga integracji z dodatkowymi usługami AWS lub samodzielnej implementacji,
\item \textbf{Uzależnienie od dostawcy} (ang. vendor lock-in) - głęboka integracja z ekosystemem AWS (S3, Lambda, EventBridge) oznacza, że migracja do innej platformy wymaga przepisania całej architektury systemu,
\item \textbf{Brak kontroli nad algorytmami} - system działa jako ,,czarna skrzynka''' (black box), uniemożliwiając dostosowanie logiki rekomendacji. Przykład: niemożliwe jest zaimplementowanie Adjusted Cosine Similarity z centrowaniem średniej dla eliminacji wartości progowej (bias) wynikającej z różnych skal zakupowych użytkowników (hurtownik vs konsument indywidualny),
\item \textbf{Wymóg dużych zbiorów danych} - według dokumentacji AWS, system wymaga minimum 25000 interakcji dla zapewnienia wysokiej jakości rekomendacji. Dla nowych platform (cold start - problem zimnego startu) jakość jest ograniczona w początkowym okresie działania.
\end{itemize}

\subsection*{Google Recommendations AI (Vertex AI)}

Google Recommendations AI to platforma GCP wykorzystująca deep learning oraz algorytmy wieloramiennych bandytów kontekstowych (ang. multi-armed contextual bandits). Algorytmy te dynamicznie balansują eksplorację (testowanie nowych produktów w celu poznania ich wartości) z eksploatacją (rekomendowanie produktów o udowodnionej skuteczności), co pozwala systemowi optymalizować rekomendacje w czasie rzeczywistym na podstawie feedbacku użytkowników. System oferuje zaawansowane rekomendacje dla e-commerce, VOD (Video on Demand - wideo na żądanie) oraz platform newsowych, z automatycznym wykrywaniem trendów i sezonowości.

\textbf{Możliwości systemu:} Platforma zapewnia automatyczne wykrywanie trendów sezonowych oraz reagowanie na zmiany w zachowaniach użytkowników bez konieczności ręcznej rekonfiguracji. System oferuje funkcję ,,Frequently Bought Together'' (często kupowane razem), która analizuje koszyki zakupowe w sposób podobny do algorytmu Apriori. Google Recommendations AI automatycznie optymalizuje parametry modeli poprzez mechanizmy AutoML, co eliminuje potrzebę ręcznego dostrajania hiperparametrów. Platforma oferuje zaawansowane możliwości personalizacji rekomendacji z uwzględnieniem kontekstu sesji użytkownika (urządzenie, lokalizacja, pora dnia), co może zwiększać współczynnik konwersji.

\noindent
\textbf{Kluczowe ograniczenia w kontekście planowanego rozwiązania:}

\begin{itemize}
\item \textbf{Model cenowy oparty na liczbie predykcji} - system rozlicza się według liczby wygenerowanych rekomendacji oraz ilości przetworzonych danych katalogowych, co może generować rosnące koszty wraz ze wzrostem ruchu użytkowników,
\item \textbf{Brak wieloźródłowej agregacji sentymentu} - system nie wspiera agregacji sentymentu z wielu źródeł tekstowych (opinie, opis produktu, nazwa, specyfikacje, kategorie) jak w planowanym rozwiązaniu,
\item \textbf{Wymóg bardzo dużych zbiorów danych} - rozwiązanie zaprojektowane dla platform o skali YouTube, co czyni je nadmiarowo złożonym dla małych sklepów internetowych,
\item \textbf{Brak interpretowalności} - głęboka ,,black box''', gdzie nawet administratorzy z dostępem do Vertex AI nie mogą zobaczyć wag embeddings (reprezentacji wektorowych) ani logiki sieci neuronowej, co uniemożliwia debugowanie i optymalizację.
\end{itemize}

\subsection*{Apache Mahout}

Apache Mahout to otwartoźródłowy framework (ang. open-source framework) implementujący klasyczne algorytmy collaborative filtering \cite{sarwar2001item} oraz faktoryzację macierzy (ang. matrix factorization - technika dekompozycji macierzy user-item) - ALS (Alternating Least Squares - metoda najmniejszych kwadratów na przemian), SVD (Singular Value Decomposition - rozkład według wartości osobliwych). Projekt powstał w 2008 roku, obecnie koncentruje się na algorytmach rozproszonych opartych na Apache Spark (ang. Spark-based distributed algorithms).

\textbf{Możliwości systemu:} Apache Mahout oferuje pełną kontrolę nad implementacją algorytmów rekomendacyjnych oraz możliwość dostosowania ich do specyficznych wymagań biznesowych. Framework eliminuje koszty licencyjne charakterystyczne dla rozwiązań komercyjnych, co czyni go atrakcyjnym dla organizacji o ograniczonym budżecie. System wykorzystuje Apache Spark do przetwarzania rozproszonych obliczeń, co umożliwia skalowanie do bardzo dużych zbiorów danych (miliony użytkowników, miliony produktów). Mahout oferuje implementacje zaawansowanych algorytmów faktoryzacji macierzy (ALS, SVD), które mogą osiągać wysoką jakość rekomendacji przy odpowiedniej konfiguracji. Jako projekt otwartoźródłowy, Mahout nie wiąże się z uzależnieniem od konkretnego dostawcy chmurowego.

\noindent
\textbf{Kluczowe ograniczenia w kontekście planowanego rozwiązania:}

\begin{itemize}
\item \textbf{Wymóg zaawansowanej wiedzy technicznej} - konieczność konfiguracji klastra Apache Spark (środowisko przetwarzania rozproszonego), YARN resource manager (zarządca zasobów), oraz monitoringu. Według Stack Overflow Developer Survey 2023, bardzo mała część programistów ma doświadczenie \\z Apache Spark,
\item \textbf{Koszty infrastruktury} - utrzymanie klastra Spark wymaga dedykowanych zasobów serwerowych oraz czasu na implementację integracji (REST API, baza danych, cache, frontend), co generuje znaczące koszty operacyjne,
\item \textbf{Brak analizy sentymentu} - Apache Mahout nie oferuje sentiment analysis. Wymagana jest integracja z zewnętrznymi bibliotekami (np. Stanford CoreNLP) lub samodzielna implementacja słownikowej analizy sentymentu,
\item \textbf{Wolniejszy rozwój projektu} - według danych z lat 2023-2024, aktywność projektu spadła (2-3 commity miesięcznie vs 20-30 commitów w latach 2012-2014), co skutkuje ograniczoną dokumentacją dla nowszych wersji.
\end{itemize}

\subsection*{Analiza i uzasadnienie własnego rozwiązania}

Analiza rozwiązań alternatywnych ujawniła fundamentalny kompromis: \textbf{zaawansowanie technologiczne vs koszty i elastyczność}. Rozwiązania chmurowe od Amazona oraz Google oferują wysoką jakość rekomendacji dzięki algorytmom deep learning, ale wiążą się z wysokimi kosztami operacyjnymi, uzależnieniem od dostawcy oraz brakiem kontroli nad algorytmami. Apache Mahout eliminuje koszty licencyjne, ale wymaga zaawansowanej wiedzy technicznej oraz kosztownej infrastruktury Spark.

\noindent
Uzasadnienie sensowności własnego rozwiązania:

\begin{itemize}
\item \textbf{Integracja trzech komplementarnych metod w jednym systemie}:

Każde z analizowanych rozwiązań wymaga dodatkowej integracji lub samodzielnej implementacji co najmniej jednej z trzech wybranych metod (Collaborative Filtering, Analiza Sentymentu, Reguły Asocjacyjne):
\begin{itemize}
\item Amazon Personalize: oferuje Collaborative Filtering, wymagane dodatkowe usługi AWS (Amazon Comprehend dla analizy sentymentu) lub samodzielna implementacja reguł asocjacyjnych,
\item Google Recommendations AI: oferuje Collaborative Filtering oraz funkcję ,,Frequently Bought Together'' (podobną do reguł asocjacyjnych), wymaga samodzielnej implementacji analizy sentymentu,
\item Apache Mahout: oferuje tylko Collaborative Filtering, wymaga samodzielnej implementacji analizy sentymentu oraz reguł asocjacyjnych.
\end{itemize}

Własna implementacja pozwala na spójną integrację wszystkich trzech metod w ramach jednej architektury systemowej oraz umożliwia dostosowanie logiki każdej metody do specyfiki branży e-commerce.

\newpage
\item \textbf{Optymalizacja kosztów dla małych i średnich platform}:

Własna implementacja (Django + PostgreSQL) eliminuje koszty licencyjne rozwiązań chmurowych przy zachowaniu wysokiej jakości rekomendacji. System jest szczególnie atrakcyjny dla małych i średnich platform e-commerce (do 10000 produktów, do 10000 użytkowników), które potrzebują zaawansowanych funkcjonalności rekomendacji przy ograniczonym budżecie.

\item \textbf{Kontrola nad logiką biznesową i możliwość dostosowania}:

Własna implementacja umożliwia unikalne podejścia niedostępne w gotowych rozwiązaniach:
\begin{itemize}
\item \textbf{Wieloźródłowa agregacja sentymentu} \cite{liu2012} z 5 źródeł tekstowych - rozwiązuje problem cold start (zimny start): produkty bez opinii użytkowników otrzymują wynik sentymentu na podstawie opisu, nazwy i specyfikacji,
\item \textbf{Bitmap pruning} \cite{zaki2000} dla algorytmu Apriori - optymalizacja przyspiesza generowanie reguł asocjacyjnych względem implementacji naiwnej poprzez operacje bitowe,
\item \textbf{Adjusted Cosine Similarity} \cite{sarwar2001item} z centrowaniem średniej - eliminacja wartości progowej (bias) wynikającej z różnych skal zakupowych użytkowników. Centrowanie średniej usuwa ten efekt skali przy obliczaniu podobieństwa.
\end{itemize}

\item \textbf{Elastyczność technologiczna i brak uzależnienia od dostawcy}:

Aplikacja oparta na Django + React + PostgreSQL może być wdrożona na dowolnej platformie: AWS, GCP, Azure, własne serwery lub localhost. Migracja między platformami wymaga jedynie zmiany parametrów połączenia - logika rekomendacji pozostaje niezmieniona.

Dla porównania: migracja z Amazon Personalize do Google Recommendations AI wymaga przepisania całej integracji (śledzenie zdarzeń, dane treningowe, wywołania API) oraz ponownego trenowania modeli, co może trwać tygodnie i powodować degradację jakości rekomendacji.
\end{itemize}

\noindent
Własna implementacja systemu rekomendacji stanowi optymalny wybór dla małych i średnich platform e-commerce, łączący:
\begin{itemize}
\item Wysoką jakość rekomendacji (trzy komplementarne metody: Collaborative Filtering, Sentiment Analysis, Apriori),
\item Pełną kontrolę nad algorytmami i możliwość dostosowania do specyfiki biznesowej,
\item Niskie koszty operacyjne (brak opłat licencyjnych rozwiązań chmurowych),
\item Interpretowalność wyników i możliwość debugowania,
\item Elastyczność technologiczną (brak uzależnienia od konkretnego dostawcy chmury).
\end{itemize}

Rozwiązanie jest szczególnie atrakcyjne dla platform potrzebujących zaawansowanych funkcjonalności rekomendacji przy ograniczonym budżecie oraz możliwości dostosowania logiki do specyficznych wymagań biznesowych.

\newpage
\section*{Rozdzia\l{} 3}
\addcontentsline{toc}{section}{Rozdział 3: Opis projektu planowanej aplikacji}
\section*{Opis projektu planowanej aplikacji}

Rozdział przedstawia szczegółowy opis planowanej aplikacji e-commerce z zaawansowanym systemem rekomendacji produktów. Zaprezentowano diagram przypadków użycia ilustrujący interakcje użytkowników z systemem oraz opisano kluczowe funkcjonalności z perspektywy różnych typów użytkowników.

\subsection*{3.1 Cel i zakres aplikacji}
\addcontentsline{toc}{subsection}{3.1 Cel i zakres aplikacji}

Aplikacja stanowi kompleksowe rozwiązanie e-commerce integrujące trzy komplementarne metody rekomendacji produktów:
\begin{itemize}
\item \textbf{Collaborative Filtering} - odkrywanie produktów podobnych na podstawie wzorców zakupowych użytkowników,
\item \textbf{Sentiment Analysis} - ocena jakości produktów poprzez analizę opinii i treści,
\item \textbf{Association Rules (Apriori)} - identyfikacja produktów często kupowanych razem.
\end{itemize}

System został zaprojektowany z myślą o małych i średnich platformach e-commerce (do 10000 produktów, do 100000 użytkowników), zapewniając funkcjonalności rekomendacyjne porównywalne z rozwiązaniami enterprise przy znacznie niższych kosztach operacyjnych.

\subsection*{3.2 Typy użytkowników systemu}
\addcontentsline{toc}{subsection}{3.2 Typy użytkowników systemu}

System obsługuje trzech typów użytkowników, z których każdy posiada dostęp do różnych poziomów funkcjonalności. Struktura uprawnień opiera się na hierarchii dziedziczenia, gdzie każdy wyższy poziom dziedziczy wszystkie funkcjonalności poziomów niższych.

\textbf{Gość} - użytkownik niezalogowany, posiadający dostęp do podstawowych funkcji sklepu internetowego. Może przeglądać produkty, wyszukiwać i dodawać je do koszyka, jednakże nie może złożyć zamówienia bez utworzenia konta.

\textbf{Klient} - użytkownik zalogowany, który dziedziczy wszystkie funkcje gościa oraz dodatkowo ma dostęp do funkcjonalności transakcyjnych i personalizacji. Może składać zamówienia, śledzić ich status, zarządzać swoim kontem oraz korzystać ze spersonalizowanych rekomendacji generowanych przez zaimplementowane algorytmy.

\textbf{Administrator} - użytkownik z najwyższymi uprawnieniami, który dziedziczy wszystkie funkcje klienta oraz dodatkowo ma dostęp do narzędzi administracyjnych. Może zarządzać całym systemem: produktami, zamówieniami, użytkownikami oraz ma dostęp do panelów statystycznych i debugowania algorytmów rekomendacji.

Taki podział użytkowników według ról i uprawnień wpływa bezpośrednio na podział systemu na trzy główne obszary funkcjonalne: obszar publiczny (dostępny dla wszystkich), obszar klienta (wymaga zalogowania) oraz obszar administracyjny (wymaga uprawnień administratora).

\subsection*{3.3 Wymagania funkcjonalne systemu}
\addcontentsline{toc}{subsection}{3.3 Wymagania funkcjonalne systemu}

System został zaprojektowany z uwzględnieniem następujących wymagań funkcjonalnych pogrupowanych według obszarów:

\noindent
\textbf{Autentykacja i autoryzacja:}
\begin{itemize}
\item Rejestracja nowego użytkownika w systemie,
\item Logowanie do systemu z walidacją danych,
\item Wylogowanie i zarządzanie sesją (token JWT).
\end{itemize}

\noindent
\textbf{Obsługa koszyka zakupowego:}
\begin{itemize}
\item Dodawanie produktów do koszyka,
\item Wyświetlanie zawartości koszyka z sumą całkowitą,
\item Modyfikacja ilości produktów w koszyku,
\item Usuwanie produktów z koszyka,
\item Wyświetlanie rekomendacji Apriori (,,Często kupowane razem'').
\end{itemize}

\noindent
\textbf{Obsługa zamówień (tylko użytkownicy zalogowani):}
\begin{itemize}
\item Składanie zamówień z danymi dostawy i płatności,
\item Wyświetlanie historii zamówień użytkownika,
\item Śledzenie statusu zamówienia (oczekujące, w realizacji, zakończone, anulowane),
\item Wyświetlanie szczegółów zamkniętych zamówień.
\end{itemize}

\noindent
\textbf{Zarządzanie kontem użytkownika:}
\begin{itemize}
\item Wyświetlanie profilu użytkownika,
\item Edycja danych osobowych (imię, nazwisko, adres e-mail),
\item Zmiana hasła,
\item Przeglądanie historii aktywności.
\end{itemize}

\noindent
\textbf{System rekomendacji:}
\begin{itemize}
\item Wyświetlanie rekomendacji Collaborative Filtering na stronie głównej,
\item Wyświetlanie produktów podobnych na stronie szczegółów produktu,
\item Wyświetlanie rekomendacji opartych na sentymencie (produkty o najlepszych opiniach),
\item Wyświetlanie rekomendacji Apriori w koszyku zakupowym.
\end{itemize}

\noindent
\textbf{Opinie i recenzje:}
\begin{itemize}
\item Wyświetlanie opinii innych użytkowników na stronie produktu,
\item Dodawanie opinii do zakupionych produktów (ocena gwiazdkowa i treść tekstowa),
\item Automatyczne przeliczanie sentymentu po dodaniu opinii.
\end{itemize}

\noindent
\textbf{Funkcje administracyjne - zarządzanie produktami:}
\begin{itemize}
\item Dodawanie nowych produktów do katalogu,
\item Edycja istniejących produktów (nazwa, opis, cena, kategorie, specyfikacje),
\item Usuwanie produktów z potwierdzeniem,
\item Zarządzanie kategoriami produktów.
\end{itemize}

\noindent
\textbf{Funkcje administracyjne - zarządzanie zamówieniami:}
\begin{itemize}
\item Przeglądanie wszystkich zamówień w systemie,
\item Zmiana statusów zamówień,
\item Wyświetlanie szczegółów zamówienia,
\item Generowanie raportów sprzedażowych.
\end{itemize}

\noindent
\textbf{Funkcje administracyjne - zarządzanie użytkownikami:}
\begin{itemize}
\item Lista wszystkich użytkowników w systemie,
\item Nadawanie uprawnień administratora,
\item Usuwanie kont użytkowników,
\end{itemize}

\noindent
\textbf{Funkcje administracyjne - statystyki i analityka:}
\begin{itemize}
\item Panel analityczny (dashboard) z kluczowymi wskaźnikami,
\item Wykresy sprzedaży (miesięczny obrót, najpopularniejsze kategorie),
\item Statystyki użytkowników (nowe rejestracje, aktywni użytkownicy),
\item Statystyki produktów (najczęściej kupowane, najlepsze opinie).
\end{itemize}

\noindent
\textbf{Funkcje administracyjne - debugowanie algorytmów rekomendacji:}
\begin{itemize}
\item Podgląd macierzy podobieństw Collaborative Filtering,
\item Przeglądanie reguł asocjacyjnych Apriori z metrykami,
\item Walidacja poprawności działania algorytmów,
\item Wyświetlanie statystyk wydajności metod rekomendacji.
\end{itemize}

\newpage
\subsection*{3.4 Diagram przypadków użycia}
\addcontentsline{toc}{subsection}{3.4 Diagram przypadków użycia}

Diagram przypadków użycia (rys. \ref{fig:use_case_project}) przedstawia kompletny widok funkcjonalności systemu oraz relacji między aktorami a przypadkami użycia. System obsługuje trzy główne typy aktorów: Gościa (użytkownik niezalogowany), Klienta (użytkownik zalogowany) oraz Administratora (zarządzający systemem).

\begin{figure}[H]
\centering
\includegraphics[width=1.1\textwidth]{images/useCaseDiagram.png}
\caption{Diagram przypadków użycia systemu.}
\label{fig:use_case_project}
\end{figure}

\textbf{Ogólny opis diagramu:}

Diagram został zorganizowany wokół trzech głównych aktorów, z których każdy ma dostęp do różnych poziomów funkcjonalności systemu. Relacje dziedziczenia między aktorami (Gość $\rightarrow$ Klient $\rightarrow$ Administrator) odzwierciedlają hierarchię uprawnień - każdy następny poziom dziedziczy wszystkie funkcjonalności poprzedniego \\i dodaje nowe, specyficzne dla swojej roli.

\subsection*{3.5 Architektura funkcjonalna systemu}
\addcontentsline{toc}{subsection}{3.5 Architektura funkcjonalna systemu}

System został zaprojektowany w architekturze warstwowej, gdzie każda warstwa odpowiada za konkretny aspekt funkcjonalności:

\noindent
\textbf{Warstwa prezentacji} - interfejsy użytkownika dostosowane do ról (klient, administrator):
\begin{itemize}
\item \textbf{Panel klienta} - panel główny (dashboard) z historią zamówień, sekcja rekomendacji, edycja profilu,
\item \textbf{Panel administracyjny} - zarządzanie produktami/zamówieniami/użytkownikami, statystyki, panele debugowania.
\end{itemize}

\noindent
\textbf{Warstwa logiki biznesowej} - implementacja trzech algorytmów rekomendacji oraz logiki e-commerce:
\begin{itemize}
\item \textbf{Moduł Collaborative Filtering} - generowanie macierzy podobieństwa produktów, rekomendacje oparte na produktach (item-based),
\item \textbf{Moduł Sentiment Analysis} - agregacja sentymentu z 5 źródeł tekstowych (opinie, opis, nazwa, specyfikacje, kategorie),
\item \textbf{Moduł Apriori} - generowanie reguł asocjacyjnych typu ``Często kupowane razem'',
\item \textbf{Logika transakcyjna} - składanie zamówień, zarządzanie statusami, walidacja danych.
\end{itemize}

\noindent
\textbf{Warstwa danych} - relacyjna baza danych PostgreSQL przechowująca:
\begin{itemize}
\item Dane produktów (nazwa, opis, cena, kategorie, specyfikacje, zdjęcia),
\item Dane użytkowników (konta, profile, uprawnienia),
\item Dane transakcyjne (zamówienia, produkty w zamówieniach, statusy),
\item Dane opinii (recenzje tekstowe, oceny gwiazdkowe, sentyment),
\item Wyniki algorytmów (macierze podobieństwa, reguły asocjacyjne, zagregowana ocena sentymentu).
\end{itemize}

\textbf{Integracja warstw} odbywa się poprzez RESTful API z automatyczną synchronizacją - zmiana danych w jednej warstwie propaguje aktualizacje do pozostałych.

\subsection*{3.6 Struktura bazy danych}
\addcontentsline{toc}{subsection}{3.6 Struktura bazy danych}

Baza danych systemu składa się z 25 tabel zorganizowanych w cztery moduły funkcjonalne. Poniższe diagramy ERD (Entity-Relationship Diagram - diagram związków encji) przedstawiają strukturę relacyjną bazy danych wraz z kluczowymi powiązaniami między tabelami.

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{images/appErd.png}
  \caption{Diagram ERD głównych tabel aplikacji.}
  \label{fig:erd1}
\end{figure}

\noindent
Diagram \ref{fig:erd1} przedstawia rdzeń aplikacji e-commerce. Kluczowe relacje:

\begin{itemize}
\item \textbf{db\_user $\leftrightarrow$ db\_order} (1:N) - jeden użytkownik może złożyć wiele zamówień,
\item \textbf{db\_order $\rightarrow$ db\_order\_product} (1:N) - zamówienie zawiera wiele produktów,
\item \textbf{db\_product $\leftrightarrow$ db\_category} (N:M) - produkt należy do wielu kategorii,
\item \textbf{db\_product $\rightarrow$ db\_opinion} (1:N) - produkt ma wiele opinii.
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{images/methodsErd.png}
  \caption{Diagram ERD tabel metod rekomendacyjnych.}
  \label{fig:erd2}
\end{figure}

\noindent
Diagram \ref{fig:erd2} pokazuje tabele algorytmów ML:

\begin{itemize}
\item \textbf{method\_product\_similarity} - macierz podobieństw Collaborative Filtering,
\item \textbf{method\_productassociation} - reguły asocjacyjne Apriori,
\item \textbf{method\_sentiment\_analysis} - wyniki analizy sentymentu opinii,
\item \textbf{method\_product\_sentiment\_summary} - zagregowany sentyment produktu,
\item \textbf{method\_user\_product\_recommendation} - cache rekomendacji użytkownika.
\end{itemize}

\noindent
\textbf{Charakterystyka tabel bazy danych}

\noindent
Baza składa się z \textbf{25 głównych modeli} podzielonych na 4 moduły funkcjonalne:

\noindent
\textbf{1. Moduł produktów i użytkowników (12 tabel):}

\begin{itemize}
\item \texttt{db\_product} - dane produktów (ID, nazwa, cena, opis),
\item \texttt{db\_category} - kategorie produktów z hierarchią,
\item \texttt{db\_product\_category} - relacjaMany-to-Many produktów i kategorii,
\item \texttt{db\_photo\_product} - ścieżki do zdjęć produktów,
\item \texttt{db\_specification} - szczegółowe parametry techniczne produktów,
\item \texttt{db\_tag} - tagi do filtrowania produktów,
\item \texttt{db\_sale} - promocje i rabaty,
\item \texttt{db\_user} - konta użytkowników (role: admin/client),
\item \texttt{db\_order} - zamówienia z timestampami i statusami,
\item \texttt{db\_order\_product} - produkty w zamówieniach (ilość, cena),
\item \texttt{db\_cart\_item} - koszyk zakupowy przed finalizacją,
\item \texttt{db\_complaint} - reklamacje powiązane z zamówieniami.
\end{itemize}

\noindent
\textbf{2. Moduł opinii i analizy sentymentu (3 tabele):}

\begin{itemize}
\item \texttt{db\_opinion} - opinie użytkowników (treść, rating 1-5),
\item \texttt{method\_sentiment\_analysis} - wyniki analizy sentymentu dla opinii,
\item \texttt{method\_product\_sentiment\_summary} - zagregowany sentyment produktu.
\end{itemize}

\noindent
\textbf{3. Moduł metod rekomendacji (5 tabel):}

\begin{itemize}
\item \texttt{method\_product\_similarity} - macierz podobieństw produktów (Collaborative Filtering),
\item \texttt{method\_user\_product\_recommendation} - spersonalizowane rekomendacje użytkowników,
\item \texttt{method\_productassociation} - reguły asocjacyjne Apriori,
\item \texttt{method\_user\_interactions} - historia interakcji użytkowników,
\item \texttt{method\_recommendation\_settings} - konfiguracja algorytmów dla użytkownika.
\end{itemize}

\noindent
\textbf{4. Moduł analityczny i prognozowanie (5 tabel):}

\begin{itemize}
\item \texttt{method\_purchase\_probability} - prawdopodobieństwo zakupu produktu przez użytkownika,
\item \texttt{method\_sales\_forecast} - prognoza sprzedaży produktów,
\item \texttt{method\_user\_purchase\_pattern} - wzorce zakupowe użytkowników,
\item \texttt{method\_product\_demand\_forecast} - prognoza popytu i poziomy magazynowe,
\item \texttt{method\_risk\_assessment} - ocena ryzyka dla użytkowników i produktów.
\end{itemize}

Wszystkie migracje Django ORM zostały wygenerowane automatycznie na podstawie modeli Python i zarządzane przez system wersjonowania \texttt{django.db.migrations}.

\textbf{Wypełnianie bazy danych początkowymi (seeding)}

W celu umożliwienia testowania systemu oraz walidacji algorytmów rekomendacyjnych zaimplementowano mechanizm automatycznego wypełniania bazy danych testowymi danymi (ang. database seeding). Proces seedingów generuje: 500 produktów z opisami, cenami i specyfikacjami technicznymi, 20 użytkowników (5 administratorów + 15 klientów) z wypełnionymi profilami, 200 zamówień z realistycznymi timestampami, około 600 rekordów OrderProduct (przeciętnie 3 produkty na zamówienie), oraz przybliżnie 1750 opinii (średnio 3.5 opinii na produkt) z ocenami gwiazdkowymi i treściami tekstowymi. Dane testowe zostały zaprojektowane w taki sposób, aby odzwierciedlać realistyczne wzorce zachowań użytkowników w sklepie internetowym, co pozwala na efektywną walidację jakości generowanych rekomendacji przez algorytmy Collaborative Filtering, analizę sentymentu oraz reguły asocjacyjne.

\newpage
\section*{Rozdzia\l{} 4}
\addcontentsline{toc}{section}{Rozdział 4: Przedstawienie wykorzystanego stosu technologicznego oraz praktycznej realizacji projektu}
\section*{Przedstawienie wykorzystanego stosu technologicznego oraz praktycznej realizacji projektu}

Rozdział przedstawia techniczne aspekty implementacji systemu e-commerce wyposażonego w mechanizmy rekomendacji produktów. Omówiono stos technologiczny wykorzystany w projekcie, strukturę bazy danych oraz sposób wdrożenia aplikacji z wykorzystaniem konteneryzacji Docker.

\subsection*{4.1 Architektura systemu}
\addcontentsline{toc}{subsection}{4.1 Architektura systemu}

Aplikacja została zaprojektowana w architekturze klient-serwer opartej na technologiach Django (backend) oraz React (frontend). Komunikacja odbywa się poprzez RESTful API z uwierzytelnianiem tokenowym JSON Web Tokens (JWT). Struktura aplikacji wyraźnie rozdziela warstwę prezentacji (React SPA), logikę biznesową (widoki Django i serializery), oraz warstwę danych (PostgreSQL).

\noindent
\textbf{Główne założenia architektoniczne:}

\begin{itemize}
\item \textbf{Separacja frontendu i backendu} - możliwość niezależnego rozwoju i skalowania obu warstw,
\item \textbf{Podejście API-first (API-first approach)} - wszystkie funkcjonalności dostępne przez REST API,
\item \textbf{Uwierzytelnianie bezstanowe (Stateless authentication)} - token JWT eliminuje potrzebę sesji po stronie serwera,
\item \textbf{Modułowa struktura} - każdy algorytm rekomendacji stanowi niezależny moduł.
\end{itemize}

\subsection*{4.2 Stos technologiczny backendu}
\addcontentsline{toc}{subsection}{4.2 Stos technologiczny backendu}

\noindent
\textbf{Django 5.1.4 (Python 3.11)} - stanowi fundament aplikacji serwerowej, zapewniając architekturę MVC, system ORM (Object-Relational Mapping - mapowanie obiektowo-relacyjne) dla abstrakcji bazy danych oraz mechanizmy bezpieczeństwa. Kluczowe komponenty:

\begin{itemize}
\item \textbf{Django ORM} - mapowanie obiektowo-relacyjne umożliwiające operacje na bazie bez SQL,
\item \textbf{Django Signals} - mechanizm automatycznej aktualizacji rekomendacji przy zmianach danych,
\item \textbf{Django Middleware (oprogramowanie pośredniczące)} - obsługa CORS, uwierzytelnienie JWT, pamięć podręczna.
\end{itemize}

\textbf{Django REST Framework 3.15.2}

Rozszerza Django o funkcjonalności API RESTful:

\begin{itemize}
\item \textbf{Serializery} - konwersja obiektów Django na JSON z walidacją,
\item \textbf{ViewSets (zestawy widoków)} - widoki implementujące operacje CRUD,
\item \textbf{Uwierzytelnianie (Authentication)} - wsparcie dla JWT, uwierzytelnianie sesyjne,
\item \textbf{Pagination (paginacja)} - automatyczne stronicowanie wyników.
\end{itemize}

\noindent
\textbf{Biblioteki Machine Learning}

Do operacji numerycznych i obliczania podobieństw wykorzystano:
\begin{itemize}
\item \textbf{scikit-learn} - funkcja cosine\_similarity() dla Collaborative Filtering (Collaborative Filtering),
\item \textbf{NumPy} - operacje macierzowe, wektoryzacja obliczeń, przycinanie bitmapowe (bitmap pruning) w Apriori.
\end{itemize}

\subsection*{4.3 Stos technologiczny frontendu}
\addcontentsline{toc}{subsection}{4.3 Stos technologiczny frontendu}

\noindent
\textbf{React 18} - stanowi fundament aplikacji jednostronicowej (Single Page Application - SPA):

\begin{itemize}
\item \textbf{Architektura komponentowa (Component-based)} - reużywalne komponenty UI,
\item \textbf{Virtual DOM (wirtualny DOM)} - optymalizacja renderowania,
\item \textbf{React Hooks (haki React)} - useState, useEffect, useContext.
\end{itemize}

\textbf{Biblioteki wspierające}

\begin{itemize}
\item \textbf{React Router v6} - trasowanie (routing) dla aplikacji SPA,
\item \textbf{Axios} - komunikacja z API, przechwytywacze JWT (interceptors),
\item \textbf{Framer Motion} - płynne animacje,
\item \textbf{Context API} - zarządzanie stanem (AuthContext, CartContext).
\end{itemize}

\subsection*{4.4 Baza danych PostgreSQL}
\addcontentsline{toc}{subsection}{4.4 Baza danych PostgreSQL}

\textbf{Wybór PostgreSQL 14} - został wybrany jako system zarządzania bazą danych ze względu na następujące cechy:

\begin{itemize}
\item \textbf{Zaawansowane indeksy} - wsparcie dla B-tree (domyślne), GIN (wyszukiwanie pełnotekstowe), BRIN (optymalizacja dla dużych tabel),
\item \textbf{Typ danych JSONB} - natywne przechowywanie i indeksowanie struktur JSON (wykorzystane w tabeli \texttt{method\_user\_purchase\_pattern} dla sezonowości zakupów),
\item \textbf{Transakcje ACID} - gwarancja atomowości, spójności, izolacji i trwałości operacji krytycznych (zamówienia, płatności),
\item \textbf{Klucze obce i constrainty} - automatyczne wymuszanie integralności referencyjnej oraz walidacji danych (np. rating 1-5 w opiniach),
\item \textbf{Optymalizacja JOIN} - wydajne łączenie tabel w złożonych zapytaniach rekomendacyjnych,
\item \textbf{Full-text search} - wbudowane mechanizmy wyszukiwania tekstowego dla produktów.
\end{itemize}

\subsection*{4.5 Projekt techniczny systemu}
\addcontentsline{toc}{subsection}{4.5 Projekt techniczny systemu}

Po przedstawieniu stosu technologicznego oraz struktury bazy danych, niniejsza sekcja charakteryzuje projekt techniczny systemu, ze szczególnym uwzględnieniem architektury komponentów backendu i frontendu.

\textbf{Struktura backendu}

Każdy komponent systemu backendowego posiada dedykowane pliki odpowiedzialne za różne aspekty funkcjonalności:

\begin{itemize}
\item \textbf{models.py} -- definicje tabel (Product, Order, Opinion, ProductSimilarity),
\item \textbf{serializers.py} -- konwersja obiektów Django $\leftrightarrow$ JSON,
\item \textbf{views.py} -- obsługa CRUD dla produktów, zamówień,
\item \textbf{recommendation\_views.py} -- endpointy /api/generate-user-recommendations/, /api/recommendation-algorithm-status/,
\item \textbf{sentiment\_views.py} -- endpointy /api/sentiment-search/, /api/sentiment-analysis-debug/,
\item \textbf{association\_views.py} -- endpointy /api/frequently-bought-together/, /api/update-association-rules/,
\item \textbf{signals.py} -- automatyczna aktualizacja rekomendacji.
\end{itemize}

\textbf{Architektura komponentów frontendu}

\begin{itemize}
\item \textbf{App.js} -- trasowanie, globalne dostawcy kontekstu (Context providers),
\item \textbf{Navbar.jsx} -- nawigacja z wyszukiwarką i ikoną koszyka,
\item \textbf{SearchModal.jsx} -- wyszukiwarka z sortowaniem sentymentu,
\item \textbf{ProductPage.jsx} -- strona produktu z rekomendacjami Collaborative Filtering i Apriori,
\item \textbf{CartContent.jsx} -- koszyk z cross-selling (Apriori),
\item \textbf{ClientPanel.jsx} -- panel główny klienta z personalizowanymi rekomendacjami,
\item \textbf{AdminPanel.jsx} -- panel zarządzania produktami, zamówieniami, statystykami.
\end{itemize}

\subsection*{4.6 Deployment i konteneryzacja Docker}
\addcontentsline{toc}{subsection}{4.5 Deployment i konteneryzacja Docker}

Aplikacja została skonteneryzowana przy użyciu Docker Compose, zapewniając spójność środowiska między środowiskiem deweloperskim (development), testowym (staging) i produkcyjnym (production).

\begin{figure}[H]
  \centering
  \includegraphics[width=1.1\textwidth]{images/dockerView.png}
  \caption{Architektura deweloperska aplikacji w Docker Compose z mechanizmem hot-reload.}
  \label{fig:docker_view}
\end{figure}

Architektura składa się z trzech kontenerów (rys. \ref{fig:docker_view}):

\noindent
\textbf{1. Kontener frontendu (React 18)}
\begin{itemize}
\item Base image: node:18-alpine,
\item Port: 3000,
\item Volumes: montowanie src/ dla automatycznego przeładowania (hot-reload),
\item Environment: REACT\_APP\_API\_URL,
\item Zależności (Dependencies): package.json (React, Axios, React Router, Framer Motion).
\end{itemize}

\noindent
\textbf{2. Kontener backendu (Django 5.1.4)}
\begin{itemize}
\item Base image: python:3.11-slim,
\item Port: 8000,
\item Volumes: montowanie projektu dla automatycznego przeładowania (hot-reload), wolumen dla plików multimedialnych,
\item Environment: DATABASE\_URL, SECRET\_KEY, DEBUG, ALLOWED\_HOSTS,
\item Zależności (Dependencies): requirements.txt (Django, DRF, psycopg2, NumPy, scikit-learn).
\end{itemize}

\noindent
\textbf{3. Kontener bazy danych (PostgreSQL 14)}
\begin{itemize}
\item Base image: postgres:14-alpine,
\item Port: 5432,
\item Volumes: named volume postgres\_data (persystencja danych),
\item Environment: POSTGRES\_DB, POSTGRES\_USER, POSTGRES\_PASSWORD,
\item Healthcheck: pg\_isready.
\end{itemize}

Konteneryzacja Docker zapewnia kilka kluczowych korzyści dla projektu. Izolacja każdego serwisu w osobnym kontenerze eliminuje konflikty zależności, co jest szczególnie istotne przy różnych wersjach bibliotek między backendem (Python 3.11) a frontendem (Node 18). Przenośność obrazów Docker umożliwia uruchomienie aplikacji na dowolnym serwerze z silnikiem Docker bez konieczności ręcznej konfiguracji środowiska. Proces uruchomienia został uproszczony do pojedynczej komendy \texttt{docker-compose up}, która automatycznie inicjalizuje wszystkie trzy kontenery z odpowiednimi zależnościami i połączeniami sieciowymi. Dodatkowo architektura umożliwia łatwą skalowalność - w przypadku wzrostu ruchu możliwe jest uruchomienie wielu instancji kontenera backendu z zastosowaniem mechanizmów równoważenia obciążenia (load balancing).

\subsection*{4.7 Architektura i przepływ danych systemu rekomendacji}
\addcontentsline{toc}{subsection}{4.7 Architektura i przepływ danych systemu rekomendacji}

System rekomendacji został zintegrowany z aplikacją e-commerce w architekturze trójwarstwowej:

\textbf{Warstwa prezentacji (React)} - interfejs użytkownika wyświetlający rekomendacje w różnych kontekstach:
\begin{itemize}
\item Strona główna - sekcja ,,Recommended for You'' z możliwością przełączania algorytmów,
\item Panel klienta - dashboard z personalizowanymi rekomendacjami,
\item Wyszukiwarka - sortowanie według sentymentu,
\item Koszyk zakupowy - sekcja ,,Frequently Bought Together'',
\item Panel administracyjny - zarządzanie metodami rekomendacji i debugowanie.
\end{itemize}

\textbf{Warstwa logiki biznesowej (Django)} - endpointy API obsługujące zapytania o rekomendacje:
\begin{itemize}
\item \texttt{/api/generate-user-recommendations/} - generowanie rekomendacji Collaborative Filtering,
\item \texttt{/api/sentiment-search/} - wyszukiwanie produktów według sentymentu,
\item \texttt{/api/frequently-bought-together/} - produkty z reguł asocjacyjnych Apriori,
\item \texttt{/api/recommendation-algorithm-status/} - status algorytmów i debugowanie,
\item \texttt{/api/admin/update-product-similarity/} - regeneracja macierzy podobieństw.
\end{itemize}

\textbf{Warstwa danych (PostgreSQL)} - tabele przechowujące prekalkulowane wyniki:
\begin{itemize}
\item \texttt{method\_product\_similarity} - macierz podobieństw Collaborative Filtering,
\item \texttt{method\_product\_sentiment\_summary} - zagregowany sentyment,
\item \texttt{method\_productassociation} - reguły Apriori,
\item \texttt{method\_recommendation\_settings} - konfiguracja aktywnej metody.
\end{itemize}

\subsection*{Charakterystyka funkcjonowania systemu}

\noindent
Zaimplementowany system rekomendacji cechuje się:

\noindent
\textbf{Kompletnością zarządzania:}
\begin{itemize}
\item Panel administratora z dynamicznym przełączaniem metod,
\item Sekcje debugowania dla wszystkich trzech algorytmów,
\item Wizualizacja metryk i statystyk w czasie rzeczywistym.
\end{itemize}

\noindent
\textbf{Integracją w aplikacji:}
\begin{itemize}
\item Strona główna z konfigurowalnymi rekomendacjami,
\item Dashboard klienta z personalizacją,
\item Wyszukiwarka z sortowaniem według sentymentu,
\item Sekcje ,,Frequently Bought Together'' oparte na Apriori.
\end{itemize}

\noindent
\textbf{Narzędziami diagnostycznymi:}
\begin{itemize}
\item Podgląd macierzy podobieństw Collaborative Filtering,
\item Analiza źródeł sentymentu dla każdego produktu,
\item Ranking reguł asocjacyjnych z metrykami,
\item Statystyki wykonania algorytmów.
\end{itemize}

System jest w pełni funkcjonalny i gotowy do wdrożenia w środowisku produkcyjnym.
\clearpage

\newpage
\section*{Rozdzia\l{} 5}
\addcontentsline{toc}{section}{Rozdział 5: Implementacja algorytmów rekomendacji}
\section*{Implementacja algorytmów rekomendacji}

Szczegółowa implementacja trzech algorytmów rekomendacyjnych wraz z pseudokodami oraz diagramami sekwencji przedstawia praktyczne aspekty realizacji metod collaborative filtering, analizy sentymentu oraz reguł asocjacyjnych.

\subsection*{5.1 Podstawy matematyczne wykorzystanych algorytmów}

Implementowane algorytmy opierają się na następujących formułach matematycznych, które stanowią fundament dla realizacji poszczególnych metod rekomendacyjnych.

\textbf{Adjusted Cosine Similarity dla Item-Based Collaborative Filtering} (Sarwar et al. 2001) \cite{sarwar2001item} stanowi kluczową metrykę podobieństwa wykorzystywaną \\w systemie. Wzór ten oblicza podobieństwo między dwoma produktami $i$ i $j$ poprzez analizę wzorców ich współwystępowania w zakupach użytkowników:

\begin{equation}
\text{sim}(i,j) = \frac{\sum_{u \in U}(R_{u,i} - \bar{R}_u)(R_{u,j} - \bar{R}_u)}{\sqrt{\sum_{u \in U}(R_{u,i} - \bar{R}_u)^2} \cdot \sqrt{\sum_{u \in U}(R_{u,j} - \bar{R}_u)^2}}
\end{equation}

gdzie $R_{u,i}$ to ilość zakupu użytkownika $u$ dla produktu $i$, $\bar{R}_u$ to średnia użytkownika $u$, a $U$ to użytkownicy, którzy kupili oba produkty. Centrowanie średniej ($R_{u,i} - \bar{R}_u$) eliminuje bias (wartość progową) dla użytkowników kupujących systematycznie więcej.

\textbf{Analiza sentymentu} (Liu 2012) \cite{liu2012} używa formuły polarności tekstu:

\begin{equation}
S(text) = \frac{N_{pos} - N_{neg}}{N_{total}}
\end{equation}

gdzie $N_{pos}$ to liczba słów pozytywnych, $N_{neg}$ negatywnych, $N_{total}$ to całkowita liczba wszystkich słów w analizowanym tekście (nie tylko słów sentymentalnych). Wynik: $[-1, 1]$ (dodatnie = pozytywny, ujemne = negatywny).

\textbf{Reguły asocjacyjne} (Agrawal \& Srikant 1994) \cite{agrawal1994} używają trzech metryk, gdzie $A$ i $B$ oznaczają zbiory produktów (np. $A$ = \{laptop\}, $B$ = \{mysz\}):

\textit{Wsparcie (Support)} (Agrawal \& Srikant 1994) \cite{agrawal1994} - jaka jest częstość współwystępowania:

\begin{equation}
\text{Support}(A, B) = \frac{\text{transakcje z } A \text{ i } B}{\text{wszystkie transakcje}}
\end{equation}

\textit{Pewność (Confidence)} (Agrawal \& Srikant 1994) \cite{agrawal1994} - jakie jest prawdopodobieństwo warunkowe:

\begin{equation}
\text{Confidence}(A \rightarrow B) = \frac{\text{Support}(A, B)}{\text{Support}(A)}
\end{equation}

\textit{Wzrost (Lift)} (Agrawal \& Srikant 1994) \cite{agrawal1994} - ile razy bardziej jest prawdopodobny zakup:

\begin{equation}
\text{Lift}(A \rightarrow B) = \frac{\text{Support}(A, B)}{\text{Support}(A) \cdot \text{Support}(B)}
\end{equation}

Wzrost(Lift) > 1: pozytywna korelacja, Wzrost = 1: niezależność, Wzrost < 1: negatywna korelacja. Algorytm Apriori przyspiesza obliczenia dzięki własności: jeśli zbiór nie spełnia minimalnego wsparcia (Support), jego nadzbiór też nie.

\subsection*{5.2 Collaborative Filtering - Item-Based z Adjusted Cosine}
\addcontentsline{toc}{subsection}{5.1 Collaborative Filtering - Item-Based z Adjusted Cosine}

Algorytm Collaborative Filtering w wariancie Item-Based oblicza podobieństwa między produktami na podstawie historii zakupów użytkowników, wykorzystując metrykę Adjusted Cosine Similarity wprowadzoną przez Sarwar et al. (2001) \cite{sarwar2001item}. Kluczowym elementem algorytmu jest formuła matematyczna przedstawiona we wzorze (1) w sekcji 5.1, która oblicza podobieństwo między dwoma produktami $i$ i $j$ poprzez analizę wzorców ich współwystępowania w zakupach użytkowników \\z uwzględnieniem centrowania wartości względem średniej zakupów każdego użytkownika $\bar{R}_u$.

Proces implementacji składa się z trzech głównych etapów odpowiadających wzorowi (1): budowy macierzy użytkownik-produkt (algorytm 1), normalizacji wartości metodą mean-centering centrowanie względem $\bar{R}_u$ (algorytm 1) oraz obliczenia podobieństw cosinusowych (algorytm 2). Normalizacja polega na odjęciu od każdej wartości zakupowej średniej zakupów danego użytkownika ($R_{u,i} - \bar{R}_u$), co eliminuje bias (wartości progowe) wynikające z różnych skal zakupowych - hurtownik kupujący po 100 sztuk oraz klient kupujący po 1 sztuce otrzymują porównywalne wagi po normalizacji, dzięki czemu algorytm wykrywa rzeczywiste wzorce preferencji niezależnie od skali transakcji.

Algorytm 1 przedstawia budowę macierzy użytkownik-produkt oraz jej normalizację. Algorytm iteruje przez wszystkie pozycje zamówień (linie 2-8), budując macierz gdzie wiersze reprezentują użytkowników, kolumny produkty, a wartości ilości zakupione. Następnie dla każdego użytkownika obliczana jest średnia jego zakupów (linia 16) i od każdej niezerowej wartości odejmowana jest ta średnia (linie 17-19), realizując centrowanie względem $\bar{R}_u$ ze wzoru (1).

\begin{lstlisting}[style=pseudocode, caption={Budowa macierzy uzytkownik-produkt z normalizacja}]
function buduj_macierz_cf():
    pozycje = pobierz_wszystkie_pozycje_zamowien()
    macierz = pusty_slownik()
    
    for poz in pozycje:
        uz_id = poz.order.user_id
        prod_id = poz.product_id
        macierz[uz_id][prod_id] = poz.quantity
    
    M = konwertuj_na_tablice(macierz)
    M_norm = macierz_zerowa(wymiary(M))
    
    for i = 0 to liczba_wierszy(M) - 1:
        zakupione = M[i] where M[i] > 0
        if |zakupione| > 0 then
            sr = srednia(zakupione)
            for j = 0 to liczba_kolumn(M) - 1:
                if M[i][j] > 0 then
                    M_norm[i][j] = M[i][j] - sr
    
    return M_norm
\end{lstlisting}

Algorytm 2 przedstawia obliczanie podobieństw cosinusowych między produktami. Macierz znormalizowana jest transponowana (linia 2), aby wiersze reprezentowały produkty, a następnie obliczane są podobieństwa cosinusowe (linia 3), które realizują licznik i mianownik wzoru (1). Algorytm stosuje próg podobieństwa zdefiniowany jako parametr funkcji (linia 1, domyślnie prog = 0.5), który jest używany w warunku (linia 11) - zapisywane są tylko pary produktów o podobieństwie powyżej progu, co redukuje rozmiar bazy danych o przybliżenie 60-80\% przy zachowaniu najważniejszych relacji, ponieważ słabe podobieństwa (np. 0.1-0.3) mają niewielką wartość predykcyjną dla rekomendacji. Operacje zbiorcze bulk insert (linie 14-16) zapisują po 1000 rekordów jednocześnie, co znacznie przyspiesza zapis do bazy danych.

\begin{lstlisting}[style=pseudocode, caption={Obliczanie podobienstwa cosinusowego produktow}]
function oblicz_podobienstwa_cf(M_norm, prog = 0.5):
    M_T = transponuj(M_norm)
    sim = podobienstwo_cosinus(M_T)
    
    usun_podobienstwa(typ='collaborative')
    lista = pusta_lista()
    n = liczba_produktow(M_T)
    
    for i = 0 to n - 1:
        for j = 0 to n - 1:
            if i != j and sim[i][j] > prog then
                dopisz(lista, {prod1: i, prod2: j, wynik: sim[i][j]})
                
                if |lista| >= 1000 then
                    zapisz_zbiorczo(lista)
                    lista = pusta_lista()
    
    if |lista| > 0 then
        zapisz_zbiorczo(lista)
\end{lstlisting}

Algorytm 3 przedstawia generowanie rekomendacji dla konkretnego użytkownika na podstawie wcześniej obliczonych podobieństw produktów. Algorytm zbiera historię zakupów użytkownika z zamówień oraz koszyka (linie 2-9), a następnie dla każdego zakupionego produktu wyszukuje najbardziej podobne produkty (linia 13). Wyniki są agregowane (linie 14-18) - jeśli dany produkt jest podobny do wielu produktów zakupionych przez użytkownika, otrzymuje sumę wszystkich podobieństw jako końcowy wynik rekomendacji, co wzmacnia rekomendacje produktów spójnych z ogólną historią preferencji użytkownika.

\begin{lstlisting}[style=pseudocode, caption={Generowanie rekomendacji CF dla uzytkownika}]
function generuj_rekomendacje(uzytkownik, typ_algorytmu):
    historia = pusta_lista()
    
    for zam in pobierz_zamowienia(uzytkownik):
        for p in zam.produkty:
            dopisz(historia, p.id)
    
    for poz in pobierz_koszyk(uzytkownik):
        dopisz(historia, poz.produkt.id)
    
    wyniki = pusty_slownik()
    for prod_id in unikalne(historia):
        podobne = pobierz_podobne(prod_id, typ_algorytmu, limit=5)
        for s in podobne:
            if s.produkt2_id in wyniki then
                wyniki[s.produkt2_id] += s.podobienstwo
            else
                wyniki[s.produkt2_id] = s.podobienstwo

    lista = sortuj(wyniki, malejaco)
    for (p_id, wart) in lista:
        zapisz_rekomendacje(uzytkownik, p_id, typ_algorytmu, wart)
\end{lstlisting}

\textbf{Diagram sekwencji: Collaborative Filtering}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/collaborativeDiagram.png}
  \caption{Diagram sekwencji: Collaborative Filtering.}
  \label{fig:cf_sequence}
\end{figure}

Diagram \ref{fig:cf_sequence} przedstawia przepływ procesu generowania rekomendacji Collaborative Filtering. Żądanie użytkownika trafia do API (\texttt{/api/generate-user-recommendations/}), które jako pierwszy krok sprawdza pamięć podręczną - w przypadku trafienia zwracany jest wynik natychmiast, co znacznie przyspiesza odpowiedź systemu. Przy braku w pamięci podręcznej następuje zapytanie do bazy danych o historię zakupów użytkownika, na podstawie której budowana jest macierz użytkownik-produkt z OrderProduct (algorytm 1). Macierz jest normalizowana poprzez centrowanie wartości względem średniej każdego użytkownika, co eliminuje systematyczne zniekształcenie, po czym obliczane są podobieństwa cosinusowe między produktami zgodnie ze wzorem (1) - algorytm 2. Wyniki są zapisywane do pamięci podręcznej z czasem wygaśnięcia 2 godziny oraz tabeli ProductSimilarity z zachowaniem tylko podobieństw powyżej progu 0.5, po czym API zwraca top N rekomendacji (algorytm 3). Zaimplementowane optymalizacje obejmują pamięć podręczną przechowującą macierz podobieństw przez 2 godziny (7200 sekund), operacje zbiorcze bulk insert zapisujące po 1000 rekordów jednocześnie, próg 0.5 redukujący rozmiar bazy poprzez odrzucenie niższych wartości, oraz indeksowanie na kolumnach produkt\_1 i typ\_podobieństwa dla szybszego wyszukiwania.

\subsection*{5.3 Analiza Sentymentu - wieloźródłowa agregacja}
\addcontentsline{toc}{subsection}{5.2 Analiza Sentymentu - wieloźródłowa agregacja}

Analiza sentymentu pojedynczego tekstu metodą słownikową \cite{liu2012} wykorzystuje formułę polarności przedstawioną we wzorze (2) w sekcji 5.1. Proces analizy polega na normalizacji tekstu (konwersja na małe litery, usunięcie znaków specjalnych), tokenizacji oraz zliczaniu słów występujących w słownikach pozytywnym i negatywnym. Słowniki oparte na leksykonach akademickich AFINN-165 (Nielsen 2011) i Opinion Lexicon (Hu \& Liu 2004) zawierają łącznie ~400 słów (~200 słów pozytywnych, ~200 słów negatywnych) obejmujących najczęściej używane określenia jakościowe, emocjonalne i ocenne (np. pozytywne: ,,excellent'', ,,recommend'', ,,quality'', ,,reliable''; negatywne: ,,bad'', ,,poor'', ,,disappointing'', ,,defective''). Wynik wzoru (2) jest ograniczany do przedziału [-1, 1] i kategoryzowany: pozytywny (>0.1), negatywny (<-0.1), neutralny (pozostałe).

Wieloźródłowa agregacja sentymentu produktu stanowi kluczową innowację systemu, łącząc wyniki z 5 niezależnych źródeł tekstowych, gdzie każde $S_i$ jest obliczane według wzoru (2). Wagi zostały dobrane empirycznie: opinie klientów 40\% (najbardziej wiarygodne źródło), opis produktu 25\% (profesjonalny opis zawierający kluczowe cechy), nazwa produktu 15\% (często zawiera wskazówki jakościowe jak ,,Premium'', ,,Pro''), specyfikacje techniczne 12\% (obiektywne parametry), kategorie produktu 8\% (ogólny kontekst). Podejście to rozwiązuje fundamentalny problem zimnego startu - produkty bez opinii klientów nadal otrzymują wynik sentymentu na podstawie pozostałych czterech źródeł tekstowych.

\textbf{Uwaga techniczna:} System opinii opisany w rozdziale 6 stanowi jeden z pięciu źródeł tekstowych wykorzystywanych przez algorytm analizy sentymentu. Każda opinia dodana przez użytkownika jest automatycznie przetwarzana przez algorytm sentiment analysis i włączana do agregacji produktu z wagą 40\%, co czyni opinie najważniejszym źródłem danych w ocenie jakości produktów.

\begin{lstlisting}[style=pseudocode, caption={Analiza sentymentu metoda slownikowa}]
function analizuj_sentiment(tekst, slownik_poz, slownik_neg):
    slowa = tokenizuj(na_male_litery(tekst))
    
    if |slowa| = 0 then
        return (0.0, ,,neutralny'')
    end if
    
    poz = 0
    neg = 0
    
    for s in slowa:
        if s in slownik_poz then poz = poz + 1
        if s in slownik_neg then neg = neg + 1
    end for
    
    wynik = (poz - neg) / |slowa|
    wynik = ogranicz(wynik, -1.0, 1.0)
    
    if wynik > 0.1 then kat = ,,pozytywny''
    else if wynik < -0.1 then kat = ,,negatywny''
    else kat = ,,neutralny''
    
    return (wynik, kat)
end function
\end{lstlisting}

Algorytm wieloźródłowej agregacji sentymentu analizuje 5 niezależnych źródeł tekstowych produktu zamiast polegać wyłącznie na opiniach klientów. Rozwiązuje to problem zimnego startu - produkty bez opinii nadal otrzymują wynik bazujący na opisie i nazwie. Wagi źródeł: opinie 40\%, opis 25\%, nazwa 15\%, specyfikacje 12\%, kategorie 8\%. System zlicza rozkład opinii (pozytywne/negatywne/neutralne) dla lepszej oceny konsensusu.

\begin{lstlisting}[style=pseudocode, caption={Agregacja sentymentu produktu z 5 zrodel}]
function agreguj_sentiment_produktu(produkt):
    opinie = pobierz_opinie(produkt)[:20]
    wyniki_opinii = pusta_lista()
    for op in opinie:
        (w, _) = analizuj_sentiment(op.tresc)
        dopisz(wyniki_opinii, w)
    end for
    S_op = srednia(wyniki_opinii) if |wyniki_opinii| > 0 else 0
    (S_opis, _) = analizuj_sentiment(produkt.opis)
    (S_nazwa, _) = analizuj_sentiment(produkt.nazwa)
    teksty_spec = pusta_lista()
    for sp in produkt.specyfikacje[:10]:
        dopisz(teksty_spec, sp.nazwa + `` '' + sp.wartosc)
    end for
    (S_spec, _) = analizuj_sentiment(polacz(teksty_spec))
    kat_txt = polacz(pobierz_nazwy_kategorii(produkt))
    (S_kat, _) = analizuj_sentiment(kat_txt)
    S_final = 0.40*S_op + 0.25*S_opis + 0.15*S_nazwa 
            + 0.12*S_spec + 0.08*S_kat

    poz = policz(wyniki_opinii WHERE w > 0.1)
    neg = policz(wyniki_opinii WHERE w < -0.1)
    neu = policz(wyniki_opinii WHERE -0.1 <= w <= 0.1)
    
    return {
        wynik: zaokragl(S_final, 3),
        pozytywne: poz,
        negatywne: neg,
        neutralne: neu
    }
end function
\end{lstlisting}

\textbf{Diagram sekwencji: Analiza Sentymentu}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/sentimentDiagram.png}
  \caption{Diagram sekwencji: Analiza sentymentu.}
  \label{fig:sentiment_sequence}
\end{figure}

Diagram \ref{fig:sentiment_sequence} przedstawia przepływ procesu wieloźródłowej analizy sentymentu. Użytkownik wyszukuje produkty z sortowaniem według sentymentu, co inicjuje wywołanie funkcji agregacji sentymentu dla każdego produktu przez API. System analizuje 5 źródeł tekstowych równolegle z przypisanymi wagami: opinie 40\%, opis 25\%, nazwa 15\%, specyfikacje 12\%, kategorie 8\%. Dla każdego źródła wykonywana jest tokenizacja i zliczanie słów pozytywnych oraz negatywnych przy użyciu słowników AFINN-165 i Opinion Lexicon. Wyniki są agregowane według formuły ważonej $S_{koncowy} = \sum_{i=1}^{5} w_i \times S_i$, po czym końcowy wynik zapisywany jest w tabeli ProductSentimentSummary. API zwraca produkty posortowane według zagregowanego sentymentu. Kluczową zaletą tej architektury jest rozwiązanie problemu zimnego startu - produkty bez opinii nadal otrzymują wynik sentymentu na podstawie pozostałych 4 źródeł tekstowych, co umożliwia sortowanie wszystkich produktów w katalogu niezależnie od ilości recenzji.

\subsection*{5.4 Algorytm Apriori - reguły asocjacyjne}
\addcontentsline{toc}{subsection}{5.3 Algorytm Apriori - reguły asocjacyjne}

Algorytm Apriori (Agrawal \& Srikant 1994) \cite{agrawal1994} generuje reguły asocjacyjne typu ,,Często kupowane razem'' poprzez analizę współwystępowania produktów \\w transakcjach, wykorzystując trzy fundamentalne metryki przedstawione we wzorach (3), (4) i (5) w sekcji 5.1:

\textbf{Support (Wsparcie)} - wzór (3) określa częstość współwystępowania produktów A i B w transakcjach. System używa minimalnego progu support = 0.001-0.005 (0.1-0.5\% transakcji, wartość procentowa), co dla 200 zamówień oznacza że para produktów musi wystąpić w minimum 0.2-1 zamówieniu. Próg procentowy skaluje się automatycznie z rozmiarem bazy transakcji.

\textbf{Confidence (Pewność)} - wzór (4) oblicza warunkowe prawdopodobieństwo zakupu B przy założeniu zakupu A. Minimalny próg confidence = 0.01-0.1 (1-10\%) oznacza że reguła jest zapisywana tylko jeśli przynajmniej 1-10\% klientów kupujących A kupuje również B. Domyślna wartość confidence = 0.05 (5\%) została dobrana empirycznie dla optymalnej równowagi między liczbą generowanych reguł a ich jakością.

\textbf{Lift (Wzmocnienie)} - wzór (5) mierzy siłę powiązania między produktami. Interpretacja: lift > 1 wskazuje pozytywną korelację (zakup A zwiększa prawdopodobieństwo zakupu B), lift = 1 oznacza niezależność produktów, lift < 1 wskazuje negatywną korelację. System używa progu lift = 1.0, preferując reguły z lift > 1.5 jako szczególnie wartościowe dla strategii cross-sellingu.

Proces implementacji składa się z dwóch głównych etapów: (1) znajdowania częstych par produktów z obliczeniem Support według wzoru (3), oraz (2) generowania reguł z obliczeniem Confidence i Lift według wzorów (4) i (5). Kluczową optymalizacją jest przycinanie bitmapowe (Zaki 2000), które reprezentuje transakcje jako liczby całkowite z ustawionymi bitami odpowiadającymi produktom. Sprawdzenie czy transakcja zawiera parę produktów wymaga operacji bitowej AND o stałej złożoności zamiast iteracji po liście, co znacząco przyspiesza obliczenia. Wczesne przycinanie eliminuje rzadkie produkty przed obliczaniem par - dzięki właściwości antymonotoniczności Apriori (jeśli produkt jest rzadki, wszystkie jego pary też są rzadkie) zmniejsza liczbę kandydatów o około 80-90\%.

\begin{lstlisting}[style=pseudocode, caption={Apriori - znajdowanie czestych par produktow}]
function znajdz_czeste_pary(transakcje, min_wsp):
    n = |transakcje|
    min_licz = podloga(min_wsp * n)
    
    liczniki = pusty_slownik()
    for t in transakcje:
        for p in t:
            liczniki[p] = liczniki[p] + 1
        end for
    end for
    
    czeste = [p for (p, l) in liczniki if l >= min_licz]
    
    mapa = pusty_slownik()
    for i = 0 to |czeste| - 1:
        mapa[czeste[i]] = i
    end for
    
    bitmapy = pusta_lista()
    for t in transakcje:
        bm = 0
        for p in t:
            if p in mapa then
                bm = bm LUB (1 << mapa[p])
            end if
        end for
        if bm != 0 then 
            dopisz(bitmapy, bm)
        end if
    end for
    
    pary = pusty_slownik()
    for i = 0 to |czeste| - 1:
        bit_i = 1 << i
        for j = i + 1 to |czeste| - 1:
            bit_j = 1 << j
            para_bm = bit_i LUB bit_j
            
            licz = 0
            for bm in bitmapy:
                if (bm AND para_bm) == para_bm then
                    licz = licz + 1
                end if
            end for
            
            if licz >= min_licz then
                pary[{czeste[i], czeste[j]}] = licz / n
            end if
        end for
    end for
    
    wsparcia = {p: liczniki[p]/n for p in czeste}
    return (pary, wsparcia)
end function
\end{lstlisting}

\begin{lstlisting}[style=pseudocode, caption={Apriori - generowanie regul z obliczeniem lift i confidence}]
function generuj_reguly_z_par(pary, wsparcia, min_pewn):
    reguly = pusta_lista()
    
    for ({p1, p2}, wsp_para) in pary:
        wsp1 = wsparcia[p1]
        wsp2 = wsparcia[p2]
        
        pewn_1_2 = wsp_para / wsp1
        pewn_2_1 = wsp_para / wsp2
        
        lift = wsp_para / (wsp1 * wsp2)
        
        if pewn_1_2 >= min_pewn then
            dopisz(reguly, {od: p1, do: p2, 
                           wsparcie: wsp_para, 
                           pewnosc: pewn_1_2, 
                           lift: lift})
        end if
        
        if pewn_2_1 >= min_pewn then
            dopisz(reguly, {od: p2, do: p1, 
                           wsparcie: wsp_para, 
                           pewnosc: pewn_2_1, 
                           lift: lift})
        end if
    end for
    
    sortuj(reguly, wedlug=(lift, pewnosc), malejaco)
    return reguly
end function
\end{lstlisting}

\newpage
\textbf{Diagram sekwencji: Algorytm Apriori}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/associationDiagram.png}
  \caption{Diagram sekwencji: Algorytm Apriori.}
  \label{fig:apriori_sequence}
\end{figure}

Diagram \ref{fig:apriori_sequence} przedstawia przepływ procesu generowania reguł asocjacyjnych algorytmem Apriori. Administrator wywołuje aktualizację reguł przez panel administracyjny, co inicjuje ekstrakcję transakcji z bazy OrderProduct - system wybiera tylko zamówienia zawierające 2 lub więcej produktów, ponieważ pojedyncze zakupy nie tworzą asocjacji. Algorytm wykonuje wczesne przycinanie, eliminując rzadkie produkty o wsparciu poniżej 1\% transakcji, co znacznie redukuje przestrzeń obliczeniową - dzięki właściwości antymonotoniczności Apriori (jeśli produkt jest rzadki, wszystkie jego pary też są rzadkie) eliminuje się około 80-90\% kandydatów. Transakcje konwertowane są do reprezentacji bitmapowej, gdzie każda transakcja to liczba całkowita z ustawionymi bitami odpowiadającymi produktom - pozwala to wykonywać sprawdzenia przynależności jedną operacją bitową AND zamiast iteracji po liście. System generuje częste 2-itemsety (pary produktów) używając operacji bitowych, po czym dla każdego częstego itemsetu obliczane są trzy metryki: Support według wzoru (3), Confidence według wzoru (4) i Lift według wzoru (5). Reguły filtrowane są według progów (\texttt{min\_support} $\geq$ 0.01, \texttt{min\_confidence} $\geq$ 0.1, \texttt{lift} $\geq$ 1.0) i zapisywane w bazie danych tabelą AssociationRule poprzez operacje zbiorcze bulk insert z rozmiarem partii 500 rekordów, co znacznie przyspiesza zapis. Zaimplementowane optymalizacje obejmują przycinanie bitmapowe dla szybkich operacji, wczesne przycinanie eliminujące większość kandydatów, operacje bitowe AND o optymalnej złożoności obliczeniowej, oraz operacje zbiorcze minimalizujące liczbę transakcji bazodanowych.

\newpage
\section*{Rozdzia\l{} 6}
\addcontentsline{toc}{section}{Rozdział 6: Funkcjonowanie systemu rekomendacji w praktyce}
\section*{Funkcjonowanie systemu rekomendacji w praktyce}

Rozdział przedstawia funkcjonowanie zaimplementowanych metod rekomendacyjnych w działającym systemie e-commerce. Omówiono perspektywę użytkownika końcowego korzystającego z rekomendacji produktów oraz narzędzia diagnostyczne służące do weryfikacji poprawności działania algorytmów. Struktura rozdziału została zaprojektowana zgodnie z naturalną kolejnością zapoznawania się z systemem - najpierw prezentacja funkcjonalności z perspektywy użytkownika końcowego, następnie panel konfiguracji dla administratora.

\subsection*{6.1 Metoda Collaborative Filtering - Item-Based}
\addcontentsline{toc}{subsection}{6.1 Metoda Collaborative Filtering - Item-Based}

\textbf{Widok strony głównej z rekomendacjami}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{images/mainSectionView1.png}
  \caption{Strona główna - pierwsza sekcja rekomendacji.}
  \label{fig:main_cf_1}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\textwidth]{images/mainSectionView3.png}
  \caption{Strona główna - druga sekcja rekomendacji.}
  \label{fig:main_cf_3}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/mainSectionView2.png}
  \caption{Strona główna - trzecia sekcja rekomendacji.}
  \label{fig:main_cf_2}
\end{figure}

Rysunki \ref{fig:main_cf_1}, \ref{fig:main_cf_3} i \ref{fig:main_cf_2} przedstawiają trzy sekcje rekomendacji na stronie głównej aplikacji. Sekcje te są identyczne pod względem funkcjonalności i prezentują produkty w formie interaktywnych sliderów umożliwiających przewijanie oferty. Różnica między sekcjami polega wyłącznie na kolejności wyświetlania produktów - każda sekcja losuje inny podzbiór z pełnej listy rekomendacji, co zwiększa różnorodność prezentowanych ofert i minimalizuje efekt monotonii. Wszystkie trzy sekcje dynamicznie dostosowują wyświetlane produkty w zależności od metody rekomendacyjnej wybranej przez administratora w panelu zarządzania (rys. \ref{fig:admin_recommendation_settings}). Gdy aktywny jest algorytm Collaborative Filtering, wszystkie sekcje prezentują produkty dobrane na podstawie podobieństwa obliczonego metryką Adjusted Cosine Similarity zgodnie ze wzorem (1) z sekcji 5.1.

\textbf{Panel debugowania Collaborative Filtering}

Panel debugowania Collaborative Filtering znajduje się w sekcji administracyjnej systemu i służy do weryfikacji poprawności działania algorytmu oraz analizy wygenerowanych rekomendacji. Narzędzie to jest przeznaczone dla administratorów systemu oraz programistów przeprowadzających testy działania algorytmu. Panel umożliwia podgląd macierzy podobieństw produktów, sprawdzenie statusu wykonania obliczeń, analizę przykładowych rekomendacji oraz weryfikację zgodności wyników z oczekiwaniami biznesowymi. Dzięki temu administratorzy mogą szybko zdiagnozować ewentualne problemy w działaniu algorytmu, takie jak brak rekomendacji dla niektórych produktów, nieprawidłowe wartości podobieństwa czy błędy w strukturze danych.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/collaborativeDebug1.png}
  \caption{Panel debugowania Collaborative Filtering - formuła algorytmu i dane z bazy.}
  \label{fig:cf_debug_1}
\end{figure}

Rysunek \ref{fig:cf_debug_1} przedstawia sekcję debugowania algorytmu Collaborative Filtering w panelu administratora. Pod numerem (1) widoczna jest nazwa algorytmu ,,Item-Based Collaborative Filtering'', formuła matematyczna Adjusted Cosine Similarity oraz status wykonania. Pod numerem (2) znajdują się dane z bazy danych - tabela \texttt{method\_product\_similarity} zawierająca pary produktów wraz z obliczonymi współczynnikami podobieństwa oraz fragment macierzy podobieństw w formacie wizualnym.

\newpage
\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{images/collaborativeDebug2.png}
  \caption{Panel debugowania Collaborative Filtering - podsumowanie obliczeń.}
  \label{fig:cf_debug_2}
\end{figure}

Rysunek \ref{fig:cf_debug_2} pokazuje drugą część panelu debugowania Collaborative Filtering. System wyświetla podsumowanie macierzy, statystyki cache oraz przykład rekomendacji dla pierwszego użytkownika z bazy danych.

\textbf{Rekomendacje w panelu klienta}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{images/recomendationSystemAdmin4.png}
  \caption{Dashboard klienta z sekcją rekomendacji.}
  \label{fig:client_dashboard_cf}
\end{figure}

Rysunek \ref{fig:client_dashboard_cf} przedstawia dashboard klienta z sekcją spersonalizowanych rekomendacji. Produkty są dobierane na podstawie pełnej historii zakupów użytkownika z zastosowaniem metody Collaborative Filtering.

\newpage
\subsection*{6.2 Metoda analizy sentymentu}
\addcontentsline{toc}{subsection}{6.2 Metoda analizy sentymentu}

\textbf{Interfejs opinii w aplikacji}

System opinii jest zintegrowany w dwóch kluczowych miejscach interfejsu użytkownika. Użytkownicy mogą dodawać opinie bezpośrednio w panelu klienta po zakupie produktu oraz przeglądać wszystkie opinie na karcie produktu.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.92\textwidth]{images/opinionView.jpg}
  \caption{Formularz dodawania opinii na stronie produktu z oceną gwiazdkową \\i recenzją tekstową.}
  \label{fig:opinion_view1}
\end{figure}

Rysunek \ref{fig:opinion_view1} przedstawia sekcję dodawania opinii na karcie produktu. Użytkownik może wystawić ocenę gwiazdkową w skali 1-5 gwiazdek oraz napisać szczegółową recenzję tekstową opisującą swoje doświadczenia z produktem. Po dodaniu opinii przez użytkownika system automatycznie przetwarza tekst opinii algorytmem analizy sentymentu, oblicza wartość sentiment score w zakresie [-1, 1] według wzoru (2) z sekcji 5.1, klasyfikuje opinię jako pozytywną, neutralną lub negatywną, aktualizuje statystyki sentymentu produktu w tabeli ProductSentimentSummary, przelicza zagregowany wynik sentymentu produktu łączący pięć źródeł tekstowych zgodnie z wagami opisanymi w sekcji 5.3, oraz odświeża ranking produktów w wyszukiwarce jeśli użytkownik ma ustawione sortowanie według sentymentu.

\newpage
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/opinionView2.jpg}
  \caption{Lista opinii produktu z badge'ami sentymentu i oceną gwiazdkową.}
  \label{fig:opinion_view2}
\end{figure}

Rysunek \ref{fig:opinion_view2} pokazuje listę wszystkich opinii dla danego produktu. Każda opinia wyświetla email użytkownika, ocenę gwiazdkową oraz pełną treść recenzji tekstowej. System opinii pełni kluczową rolę w dwóch aspektach aplikacji. Po pierwsze, realizuje mechanizm social proof budujący zaufanie do produktów poprzez autentyczne recenzje od rzeczywistych klientów - potencjalni kupujący mogą zapoznać się z doświadczeniami innych użytkowników przed podjęciem decyzji zakupowej. Po drugie, opinie są automatycznie przetwarzane przez algorytm analizy sentymentu jako jedno z pięciu źródeł tekstowych (z wagą 40\% w wieloźródłowej agregacji opisanej w sekcji 5.3), co czyni je najważniejszym elementem systemu oceny jakości produktów.

\textbf{Wyszukiwarka z sortowaniem według sentymentu}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.65\textwidth]{images/searchSentimentView.png}
  \caption{Wyszukiwarka produktów z sortowaniem według sentymentu.}
  \label{fig:sentiment_search}
\end{figure}

Rysunek \ref{fig:sentiment_search} przedstawia wyszukiwarkę z wynikami posortowanymi według zagregowanego sentymentu. Każdy produkt wyświetla wynik sentiment score, kategorię oraz rozkład opinii.

\newpage
\textbf{Panel debugowania analizy sentymentu}

Panel debugowania analizy sentymentu znajduje się w sekcji administracyjnej systemu i służy do weryfikacji poprawności działania algorytmu oraz analizy zagregowanych wyników sentymentu produktów. Narzędzie to jest przeznaczone dla administratorów systemu oraz programistów przeprowadzających testy działania algorytmu. Panel umożliwia podgląd wyników z źródeł tekstowych (opinie, opis, nazwa, specyfikacje, kategorie) wraz z przypisanymi wagami, sprawdzenie statusu kategorii sentymentu oraz analizę rozkładu opinii pozytywnych, neutralnych i negatywnych.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/sentimentDebug2.png}
  \caption{Panel debugowania analizy sentymentu.}
  \label{fig:sentiment_debug}
\end{figure}

Rysunek \ref{fig:sentiment_debug} pokazuje panel debugowania analizy sentymentu. Administrator może wybrać dowolny produkt z listy rozwijanej i sprawdzić wynik zagregowany, status kategorii oraz szczegółowe informacje z poszczególnych źródeł tekstowych.

\newpage
\subsection*{6.3 Metoda reguł asocjacyjnych (Apriori)}
\addcontentsline{toc}{subsection}{6.3 Metoda reguł asocjacyjnych (Apriori)}

\textbf{Widok rekomendacji Apriori na stronie produktu}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{images/associationView.png}
  \caption{Sekcja ,,Frequently Bought Together'' na stronie produktu.}
  \label{fig:association_view}
\end{figure}

Rysunek \ref{fig:association_view} przedstawia sekcję ,,Frequently Bought Together'' na stronie produktu. Pod numerem (1) widoczne są produkty dodane przez użytkownika do koszyka. Pod numerem (2) system wyświetla produkty proponowane na podstawie reguł asocjacyjnych wraz z metrykami lift, support i confidence.

\textbf{Panel zarządzania regułami asocjacyjnymi}

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{images/associationAdmin.png}
  \caption{Panel administracyjny zarządzania regułami Apriori.}
  \label{fig:association_admin}
\end{figure}

Rysunek \ref{fig:association_admin} pokazuje panel administracyjny z listą wygenerowanych reguł asocjacyjnych. Pod numerem (1) znajduje się lista par produktów często kupowanych razem. Pod numerem (2) wyświetlane są szczegółowe metryki każdej reguły - support, confidence i lift.

\textbf{Panel debugowania reguł asocjacyjnych}

Panel debugowania reguł asocjacyjnych znajduje się w sekcji administracyjnej systemu i służy do weryfikacji poprawności działania wygenerowanych reguł. Panel umożliwia wybór dowolnego produktu z listy rozwijanej, podgląd wszystkich reguł asocjacyjnych dla wybranego produktu wraz z metrykami (support, confidence, lift), analizę top 10 najsilniejszych reguł posortowanych według wartości lift oraz sprawdzenie rozkładu wartości lift i porównanie ze średnimi globalnymi.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/associationDebug1.png}
  \caption{Panel debugowania Apriori - wybór produktu i dane z bazy.}
  \label{fig:association_debug_1}
\end{figure}

Rysunek \ref{fig:association_debug_1} przedstawia pierwszy ekran panelu debugowania algorytmu Apriori. Pod numerem (1) administrator wybiera produkt z listy rozwijanej. Poniżej system wyświetla dane produktu z bazy danych, obliczenia transakcji oraz wszystkie reguły asocjacyjne dla wybranego produktu.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/associationDebug2.png}
  \caption{Panel debugowania Apriori - top 10 reguł i szczegóły analizy.}
  \label{fig:association_debug_2}
\end{figure}

Rysunek \ref{fig:association_debug_2} pokazuje drugą część panelu debugowania Apriori. Pod numerem (1) znajduje się ranking top 10 reguł asocjacyjnych dla wybranego produktu posortowanych według lift. Pod numerem (2) wyświetlane są szczegółowe analizy reguł dla produktów, w tym rozkład wartości lift, średnie metryki oraz porównanie z globalnymi statystykami.

\newpage
\subsection*{6.4 Konfiguracja metod rekomendacji w panelu administratora}
\addcontentsline{toc}{subsection}{6.4 Konfiguracja metod rekomendacji w panelu administratora}

Panel administracyjny umożliwia dynamiczne przełączanie między trzema metodami rekomendacji wyświetlanymi na stronie głównej aplikacji.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/recomendationSystemAdmin2.png}
  \caption{Panel zarządzania metodami rekomendacji.}
  \label{fig:admin_recommendation_settings}
\end{figure}

Rysunek \ref{fig:admin_recommendation_settings} przedstawia panel konfiguracji z opcjami metod rekomendacyjnych. Administrator może wybrać aktywny algorytm, który będzie wykorzystywany we wszystkich sekcjach rekomendacji na stronie głównej. System zawiera łącznie sześć metod rekomendacyjnych zaimplementowanych w ramach dwóch prac inżynierskich. W ramach niniejszej pracy zaimplementowano:

\begin{itemize}
\item \textbf{Collaborative Filtering} - rekomendacje oparte na historii zakupów użytkowników (opisane w niniejszej pracy).
\end{itemize}

Pozostałe metody (Content-Based Filtering, Fuzzy Logic) zostały zaimplementowane przez współautora systemu i opisane w odrębnej pracy inżynierskiej.

Zmiana metody następuje natychmiast po zapisaniu ustawień i wpływa na wszystkie sekcje rekomendacji w aplikacji.

\subsection*{Mechanizmy optymalizacji systemu}

System wykorzystuje mechanizmy optymalizacji dla zapewnienia wydajności:

\textbf{Prekalkulacja w bazie danych}

Wszystkie trzy algorytmy zapisują wyniki do dedykowanych tabel z indeksami przyspieszającymi zapytania:

\begin{itemize}
\item \texttt{method\_product\_similarity} - macierz podobieństw Collaborative Filtering,
\item \texttt{method\_productassociation} - reguły asocjacyjne Apriori,
\item \texttt{method\_product\_sentiment\_summary} - zagregowany sentyment produktów.
\end{itemize}

\textbf{Django Signals - automatyczna aktualizacja}

System wykorzystuje mechanizm Django Signals do automatycznego przeliczania rekomendacji po zmianach danych:

\begin{itemize}
\item Nowe zamówienie - przeliczenie macierzy Collaborative Filtering,
\item Nowa opinia - aktualizacja sentymentu produktu,
\item Nowy produkt - automatyczna analiza sentymentu opisu i nazwy.
\end{itemize}

\textbf{Operacje zbiorcze}

System używa operacji zbiorczych (bulk operations) dla zapisu wielu rekordów jednocześnie, co znacząco przyspiesza operacje zapisu do bazy danych.
\clearpage

\newpage
\section*{Rozdzia\l{} 7}
\addcontentsline{toc}{section}{Rozdział 7: Porównanie i ewaluacja metod rekomendacyjnych}
\section*{Porównanie i ewaluacja metod rekomendacyjnych}

Rozdział przedstawia praktyczne porównanie sześciu metod rekomendacyjnych zaimplementowanych w aplikacji we współpracy dwuosobowej. Ewaluacja koncentruje się na trzech parach metod o komplementarnym charakterze: Collaborative Filtering vs Content-Based Filtering (podejście behawioralne vs atrybutowe), Sentiment Analysis vs Fuzzy Logic (uniwersalne vs spersonalizowane), oraz Apriori vs Markov Chain (współzakupy vs sekwencje czasowe).

\subsection*{Krótka charakterystyka metod współautora projektu}

\textbf{Content-Based Filtering (CBF)} analizuje cechy produktów i znajduje podobieństwa między nimi. System sprawdza kategorie produktu, jego tagi, przedział cenowy oraz słowa kluczowe z opisu. Każda z tych cech ma przypisaną wagę - kategorie są najważniejsze (40\%), następnie tagi (30\%), cena (20\%) i słowa kluczowe (10\%). Dzięki temu laptop jest podobny do innego laptopa przez wspólne cechy, nie przez to że użytkownicy kupowali je razem. Wyniki podobieństw są zapisywane w modelu \texttt{ProductSimilarity} z oznaczeniem typu \texttt{content\_based}. Zaletą tej metody jest natychmiastowe działanie dla nowych produktów - wystarczą same cechy z formularza dodawania produktu. Algorytm ekstraktuje słowa kluczowe z opisów, co pozwala uwzględnić nawet szczegółowe specyfikacje techniczne. W praktyce metoda najlepiej sprawdza się w katalogach z dobrze opisanymi produktami o jasno zdefiniowanych cechach.

\textbf{Fuzzy Logic} personalizuje rekomendacje według profilu cenowego użytkownika. System używa sześciu reguł typu ,,jeśli-to'' (IF-THEN), które oceniają produkty na podstawie trzech kryteriów: cena (tania/średnia/droga), jakość z ocen użytkowników (niska/średnia/wysoka) oraz popularność mierzona liczbą zamówień. Dla każdego użytkownika budowany jest profil na podstawie jego historii zakupów -- system oblicza parametr wrażliwości cenowej, który określa czy użytkownik preferuje tanie produkty czy drogie premium. Ten sam produkt może być polecony użytkownikowi premium jako ,,wysoka jakość, warta swojej ceny'' i odrzucony dla użytkownika budżetowego jako ,,zbyt drogi''. Metoda jest dostępna w dedykowanej sekcji panelu klienta. Wnioskowanie rozmyte używa funkcji przynależności trójkątnych, które modelują płynne przejścia między kategoriami cenowymi zamiast ostrych granic. Dzięki temu system unika sytuacji gdzie produkt za 499~PLN jest ,,tani'' a za 501~PLN nagle staje się ,,drogi''.

\newpage
\textbf{Modele Probabilistyczne} przewidują przyszłe zakupy łącząc dwa algorytmy. Pierwszy analizuje sekwencje zakupów w czasie i przewiduje którą kategorię użytkownik prawdopodobnie kupi następną (np. ,,po laptopie zwykle następują akcesoria komputerowe''). Drugi algorytm ocenia prawdopodobieństwo zakupu na podstawie pięciu cech użytkownika: łączna liczba zamówień, średnia wartość zamówienia, dni od ostatniego zakupu, ulubiona kategoria oraz częstotliwość zakupów. Oba modele działają razem, co pozwala identyfikować użytkowników zagrożonych odejściem oraz planować kampanie retention. Wyniki są widoczne w sekcji analiz probabilistycznych panelu klienta z~wizualizacją łańcucha przejść między kategoriami. Model sekwencji wykorzystuje macierz przejść trenowaną na rzeczywistych sekwencjach zamówień, co pozwala modelować zachowania specyficzne dla danego sklepu.

\subsection*{Porównanie par metod}

\subsubsection*{Collaborative Filtering vs Content-Based Filtering}

Tabela \ref{tab:cf-vs-cbf} przedstawia kluczowe różnice między metodami CF i CBF. Item-Based CF analizuje historię zakupów i buduje macierz podobieństw produktów używając algorytmu Adjusted Cosine Similarity z centrowaniem średniej użytkownika. CBF ekstraktuje cechy bezpośrednio z atrybutów produktów (kategoria, tagi, cena) bez potrzeby historii zakupów.

\begin{table}[H]
\centering
\caption{Porównanie metod Collaborative Filtering i Content-Based Filtering}
\label{tab:cf-vs-cbf}
\begin{tabular}{|p{3cm}|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{Kryterium} & \textbf{CF (Item-Based)} & \textbf{CBF (Feature-Based)} \\
\hline
Źródło danych & Historia zakupów & Atrybuty produktów \\
\hline
Pokrycie katalogu & Częściowe - tylko produkty z historią & Pełne - każdy produkt ma cechy \\
\hline
Problem cold start & Występuje dla nowych produktów & Nie występuje \\
\hline
Typ powiązań & Nieoczywiste cross-category (aparat → plecak) & Oczywiste w kategorii (laptop A → laptop B) \\
\hline
Algorytm & Adjusted Cosine + centrowanie średniej & Weighted TF-IDF + Cosine Similarity \\
\hline
Przechowywanie & \texttt{ProductSimilarity} (type='collaborative') & \texttt{ProductSimilarity} (type='content\_based') \\
\hline
Złożoność & Wyższa - macierz wszystkich produktów & Niższa - wektory powiązanych produktów \\
\hline
\end{tabular}
\end{table}

\newpage
\textbf{Różnice w działaniu:} CF wykrywa powiązania które nie są oczywiste na podstawie samych cech produktów. Jeśli użytkownicy kupujący aparaty fotograficzne często kupują też plecaki turystyczne, CF połączy te produkty mimo różnych kategorii. CBF natomiast zaleci laptopy podobne do laptopów -- produkty z tej samej kategorii, w podobnym przedziale cenowym, o podobnych tagach. CF wymaga dużo danych historycznych aby działać dobrze, podczas gdy CBF działa od razu bo każdy produkt ma cechy.

\textbf{Zastosowanie praktyczne:} W projekcie obie metody działają równolegle. Macierz podobieństw CF jest obliczana offline na podstawie historii zakupów \textit{wszystkich} użytkowników --- to nie wymaga logowania. Natomiast spersonalizowane rekomendacje ,,Polecane dla Ciebie'' wymagają zalogowania, aby system wiedział \textit{która} historia zakupów ma być podstawą rekomendacji. CBF jest używany dla nowych produktów bez historii współzakupów oraz jako fallback --- gwarantuje że każdy produkt może być rekomendowany nawet bez danych transakcyjnych. Dla sklepów z małą liczbą transakcji CBF jest bezpieczniejszym wyborem. Dla dojrzałych sklepów z bogatą historią CF odkrywa ciekawsze powiązania które zwiększają cross-selling.

\subsubsection*{Sentiment Analysis vs Fuzzy Logic}

Tabela \ref{tab:sentiment-vs-fuzzy} zestawia metody uniwersalną (Sentiment) i spersonalizowaną (Fuzzy Logic). Sentiment agreguje tekst z pięciu źródeł używając leksykonów Opinion Lexicon (Hu \& Liu 2004) i AFINN-165 (Nielsen 2011). Fuzzy Logic buduje indywidualny \texttt{FuzzyUserProfile} z historii zakupów każdego użytkownika.

\begin{table}[H]
\centering
\caption{Porównanie metod Sentiment Analysis i Fuzzy Logic}
\label{tab:sentiment-vs-fuzzy}
\begin{tabular}{|p{3cm}|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{Kryterium} & \textbf{Sentiment (uniwersalny)} & \textbf{Fuzzy (spersonalizowany)} \\
\hline
Personalizacja & Nie - identyczny dla wszystkich & Tak - \texttt{FuzzyUserProfile} z parametrem \texttt{price\_sensitivity} \\
\hline
Źródła danych & 5 źródeł: opinie, opis, nazwa, specs, kategorie & Historia: średnia cena, częstotliwość kategorii, liczba zamówień \\
\hline
Pokrycie & Pełne - każdy produkt ma tekst & Częściowe - zakres cenowy użytkownika \\
\hline
Typ oceny & Obiektywna jakość (pozytywny/negatywny) & Relatywna wartość (,,tani'' vs ,,drogi'') \\
\hline
Algorytm & Leksykony słów pozytywnych/negatywnych & Mamdani z 6 regułami IF-THEN \\
\hline
Cache & Tak - model \texttt{ProductSentimentSummary} & Nie - dynamiczne \\
\hline
Użycie & Wyszukiwarka (sortowanie) & Panel klienta (sekcja Fuzzy) \\
\hline
\end{tabular}
\end{table}

\textbf{Różnice w działaniu:} Sentiment ocenia czy produkt jest obiektywnie dobry czy zły analizując tekst opinii, opisów i specyfikacji. Laptop z wieloma pozytywnymi opiniami dostanie wysoki score niezależnie od tego kto go przegląda. Fuzzy Logic natomiast ocenia czy produkt pasuje do konkretnego użytkownika - ten sam laptop może być ,,zbyt drogi'' dla użytkownika budżetowego i ,,świetna wartość'' dla użytkownika premium. Sentiment jest szybszy bo wynik jest obliczany raz i zapisywany w bazie, Fuzzy musi przeliczać 6 reguł dla każdego użytkownika osobno.

\textbf{Zastosowanie praktyczne:} Metody działają komplementarnie. Sentiment jest używany w wyszukiwarce do sortowania produktów według jakości -- pokazuje obiektywnie najlepsze produkty na górze listy. Fuzzy Logic jest w panelu klienta jako osobna sekcja rekomendacji -- filtruje produkty według profilu cenowego użytkownika. Użytkownik który zawsze kupuje produkty poniżej 300~PLN nie zobaczy laptopów za 5000~PLN nawet jeśli mają doskonałe opinie. System buduje profil automatycznie analizując poprzednie zakupy.

\subsubsection*{Apriori vs Markov Chain}

Tabela \ref{tab:apriori-vs-markov} porównuje metody przewidywania zakupów. Apriori analizuje współwystępowanie produktów w koszykach zakupowych i generuje reguły asocjacyjne z metrykami support, confidence, lift. Markov analizuje sekwencje kategorii w czasie i przewiduje przyszłe wizyty.

\begin{table}[H]
\centering
\caption{Porównanie metod Apriori i Markov Chain}
\label{tab:apriori-vs-markov}
\begin{tabular}{|p{3cm}|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{Kryterium} & \textbf{Apriori (współzakupy)} & \textbf{Markov (sekwencje)} \\
\hline
Zakres czasowy & Teraźniejszość - koszyk zakupowy & Przyszłość - następna wizyta \\
\hline
Typ predykcji & Produkty kupowane razem (laptop + mysz) & Kategorie w kolejnych transakcjach \\
\hline
Pokrycie & Częściowe - produkty kupione razem & Szerokie - poziom kategorii \\
\hline
Algorytm & Bitmap pruning + antymonotoniczność & First-order Markov (48 stanów) \\
\hline
Przechowywanie & Model \texttt{ProductAssociation} & Macierz przejść z historii \\
\hline
Optymalizacja & Bitmap - liczby binarne, operacje AND & Naive Bayes (5 cech użytkownika) \\
\hline
Użycie & Koszyk - ,,Często kupowane razem'' & Panel - wizualizacja przejść \\
\hline
Wartość & Cross-selling (↑ wartość transakcji) & Retention (identyfikacja churn) \\
\hline
\end{tabular}
\end{table}

\textbf{Różnice w działaniu:} Apriori szuka produktów które ludzie kupują razem w jednym zamówieniu. Jeśli klient dodaje laptop do koszyka, Apriori pokaże mysz i torbę bo poprzedni klienci kupowali to razem. Metryki support, confidence i lift określają jak silne jest powiązanie. Markov natomiast analizuje kolejność zakupów w czasie -- jeśli użytkownik kupił laptop w styczniu, Markov przewiduje że w lutym prawdopodobnie wróci po akcesoria komputerowe. Apriori jest szybszy bo używa bitmap pruning (operacje bitowe zamiast pętli), Markov wymaga więcej obliczeń bo musi przeanalizować całą historię użytkownika.

\textbf{Zastosowanie praktyczne:} Apriori maksymalizuje wartość bieżącej transakcji -- pokazuje dodatkowe produkty w koszyku które klient może chcieć kupić od razu. Markov służy do planowania kampanii retention -- identyfikuje użytkowników którzy prawdopodobnie nie wrócą do sklepu i można im wysłać rabat zachęcający do powrotu. W panelu admina Markov wizualizuje przepływ między kategoriami jako graf, co pomaga zrozumieć ścieżki zakupowe klientów i zaplanować strategię merchandisingową.

Tabela \ref{tab:summary} zestawia wszystkie sześć metod według kluczowych charakterystyk. Każda metoda ma specyficzne zastosowanie w zależności od kontekstu użycia i dostępnych danych.

\begin{table}[H]
\centering
\caption{Zestawienie zbiorcze sześciu metod rekomendacyjnych}
\label{tab:summary}
\footnotesize
\begin{tabular}{|p{2.2cm}|p{2.5cm}|p{2.2cm}|p{2.8cm}|p{2.5cm}|}
\hline
\textbf{Metoda} & \textbf{Dane} & \textbf{Cold start} & \textbf{Typ} & \textbf{Zastosowanie} \\
\hline
CF & Historia zakupów & Tak (nowe produkty) & Powiązania cross-category & Discovery \\
\hline
CBF & Atrybuty produktów & Nie & Podobieństwa w kategorii & Nowe produkty \\
\hline
Sentiment & Tekst & Częściowy & Ocena jakości & Ranking \\
\hline
Fuzzy & Historia użytkownika & Tak (nowi użytkownicy) & Profil cenowy & Personalizacja \\
\hline
Apriori & Koszyki & Tak (nowe produkty) & Komplementarne & Cross-selling \\
\hline
Markov & Sekwencje & Nie & Predykcja kategorii & Retention \\
\hline
\end{tabular}
\end{table}

\textbf{Wnioski z implementacji:} 

\textbf{(1) Metody uzupełniają się wzajemnie.} Żadna pojedyncza metoda nie rozwiązuje wszystkich problemów rekomendacji. CF doskonale wykrywa nieoczywiste powiązania ale wymaga bogatej historii. CBF gwarantuje pokrycie wszystkich produktów ale generuje oczywiste sugestie. Sentiment ocenia jakość ale nie personalizuje. Fuzzy personalizuje ale wymaga profilu użytkownika. Najlepsze rezultaty daje połączenie wszystkich metod w~różnych częściach interfejsu.

\textbf{(2) Wybór metody zależy od dojrzałości sklepu.} Dla nowego sklepu z małą liczbą produktów i transakcji najlepszy jest start z CBF i Sentiment -- działają od razu bez historii. Po zgromadzeniu kilkuset transakcji można dodać Apriori do koszyka dla cross-sellingu. Gdy sklep ma tysiące transakcji i setki aktywnych użytkowników, CF i Markov zaczynają dawać wartość odkrywając wzorce zachowań.

\textbf{(3) Optymalizacja jest kluczowa dla wydajności.} Bitmap pruning w Apriori znacząco przyspiesza przetwarzanie -- reprezentacja transakcji jako liczb binarnych pozwala na operacje bitowe zamiast iteracji po listach. Cache'owanie wyników Sentiment eliminuje powtarzalne obliczenia. Indeksowanie w bazie danych (model \texttt{ProductSimilarity}) przyspiesza wyszukiwanie podobnych produktów.

\textbf{(4) Praktyczne zastosowanie jest różne.} Apriori daje efekt natychmiast -- sekcja ,,Często kupowane razem'' w koszyku bezpośrednio zwiększa wartość zamówienia. Markov ma wartość długoterminową -- identyfikuje użytkowników którzy przestają być aktywni i pozwala reagować kampaniami. CF i CBF działają w tle stale sugerując produkty. Sentiment pomaga w nawigacji po katalogu.

\textbf{Ograniczenia badania:} System był testowany z danymi z seedera, nie z prawdziwymi użytkownikami. Rzeczywiste wzorce zachowań mogą być inne. Wydajność mierzona była bez równoczesnego obciążenia wieloma użytkownikami. Brak testów A/B uniemożliwia precyzyjne określenie wpływu każdej metody na współczynnik konwersji. Przyszłe wdrożenie produkcyjne wymaga monitorowania rzeczywistych metryk biznesowych.

\clearpage

\newpage
\addcontentsline{toc}{section}{Rozdział 8: Podsumowanie i wnioski końcowe}
\section*{Podsumowanie i wnioski końcowe}

Niniejsza praca przedstawiła proces implementacji oraz analizy kompletnego systemu e-commerce wyposażonego w mechanizmy rekomendacji produktów. System został opracowany od podstaw we współpracy dwuosobowej, przy czym w ramach niniejszej pracy zaimplementowano trzy metody rekomendacyjne: Collaborative Filtering z metryką Adjusted Cosine Similarity, analizę sentymentu opartą na podejściu słownikowym oraz reguły asocjacyjne wykorzystujące algorytm Apriori.

\subsection*{Ograniczenia systemu}

\noindent
W trakcie realizacji projektu zidentyfikowano następujące ograniczenia:

\textbf{Problem zimnego startu} — algorytmy Collaborative Filtering oraz Apriori wymagają historycznych danych o interakcjach użytkowników z produktami. Dla nowych użytkowników bez historii zakupów oraz nowych produktów bez opinii mechanizmy te nie są w stanie generować efektywnych rekomendacji. Analiza sentymentu częściowo kompensuje to ograniczenie, ponieważ może ocenić jakość produktu na podstawie jego opisu, specyfikacji technicznych oraz nazwy, nawet w przypadku braku opinii użytkowników.

\textbf{Ograniczenia analizy sentymentu} — zastosowane podejście słownikowe nie radzi sobie efektywnie z negacją językową (przykład: ,,nie polecam'') oraz z ironią \\i sarkazmem. Słowa pozytywne w kontekście negatywnym mogą być błędnie klasyfikowane, co wpływa na dokładność oceny sentymentu. Rozwiązanie tego problemu wymagałoby zastosowania bardziej zaawansowanych technik przetwarzania języka naturalnego, takich jak modele kontekstowe.

\textbf{Skalowalność dla bardzo dużych katalogów} — dla katalogów produktów przekraczających tysiące pozycji mogą wystąpić wyzwania wydajnościowe wymagające dalszych optymalizacji, takich jak partycjonowanie danych, rozproszenie obliczeń lub zastosowanie dedykowanych struktur danych.

\subsection*{Kierunki dalszego rozwoju}

\noindent
Zidentyfikowano następujące kierunki rozwoju systemu:

\textbf{Zastosowanie głębokiego uczenia maszynowego} — obecny system wykorzystuje klasyczne algorytmy rekomendacyjne oparte na analizie podobieństw oraz regułach asocjacyjnych. Zastosowanie sieci neuronowych, takich jak autoencodery czy sieci rekurencyjne, mogłoby umożliwić automatyczne uczenie się ukrytych wzorców w danych bez konieczności ręcznego definiowania reguł. Przykładowo, sieci neuronowe mogłyby odkryć nieoczywiste zależności między produktami oraz preferencjami użytkowników, które nie są widoczne w tradycyjnych metrykach podobieństwa.

\textbf{Rekomendacje w czasie rzeczywistym} — obecny system wykorzystuje mechanizm cache'owania z okresem ważności 2 godzin (CACHE\_TIMEOUT\_LONG = 7200 sekund), co oznacza, że rekomendacje są przeliczane cyklicznie. Implementacja systemu aktualizującego rekomendacje w czasie rzeczywistym po każdej akcji użytkownika (przeglądanie produktów, dodawanie do koszyka, finalizacja zakupu) mogłaby znacząco zwiększyć trafność sugestii poprzez uwzględnienie bieżącego kontekstu sesji zakupowej. Jednakże należy rozważyć, czy takie rozwiązanie nie wpłynęłoby negatywnie na efektywność działania całego systemu ze względu na konieczność ciągłego przeliczania rekomendacji.

\textbf{Zaawansowane metody obsługi zimnego startu} — zastosowanie technik faktoryzacji macierzy, takich jak Singular Value Decomposition (SVD), mogłoby umożliwić generowanie rekomendacji dla nowych produktów na podstawie ich cech (kategoria, cena, marka, specyfikacja) oraz analogii do istniejących produktów.

\subsection*{Wnioski końcowe}

Zrealizowany system stanowi kompletne rozwiązanie e-commerce z mechanizmami rekomendacji produktów, gotowe do wdrożenia w środowisku produkcyjnym. Implementacja od podstaw bez wykorzystania gotowych bibliotek rekomendacyjnych umożliwiła pełne zrozumienie mechanizmów działania algorytmów oraz ich świadome dostosowanie do specyfiki handlu elektronicznego. Komplementarność zastosowanych metod — Collaborative Filtering dla identyfikacji produktów podobnych, analiza sentymentu dla oceny jakości oraz algorytm Apriori dla cross-sellingu — zapewnia wszechstronne wsparcie procesu decyzyjnego użytkownika. Zastosowane techniki optymalizacyjne, w tym bitmap pruning, cache'owanie oraz indeksowanie bazy danych, gwarantują akceptowalne czasy odpowiedzi systemu nawet przy większych katalogach produktów.

Praca wykazała, że implementacja systemu rekomendacyjnego od podstaw jest możliwa i celowa w kontekście edukacyjnym oraz w sytuacjach wymagających pełnej kontroli nad logiką biznesową. Zrealizowany projekt pozwolił na zdobycie praktycznej wiedzy w zakresie projektowania systemów rekomendacyjnych, optymalizacji algorytmów, rozwoju aplikacji.

\clearpage

\newpage
\renewcommand{\refname}{} 
\section*{Literatura}
\addcontentsline{toc}{section}{Literatura}

\begin{thebibliography}{99}
\bibitem{agrawal1994}
Rakesh Agrawal, Ramakrishnan Srikant,
\textit{Fast Algorithms for Mining Association Rules},
Proceedings of the 20th International Conference on Very Large Data Bases (VLDB), 1994.

\bibitem{bennett2007netflix}
James Bennett, Stan Lanning,
\textit{The Netflix Prize},
Proceedings of KDD Cup and Workshop, 2007.

\bibitem{herlocker2000explaining}
Jonathan L. Herlocker, Joseph A. Konstan, John Riedl,
\textit{Explaining Collaborative Filtering Recommendations},
Proceedings of the 2000 ACM Conference on Computer Supported Cooperative Work (CSCW), 2000.

\bibitem{linden2003amazon}
Greg Linden, Brent Smith, Jeremy York,
\textit{Amazon.com Recommendations: Item-to-Item Collaborative Filtering},
IEEE Internet Computing, 2003.

\bibitem{liu2012}
Bing Liu,
\textit{Sentiment Analysis and Opinion Mining},
Synthesis Lectures on Human Language Technologies, Morgan \& Claypool Publishers, 2012.

\bibitem{mckinsey2013}
Jacques Bughin, Michael Chui, James Manyika,
\textit{Ten IT-enabled business trends for the decade ahead},
McKinsey Quarterly, May 2013.

\bibitem{resnick1997recommender}
Paul Resnick, Hal R. Varian,
\textit{Recommender Systems},
Communications of the ACM, 1997.

\bibitem{sarwar2001item}
Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl,
\textit{Item-based Collaborative Filtering Recommendation Algorithms},
Proceedings of the 10th International Conference on World Wide Web (WWW), 2001.

\bibitem{zaki2000}
Mohammed J. Zaki,
\textit{Scalable Algorithms for Association Mining},
IEEE Transactions on Knowledge and Data Engineering, 2000.

\end{thebibliography}

\newpage
% Wykaz rysunków i tabel
\section*{Wykaz rysunków i tabel}
\small
\listoffigures
\listoftables

\newpage
\section*{Streszczenie}
\addcontentsline{toc}{section}{Streszczenie}

\noindent
\textbf{Tytuł pracy w języku polskim:}\\
System rekomendacji produktów oparty na filtracji współpracy, analizie sentymentu i regułach asocjacyjnych

\vspace{0.5cm}

\noindent
\textbf{Tytuł pracy w języku angielskim:}\\
Product Recommendation System Based on Collaborative Filtering, Sentiment Analysis, and Association Rules

\vspace{0.5cm}

\noindent
\textbf{Streszczenie:}

\vspace{0.3cm}

Niniejsza praca inżynierska przedstawia projekt oraz implementację systemu rekomendacji produktów dla platformy e-commerce, łączącego trzy komplementarne metody rekomendacyjne: collaborative filtering, analizę sentymentu oraz reguły asocjacyjne. Celem było zaprojektowanie rozwiązania eliminującego problem przeładowania informacyjnego \\w sklepach internetowych poprzez dostarczanie użytkownikom spersonalizowanych rekomendacji.

Część teoretyczna obejmuje przegląd systemów rekomendacyjnych oraz analizę rozwiązań alternatywnych (Amazon Personalize, Google Recommendations AI, Apache Mahout) wraz z uzasadnieniem implementacji dedykowanego systemu. Przedstawiono fundament matematyczny wykorzystanych algorytmów: metrykę Adjusted Cosine Similarity dla Item-Based Collaborative Filtering, słownikowe podejście do analizy sentymentu z agregacją wieloźródłową oraz metryki support, confidence i lift dla reguł asocjacyjnych algorytmu Apriori.

Część projektowa obejmuje szczegółowy projekt architektury systemu w modelu trójwarstwowym (warstwa prezentacji React, warstwa logiki biznesowej Django, warstwa danych PostgreSQL), projekt struktury bazy danych z tabelami dla prekalkulowanych wyników algorytmów, projekt interfejsów użytkownika (widoki użytkownika końcowego i panele administracyjne) oraz projekt mechanizmów optymalizacyjnych (cache'owanie, indeksowanie, operacje zbiorcze).

Część implementacyjna przedstawia realizację aplikacji webowej w architekturze Django REST Framework (backend) oraz React 18 (frontend). System integruje trzy metody działające komplementarnie w różnych kontekstach: Collaborative Filtering dla personalizacji na stronie głównej, analizę sentymentu dla oceny jakości w wyszukiwarce oraz algorytm Apriori dla cross-sellingu w koszyku zakupowym. Zaimplementowano kompletny interfejs z narzędziami debugowania oraz panel administracyjny umożliwiający dynamiczne przełączanie metod rekomendacyjnych.

Wartością pracy jest implementacja algorytmów od podstaw, co umożliwiło głębokie zrozumienie mechanizmów oraz świadome dostosowanie do specyfiki e-commerce.

\clearpage

\newpage

\input{attachment.tex}

%\begin{figure}[H]
    %\centering
    %\includegraphics[width=\textwidth]{Oświadczenie.pdf}
%\end{figure}

\end{document}