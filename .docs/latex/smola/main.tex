% filepath: /SmartRecommender-Project-Django-React/.docs/latex/smola/main.tex

\documentclass[a4paper,12pt,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amsmath, amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{url}
\usepackage{titlesec}
\usepackage{tocloft}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{placeins}
\usepackage{float}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}

% Marginesy zgodnie z wytycznymi
\geometry{left=3.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% Numeracja stron u dołu, wyrównana do zewnętrznego marginesu
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[LE,RO]{\thepage}
\renewcommand{\headrulewidth}{0pt}

% Interlinia 1,5
\onehalfspacing

% Wcięcia akapitów
\setlength{\parindent}{1cm}

% Zapobieganie dużym odstępom pionowym - strony nie muszą być wyrównane do dołu
\raggedbottom

% Tytuły - czcionka pogrubiona
\titleformat{\section}[block]{\bfseries\Large\raggedright}{}{1em}{}
\titleformat{\subsection}[block]{\bfseries\large\raggedright}{}{1em}{}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red}
}

% Styl dla pseudokodu
\lstdefinelanguage{Pseudocode}{
  morekeywords={FUNKCJA, ZWROC, DLA, KAZDEGO, W, JEZELI, WTEDY, INACZEJ, KONIEC, LUB, I, NIE, DOPOKI, WYKONUJ, ORAZ, ZWRACA, GDZIE, OD, DO, KROK},
  sensitive=false,
  morecomment=[l]{//},
  morestring=[b]"
}

\lstdefinestyle{pseudocode}{
  language=Pseudocode,
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries\color{blue},
  commentstyle=\color{gray},
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  breaklines=true,
  xleftmargin=2em,
  framexleftmargin=1.5em,
  literate={ą}{{\k{a}}}1 {ć}{{\'c}}1 {ę}{{\k{e}}}1 {ł}{{\l{}}}1 {ń}{{\'n}}1 {ó}{{\'o}}1 {ś}{{\'s}}1 {ź}{{\'z}}1 {ż}{{\.z}}1
           {Ą}{{\k{A}}}1 {Ć}{{\'C}}1 {Ę}{{\k{E}}}1 {Ł}{{\L{}}}1 {Ń}{{\'N}}1 {Ó}{{\'O}}1 {Ś}{{\'S}}1 {Ź}{{\'Z}}1 {Ż}{{\.Z}}1
}

\begin{document}

\begin{titlepage}

\begin{minipage}{0.7\textwidth}
    {\large\bf UNIWERSYTET RZESZOWSKI}\\
    {\large\bf Wydział Nauk Ścisłych i Technicznych}
\end{minipage}
\hfill
\begin{minipage}{0.25\textwidth}
    \centering
    \includegraphics[width=8em]{images/UR.png}
\end{minipage}


\vspace{3cm}

\begin{center}
    {\Large Piotr Smoła} \\
    {\large nr albumu: 125162} \\
    {\large Kierunek: Informatyka}
\end{center}

\vspace{2cm}

\begin{center}
    {\LARGE\bf System rekomendacji produktów oparty na filtracji treści, logice rozmytej i modelach probabilistycznych}
\end{center}

\vspace{1.5cm}

\begin{center}
    {\large Praca inżynierska}
\end{center}

\vspace{1.5cm}

\begin{flushright}
    {\large Praca wykonana pod kierunkiem}\\
    {\large dr inż. Piotra Grochowalskiego}
\end{flushright}

\vspace{3cm}

\begin{center}
    {\large Rzesz\'ow, 2026}
\end{center}

\end{titlepage}

% Spis treści
\tableofcontents
\newpage


\section*{Wstęp}
\addcontentsline{toc}{section}{Wstęp}

Nowoczesne platformy e-commerce oferują tysiące lub dziesiątki tysięcy produktów, co stanowi istotne wyzwanie zarówno dla klientów, jak i właścicieli sklepów internetowych. Użytkownik poszukujący produktu staje przed wyborem setek opcji, co często prowadzi do rezygnacji z zakupu. Bez wsparcia inteligentnych systemów rekomendacyjnych proces zakupowy staje się czasochłonny i frustrujący. Z perspektywy biznesowej oznacza to utratę potencjalnych klientów oraz sytuacje, w których nabywcy nie odkrywają produktów optymalnie dopasowanych do ich potrzeb.

Systemy rekomendacyjne stanowią rozwiązanie tego problemu poprzez automatyczną analizę preferencji użytkowników w celu proponowania produktów dopasowanych do indywidualnych potrzeb, zwiększając jednocześnie konwersję i wartość sprzedaży \cite{ricci2015recommender}.

Praca inżynierska powstała we współpracy dwuosobowej jako kompleksowy system e-commerce wyposażony w sześć metod rekomendacyjnych. Praca niniejsza obejmuje implementację trzech zaawansowanych metod uczenia maszynowego: filtracji opartej na treści (Content-Based Filtering), logiki rozmytej (Fuzzy Logic) oraz modeli probabilistycznych (łańcuch Markowa i naiwny klasyfikator Bayesa). Praca współautora koncentruje się na trzech komplementarnych metodach: filtracji współpracy (Collaborative Filtering), analizie sentymentu oraz regułach asocjacyjnych (algorytm Apriori).

\subsection*{Motywacja i kontekst problemu}
\addcontentsline{toc}{subsection}{Motywacja i kontekst problemu}

Problem rekomendacji w platformach e-commerce jest złożony i wieloaspektowy. Preferencje użytkowników są subiektywne i trudne do modelowania matematycznego. Dane o użytkownikach są często niekompletne lub niedostępne, zwłaszcza dla nowych użytkowników i produktów - zjawisko znane jako problem zimnego startu (cold start problem). Katalogi produktów dynamicznie się zmieniają, co wymaga ciągłej aktualizacji modeli rekomendacyjnych. Dodatkowo, użytkownicy oczekują nie tylko trafnych rekomendacji, ale również ich wyjaśnienia - dlaczego dany produkt został zaproponowany.

Istniejące rozwiązania komercyjne (Amazon Personalize, Google Recommendations AI) oferują zaawansowane mechanizmy rekomendacji, jednak działają jako czarne skrzynki (black-box), nie pozwalając na kontrolę nad algorytmami ani ich dostosowanie do specyficznych wymagań biznesowych. Biblioteki open-source (Apache Mahout, Surprise) rozwiązują problem kosztów, ale nie oferują implementacji logiki rozmytej ani zaawansowanych modeli probabilistycznych w jednym spójnym systemie.

Rzeczona praca odpowiada na powyższe wyzwania poprzez zaprojektowanie i implementację modułowego systemu rekomendacyjnego łączącego trzy komplementarne podejścia: filtrację opartą na treści (Content-Based Filtering, CBF), logikę rozmytą (Fuzzy Logic) oraz modele probabilistyczne (łańcuchy Markowa i naiwny klasyfikator Bayesa). Każda z tych metod rozwiązuje inne aspekty problemu rekomendacji i oferuje unikalne możliwości personalizacji. System został zaimplementowany od podstaw, bez wykorzystania zewnętrznych bibliotek uczenia maszynowego, co zapewnia pełną kontrolę nad algorytmami oraz możliwość ich dostosowania do specyficznych wymagań platformy e-commerce.

\subsection*{Cel i zakres pracy}
\addcontentsline{toc}{subsection}{Cel i zakres pracy}

Głównym celem pracy jest zaprojektowanie i implementacja kompleksowego systemu rekomendacji produktów dla platformy e-commerce, który łączy sześć zaawansowanych i komplementarnych metod uczenia maszynowego. System został zbudowany od podstaw, bez wykorzystania gotowych bibliotek uczenia maszynowego, co zapewniło pełną kontrolę nad algorytmami i możliwość ich dostosowania do specyficznych wymagań biznesowych.

Praca została zrealizowana we współpracy dwuosobowej jako kompleksowe rozwiązanie e-commerce, gdzie każdy z autorów zaimplementował trzy komplementarne metody rekomendacyjne:
\begin{itemize}
    \item \textbf{Niniejsza praca}: Content-Based Filtering, logika rozmyta (Fuzzy Logic), modele probabilistyczne (Markov Chain + Naive Bayes)
    \item \textbf{Praca współautora}: Collaborative Filtering, analiza sentymentu (Sentiment Analysis), reguły asocjacyjne (Apriori)
\end{itemize}

W ramach realizacji celu głównego zdefiniowano następujące cele szczegółowe:

\begin{itemize}
    \item Zaprojektowanie architektury modułowego systemu rekomendacyjnego z sześcioma niezależnymi silnikami działającymi w ramach wspólnej infrastruktury (architektura trójwarstwowa: Django + React + PostgreSQL)
    \item Implementacja algorytmu filtracji opartej na treści (Content-Based Filtering) z wykorzystaniem ważonych wektorów cech (kategorie 40\%, tagi 30\%, cena 20\%, słowa kluczowe 10\%) i miary podobieństwa kosinusowego
    \item Opracowanie systemu wnioskowania rozmytego typu Mamdani z regułami IF-THEN i funkcjami przynależności (trójkątne i trapezoidalne) dla trzech wymiarów: wrażliwość cenowa, preferencje kategorialne, preferencja jakości
    \item Zbudowanie modeli probabilistycznych: łańcucha Markowa pierwszego rzędu dla predykcji sekwencji zakupowych oraz naiwnego klasyfikatora Bayesa dla predykcji churnu i prawdopodobieństwa zakupu
    \item Integracja z trzema komplementarnymi metodami zaimplementowanymi przez współautora: Collaborative Filtering z metryką Adjusted Cosine Similarity, wieloźródłowa analiza sentymentu (5 źródeł tekstowych) oraz reguły asocjacyjne Apriori z optymalizacją bitmap pruning
    \item Optymalizacja wydajności systemu dla wdrożenia produkcyjnego (cache, bulk operations, indeksy bazodanowe, Docker)
    \item Przeprowadzenie ewaluacji jakości rekomendacji na rzeczywistych danych (500 produktów, 20 użytkowników, 265 zamówień)
\end{itemize}

Zakres pracy obejmuje trzy główne obszary: podstawy teoretyczne metod rekomendacyjnych, projekt i implementację systemu oraz ewaluację jego działania. System został zintegrowany z aplikacją webową e-commerce (Django 5.1.4 + React 18 + PostgreSQL 14), umożliwiającą weryfikację wszystkich sześciu zaimplementowanych algorytmów w warunkach zbliżonych do rzeczywistych.

Niniejsza praca koncentruje się szczegółowo na aspektach algorytmicznych i jakościowych trzech metod zaimplementowanych w jej ramach, z uwzględnieniem problemu zimnego startu, interpretowalności wyników oraz personalizacji doświadczenia użytkownika. Każda z sześciu metod rozwiązuje inne wyzwania:
\begin{itemize}
    \item \textbf{Content-Based Filtering} (niniejsza praca) - rozwiązuje problem zimnego startu dla nowych produktów poprzez analizę cech produktowych
    \item \textbf{Fuzzy Logic} (niniejsza praca) - oferuje najwyższą interpretowalność decyzji algorytmu (explainable AI) poprzez reguły IF-THEN
    \item \textbf{Modele probabilistyczne} (niniejsza praca) - przewidują sekwencje zakupowe i ryzyko churnu na podstawie historii transakcji
    \item \textbf{Collaborative Filtering} (współautor) - odkrywa ukryte wzorce zakupowe poprzez analizę podobieństw między użytkownikami
    \item \textbf{Sentiment Analysis} (współautor) - agreguje jakość produktów z wielu źródeł tekstowych, rozwiązując problem zimnego startu dla produktów bez opinii
    \item \textbf{Association Rules - Apriori} (współautor) - identyfikuje produkty często kupowane razem, umożliwiając cross-selling
\end{itemize}

Wspólna infrastruktura techniczna (baza danych 25 tabel, REST API, frontend React) została zaprojektowana i zaimplementowana we współpracy, zapewniając spójne środowisko dla wszystkich sześciu metod rekomendacyjnych.

\newpage

\section*{Rozdzia\l{} 1}
\addcontentsline{toc}{section}{Rozdział 1: Teoretyczne podstawy metod rekomendacyjnych}
\section*{Teoretyczne podstawy metod rekomendacyjnych}

System rekomendacji produktów został oparty na sześciu zaawansowanych metodach uczenia maszynowego, które łączą różne podejścia do problemu personalizacji. Niniejszy rozdział prezentuje podstawy teoretyczne trzech metod zaimplementowanych w ramach tej pracy: filtracji opartej na treści (Content-Based Filtering), logiki rozmytej (Fuzzy Logic) oraz modeli probabilistycznych (Markov Chain, Naive Bayes). System został rozbudowany we współpracy o dodatkowe trzy komplementarne metody (Collaborative Filtering, analiza sentymentu, reguły asocjacyjne Apriori), których teoretyczne podstawy stanowią przedmiot odrębnej pracy inżynierskiej współautora.

\subsection*{1.1 Historia i ewolucja systemów rekomendacyjnych}
\addcontentsline{toc}{subsection}{1.1 Historia i ewolucja systemów rekomendacyjnych}

Systemy rekomendacyjne powstały jako rozwiązanie problemu wyboru spośród dziesiątek tysięcy produktów dostępnych w sklepach internetowych. Rozwój tej dziedziny datuje się na lata 90. XX wieku, kiedy pojawiły się pierwsze platformy handlu elektronicznego. Wczesne komercyjne zastosowania systemów rekomendacji, w szczególności w Amazon.com, zostały udokumentowane w literaturze naukowej, stanowiąc punkt odniesienia dla kolejnych implementacji. Kluczowym przełomem była publikacja wprowadzająca metodę Item-Based Collaborative Filtering wykorzystującą metrykę Adjusted Cosine Similarity, która stała się standardem w przemyśle e-commerce.

Istotnym katalizatorem rozwoju zaawansowanych technik rekomendacji były konkursy badawcze, szczególnie Netflix Prize organizowany w latach 2006-2009. Konkurs ten, z pulą nagród wynoszącą milion dolarów, przyciągnął uwagę środowiska akademickiego oraz przemysłowego, znacząco przyspieszając rozwój algorytmów faktoryzacji macierzy, zespołów modeli oraz metod deep learning. Współcześnie systemy rekomendacyjne stanowią fundament funkcjonowania wiodących platform e-commerce (handlu elektronicznego), serwisów VOD (Video on Demand - wideo na żądanie), platform muzycznych oraz mediów społecznościowych.

Ewolucja systemów rekomendacyjnych przebiegała od prostych metod statystycznych (najbardziej popularne produkty, najlepiej ocenione) przez collaborative filtering (analiza wzorców zakupowych użytkowników), content-based filtering (analiza cech produktów), aż po zaawansowane metody hybrydowe łączące multiple podejścia. Obecne trendy obejmują wykorzystanie deep learning (sieci neuronowe), contextual bandits (algorytmy balansujące eksplorację i eksploatację), explainable AI (interpretowalność decyzji algorytmicznych) oraz personalizację w czasie rzeczywistym.

\subsection*{1.2 Content-Based Filtering — podstawy teoretyczne}
\addcontentsline{toc}{subsection}{1.2 Content-Based Filtering — podstawy teoretyczne}

Content-Based Filtering (CBF, filtracja oparta na treści) jest jedną z fundamentalnych metod systemów rekomendacyjnych. W przeciwieństwie do Collaborative Filtering, CBF analizuje cechy samych produktów, a nie wzorce zachowań użytkowników. Metoda została szczegółowo opisana w literaturze \cite{pazzani2007content}.

\textbf{Zasada działania}: System buduje profil cech każdego produktu (wektor cech) i oblicza podobieństwo między produktami na podstawie ich cech. Użytkownikowi rekomendowane są produkty podobne do tych, które wcześniej przeglądał lub kupił.

\textbf{Reprezentacja produktu jako wektora cech}

Każdy produkt $p$ jest reprezentowany jako wektor w wielowymiarowej przestrzeni cech:

\begin{equation}
\vec{p} = (f_1, f_2, ..., f_n)
\end{equation}

gdzie $f_i$ to waga cechy $i$ (np. należenie do kategorii, posiadanie tagu, przedział cenowy). W ogólnym przypadku stosuje się wagi różnicujące znaczenie poszczególnych cech:

\begin{equation}
\vec{p} = \sum_{i} w_i \cdot f_i(p)
\end{equation}

gdzie $w_i$ to waga cechy $i$, a $f_i(p)$ to wartość cechy dla produktu $p$. Funkcja indykatorowa $\mathbf{1}_{feature}(p)$ przyjmuje wartość 1 jeśli produkt posiada daną cechę, 0 w przeciwnym razie.

\textbf{Zalety CBF}:
\begin{itemize}
    \item Brak problemu zimnego startu dla nowych produktów — wystarczy opis i cechy
    \item Przejrzystość rekomendacji — można wyjaśnić dlaczego produkt został polecony ("podobna kategoria", "podobne tagi")
    \item Niezależność od innych użytkowników — działa nawet dla pierwszego klienta w systemie
    \item Szybka aktualizacja — dodanie nowego produktu nie wymaga przeliczenia całej macierzy
\end{itemize}

\textbf{Wady CBF}:
\begin{itemize}
    \item Problem "filter bubble" — rekomenduje tylko podobne produkty, użytkownik nie odkrywa nowych kategorii
    \item Wymaga dobrze opisanych cech produktów — jakość rekomendacji zależy od jakości metadanych
    \item Nie odkrywa nieoczywistych powiązań między produktami (np. "użytkownicy kupujący kawę często kupują cukier")
    \item Ograniczenie do podobieństwa cech — nie uwzględnia kontekstu użytkownika
\end{itemize}

\textbf{Podobieństwo kosinusowe} (Cosine Similarity) jest standardową metryką w CBF \cite{salton1989automatic}. Dla dwóch wektorów $\vec{A}$ i $\vec{B}$:

\begin{equation}
\text{cos}(\theta) = \frac{\vec{A} \cdot \vec{B}}{||\vec{A}|| \times ||\vec{B}||} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \times \sqrt{\sum_{i=1}^{n} B_i^2}}
\end{equation}

gdzie $\vec{A}$ i $\vec{B}$ to wektory cech dwóch produktów. Wynik mieści się w przedziale $[0, 1]$ dla nieujemnych wektorów (w kontekście TF-IDF i wag binarnych).

\textbf{Interpretacja podobieństwa kosinusowego}:
\begin{itemize}
    \item $cos(\theta) = 1$ — wektory identyczne (produkty mają te same cechy)
    \item $cos(\theta) = 0$ — wektory ortogonalne (brak wspólnych cech)
    \item $cos(\theta) \in (0, 1)$ — częściowe podobieństwo
\end{itemize}

\textbf{TF-IDF (Term Frequency - Inverse Document Frequency)}

W kontekście ekstrakcji słów kluczowych z opisów tekstowych stosuje się miarę TF-IDF (Term Frequency - Inverse Document Frequency) \cite{salton1989automatic}:

\begin{equation}
TF(t, d) = \frac{count(t, d)}{|d|}
\end{equation}

gdzie $count(t, d)$ to liczba wystąpień terminu $t$ w dokumencie $d$, a $|d|$ to długość dokumentu (liczba słów).

Pełna wersja TF-IDF uwzględnia rzadkość terminu w całym korpusie:

\begin{equation}
TF\text{-}IDF(t, d, D) = TF(t, d) \times IDF(t, D)
\end{equation}

gdzie $IDF(t, D) = \log\frac{|D|}{|\{d \in D : t \in d\}|}$ to odwrócona częstość dokumentowa, penalizująca terminy występujące w wielu dokumentach.

\subsection*{1.3 Logika rozmyta — podstawy teoretyczne}
\addcontentsline{toc}{subsection}{1.3 Logika rozmyta — podstawy teoretyczne}

Logika rozmyta (Fuzzy Logic) została wprowadzona przez Lotfi Zadeha w przełomowej pracy \cite{zadeh1965fuzzy}. Rozszerza klasyczną logikę dwuwartościową (prawda/fałsz) o stopnie przynależności w przedziale $[0, 1]$.

\textbf{Motywacja}: Klasyczna logika wymaga precyzyjnych granic. Pytanie "Czy produkt za 450 PLN jest tani?" nie ma jednoznacznej odpowiedzi — zależy od kontekstu, kategorii produktu i preferencji użytkownika. Logika rozmyta pozwala odpowiedzieć: "Produkt jest tani ze stopniem 0.3 i średnio drogi ze stopniem 0.7".

\textbf{Zbiory rozmyte} (Fuzzy Sets): W klasycznej teorii zbiorów element należy lub nie należy do zbioru. W zbiorach rozmytych element ma stopień przynależności $\mu(x) \in [0, 1]$. Formalnie, zbiór rozmyty $A$ na uniwersum $X$ jest zdefiniowany przez funkcję przynależności:

\begin{equation}
\mu_A : X \rightarrow [0, 1]
\end{equation}

gdzie $\mu_A(x)$ oznacza stopień przynależności elementu $x$ do zbioru $A$.

\textbf{Przykład}: Dla zmiennej "cena" możemy zdefiniować trzy zbiory rozmyte:
\begin{itemize}
    \item \textbf{cheap}: ceny niskie (pełna przynależność dla cen < 100 PLN)
    \item \textbf{medium}: ceny średnie (pełna przynależność dla cen 500-1200 PLN)
    \item \textbf{expensive}: ceny wysokie (pełna przynależność dla cen > 2000 PLN)
\end{itemize}

Produkt za 350 PLN może mieć: $\mu_{cheap}(350) = 0.3$, $\mu_{medium}(350) = 0.5$, $\mu_{expensive}(350) = 0.0$.

\textbf{Funkcje przynależności} (Membership Functions) definiują stopień przynależności elementu do zbioru rozmytego. Najczęściej stosowane typy:

\textit{Funkcja trójkątna} (Triangular MF):
\begin{equation}
\mu_{triangle}(x; a, b, c) = \max\left(0, \min\left(\frac{x-a}{b-a}, \frac{c-x}{c-b}\right)\right)
\end{equation}

gdzie $a$ to dolna granica, $b$ to punkt maksymalny ($\mu=1$), $c$ to górna granica.

\textit{Funkcja trapezoidalna} (Trapezoidal MF):
\begin{equation}
\mu_{trapezoid}(x; a, b, c, d) = \max\left(0, \min\left(\frac{x-a}{b-a}, 1, \frac{d-x}{d-c}\right)\right)
\end{equation}

gdzie przedział $[b, c]$ ma pełną przynależność ($\mu=1$), a $[a, b)$ i $(c, d]$ to obszary przejściowe.

\textit{Funkcja gaussowska} (Gaussian MF):
\begin{equation}
\mu_{gaussian}(x; c, \sigma) = e^{-\frac{(x-c)^2}{2\sigma^2}}
\end{equation}

gdzie $c$ to środek (mean), a $\sigma$ to odchylenie standardowe kontrolujące szerokość.

\textbf{Operacje na zbiorach rozmytych}

\textit{Uzupełnienie} (Negacja):
\begin{equation}
\mu_{\bar{A}}(x) = 1 - \mu_A(x)
\end{equation}

\textit{Przecięcie} (AND) — T-norma:
\begin{equation}
\mu_{A \cap B}(x) = T(\mu_A(x), \mu_B(x))
\end{equation}

Najczęściej używane T-normy:
\begin{itemize}
    \item Minimum (Gödel): $T_{min}(a, b) = \min(a, b)$
    \item Iloczyn algebraiczny: $T_{prod}(a, b) = a \cdot b$
    \item Łukasiewicz: $T_L(a, b) = \max(0, a + b - 1)$
\end{itemize}

\textit{Suma} (OR) — T-conorma (S-norma):
\begin{equation}
\mu_{A \cup B}(x) = S(\mu_A(x), \mu_B(x))
\end{equation}

Najczęściej używane T-conormy:
\begin{itemize}
    \item Maksimum: $S_{max}(a, b) = \max(a, b)$
    \item Suma algebraiczna: $S_{sum}(a, b) = a + b - a \cdot b$
    \item Łukasiewicz: $S_L(a, b) = \min(1, a + b)$
\end{itemize}

\textbf{System wnioskowania Mamdani} \cite{mamdani1975experiment} jest najbardziej rozpowszechnioną metodą wnioskowania rozmytego. Składa się z czterech etapów:

\begin{enumerate}
    \item \textbf{Fuzzyfikacja} — przekształcenie wartości wejściowych na stopnie przynależności do zbiorów rozmytych. Przykład: cena 450 PLN → $\mu_{cheap}=0.1$, $\mu_{medium}=0.6$, $\mu_{expensive}=0.0$.

    \item \textbf{Ewaluacja reguł} — obliczenie aktywacji reguł IF-THEN za pomocą T-norm. Dla reguły "IF price IS cheap AND quality IS high THEN recommendation IS strong":
    \begin{equation}
    \alpha = T(\mu_{cheap}(price), \mu_{high}(quality)) = \min(\mu_{cheap}, \mu_{high})
    \end{equation}

    \item \textbf{Agregacja} — połączenie wyników wszystkich reguł za pomocą T-conormy. Jeśli wiele reguł prowadzi do tego samego konsekwentu:
    \begin{equation}
    \mu_{output} = S(\alpha_1, \alpha_2, ..., \alpha_n) = \max(\alpha_1, \alpha_2, ..., \alpha_n)
    \end{equation}

    \item \textbf{Defuzzyfikacja} — przekształcenie wyniku rozmytego na wartość liczbową.
\end{enumerate}

\textbf{Metody defuzzyfikacji}:

\textit{Centroid} (środek ciężkości):
\begin{equation}
y^* = \frac{\int y \cdot \mu(y) dy}{\int \mu(y) dy}
\end{equation}

\textit{Średnia ważona} (Weighted Average) — uproszczona metoda używana w implementacji:
\begin{equation}
y^* = \frac{\sum_{i=1}^{n} \alpha_i \cdot w_i}{\sum_{i=1}^{n} w_i}
\end{equation}

gdzie $\alpha_i$ to aktywacja reguły $i$, a $w_i$ to waga reguły.

\textit{Mean of Maximum} (MoM):
\begin{equation}
y^* = \frac{1}{|M|} \sum_{y \in M} y, \quad M = \{y : \mu(y) = \max_z \mu(z)\}
\end{equation}

\textbf{Reguły rozmyte IF-THEN}

Reguła rozmyta ma postać \cite{ross2010fuzzy}:
\begin{equation}
\text{IF } x_1 \text{ IS } A_1 \text{ AND } x_2 \text{ IS } A_2 \text{ THEN } y \text{ IS } B
\end{equation}

gdzie $A_1$, $A_2$, $B$ to zbiory rozmyte definiujące warunki i konsekwencje reguły. Operator AND realizowany jest przez T-normę, najczęściej minimum lub iloczyn algebraiczny.

\subsection*{1.4 Modele probabilistyczne — podstawy teoretyczne}
\addcontentsline{toc}{subsection}{1.4 Modele probabilistyczne — podstawy teoretyczne}

\textbf{Łańcuchy Markowa} (Markov Chains) zostały wprowadzone przez Andrieja Markowa w 1906 roku. Są procesami stochastycznymi spełniającymi własność Markowa — przyszły stan zależy tylko od stanu obecnego, nie od historii \cite{rabiner1989tutorial}.

\textit{Definicja formalna}: Łańcuch Markowa to ciąg zmiennych losowych $X_0, X_1, X_2, ...$ przyjmujących wartości ze zbioru stanów $S = \{s_1, s_2, ..., s_n\}$, spełniający własność Markowa:

\begin{equation}
P(X_{t+1} = s_{j} | X_t = s_i, X_{t-1} = s_{i-1}, ..., X_0 = s_0) = P(X_{t+1} = s_j | X_t = s_i)
\end{equation}

Oznacza to, że prawdopodobieństwo przejścia do stanu $s_j$ zależy tylko od obecnego stanu $s_i$, nie od tego jak do niego dotarliśmy.

\textit{Macierz przejść} (Transition Matrix) $P$ zawiera prawdopodobieństwa przejść między stanami:

\begin{equation}
P_{ij} = P(X_{t+1} = s_j | X_t = s_i)
\end{equation}

Macierz $P$ spełnia warunki:
\begin{itemize}
    \item $P_{ij} \geq 0$ dla wszystkich $i, j$
    \item $\sum_j P_{ij} = 1$ dla wszystkich $i$ (wiersze sumują się do 1)
\end{itemize}

\textit{Estymacja prawdopodobieństw przejść} z danych:
\begin{equation}
\hat{P}_{ij} = \frac{count(s_i \rightarrow s_j)}{\sum_k count(s_i \rightarrow s_k)}
\end{equation}

gdzie $count(s_i \rightarrow s_j)$ to liczba obserwowanych przejść ze stanu $s_i$ do stanu $s_j$.

\textit{Rozkład stacjonarny} (Stationary Distribution) $\pi$ spełnia:
\begin{equation}
\pi = \pi P, \quad \sum_i \pi_i = 1
\end{equation}

Jest to rozkład prawdopodobieństwa, który pozostaje niezmieniony po przejściu — reprezentuje długoterminowe prawdopodobieństwa przebywania w każdym stanie. Rozkład stacjonarny jest istotny w analizie długoterminowego zachowania systemu.

\textbf{Naiwny klasyfikator Bayesa} (Naive Bayes, NB) opiera się na twierdzeniu Bayesa z założeniem niezależności cech \cite{murphy2012machine}.

\textit{Twierdzenie Bayesa}:
\begin{equation}
P(C | X) = \frac{P(X | C) \cdot P(C)}{P(X)}
\end{equation}

gdzie:
\begin{itemize}
    \item $P(C | X)$ — prawdopodobieństwo a posteriori klasy $C$ przy cechach $X$
    \item $P(C)$ — prawdopodobieństwo a priori klasy $C$
    \item $P(X | C)$ — wiarygodność (likelihood) — prawdopodobieństwo obserwacji cech $X$ w klasie $C$
    \item $P(X)$ — prawdopodobieństwo marginalne cech (stałe dla wszystkich klas)
\end{itemize}

\textit{Założenie naiwne} (Naive assumption) — niezależność warunkowa cech:
\begin{equation}
P(X | C) = P(x_1, x_2, ..., x_n | C) = \prod_{i=1}^{n} P(x_i | C)
\end{equation}

Założenie to jest "naiwne" bo w rzeczywistości cechy są często skorelowane. Jednak Naive Bayes działa zaskakująco dobrze w praktyce.

\textit{Klasyfikacja}:
\begin{equation}
\hat{C} = \arg\max_C P(C) \prod_{i=1}^{n} P(x_i | C)
\end{equation}

Ponieważ $P(X)$ jest stałe dla wszystkich klas, można je pominąć przy porównywaniu.

\textit{Problem zerowych prawdopodobieństw}: Jeśli cecha $x_i$ nie wystąpiła w klasie $C$ w danych treningowych, to $P(x_i | C) = 0$, co zeruje całe prawdopodobieństwo.

\textbf{Wygładzanie Laplace'a} (Laplace Smoothing / Add-one Smoothing) rozwiązuje ten problem:
\begin{equation}
P(x_i = v | C) = \frac{count(x_i = v, C) + 1}{count(C) + |V_i|}
\end{equation}

gdzie $|V_i|$ to liczba unikalnych wartości cechy $x_i$. Dodanie 1 do licznika i $|V|$ do mianownika zapewnia, że żadne prawdopodobieństwo nie będzie zerowe.

\textit{Logarytm dla stabilności numerycznej}: Iloczyn wielu małych prawdopodobieństw prowadzi do underflow. Rozwiązanie — praca w przestrzeni logarytmów:
\begin{equation}
\log P(C | X) = \log P(C) + \sum_{i=1}^{n} \log P(x_i | C) + const
\end{equation}

\textit{Warianty Naive Bayes}:
\begin{itemize}
    \item \textbf{Multinomial NB} — dla danych zliczeniowych (np. częstość słów)
    \item \textbf{Bernoulli NB} — dla cech binarnych (obecność/brak)
    \item \textbf{Gaussian NB} — dla cech ciągłych (zakłada rozkład normalny)
\end{itemize}

Naive Bayes jest szeroko stosowany w klasyfikacji tekstu, filtracji spamu oraz systemach rekomendacyjnych ze względu na prostotę implementacji i niskie wymagania obliczeniowe.

\subsection*{1.5 Metryki oceny systemów rekomendacyjnych}
\addcontentsline{toc}{subsection}{1.5 Metryki oceny systemów rekomendacyjnych}

Ewaluacja systemów rekomendacyjnych wymaga odpowiednich metryk jakości. Najpopularniejsze:

\textbf{Precision@K} — jaka część top K rekomendacji była faktycznie kupiona/polubiona:
\begin{equation}
Precision@K = \frac{|Recommended@K \cap Relevant|}{K}
\end{equation}

\textbf{Recall@K} — jaka część produktów istotnych dla użytkownika została trafiona:
\begin{equation}
Recall@K = \frac{|Recommended@K \cap Relevant|}{|Relevant|}
\end{equation}

\textbf{F1-Score} — harmoniczna średnia Precision i Recall:
\begin{equation}
F1@K = 2 \cdot \frac{Precision@K \cdot Recall@K}{Precision@K + Recall@K}
\end{equation}

\textbf{Mean Reciprocal Rank (MRR)} — pozycja pierwszego trafienia:
\begin{equation}
MRR = \frac{1}{|U|} \sum_{u \in U} \frac{1}{rank_u}
\end{equation}

gdzie $rank_u$ to pozycja pierwszego istotnego produktu w rankingu dla użytkownika $u$.

\textbf{Coverage} — procent produktów, które system jest w stanie rekomendować:
\begin{equation}
Coverage = \frac{|\text{products with recommendations}|}{|\text{all products}|}
\end{equation}

\newpage

\section*{Rozdzia\l{} 2}
\addcontentsline{toc}{section}{Rozdział 2: Weryfikacja i analiza rozwiązań alternatywnych}
\section*{Weryfikacja i analiza rozwiązań alternatywnych}

W celu uzasadnienia sensowności tworzenia dedykowanego systemu rekomendacji przeprowadzono analizę trzech reprezentatywnych rozwiązań rynkowych. Celem weryfikacji było zidentyfikowanie ograniczeń istniejących narzędzi oraz określenie wymagań dla planowanej aplikacji e-commerce. System został zaprojektowany jako kompleksowe rozwiązanie wykorzystujące sześć komplementarnych metod rekomendacyjnych: trzy metody zaimplementowane w ramach niniejszej pracy (Content-Based Filtering, logika rozmyta, modele probabilistyczne) oraz trzy metody zaimplementowane przez współautora (Collaborative Filtering, analiza sentymentu, reguły asocjacyjne Apriori).

\subsection*{2.1 Amazon Personalize}
\addcontentsline{toc}{subsection}{2.1 Amazon Personalize}

Amazon Personalize to zarządzana usługa AWS oferująca systemy rekomendacji oparte na algorytmach stosowanych w Amazon.com. System wykorzystuje deep learning (głębokie uczenie - wielowarstwowe sieci neuronowe) oraz collaborative filtering, oferując trzy typy rekomendacji: User Personalization (personalizacja użytkownika), Similar Items (podobne produkty) oraz Personalized Ranking (spersonalizowane rankowanie).

\textbf{Kluczowe ograniczenia w kontekście planowanego rozwiązania:}

\begin{itemize}
\item \textbf{Wysokie koszty operacyjne} - rozwiązania chmurowe wiążą się z regularnymi opłatami licencyjnymi, które mogą być znaczące dla małych i średnich platform e-commerce. Dla porównania, własna implementacja eliminuje te koszty przy zachowaniu kontroli nad funkcjonalnościami,
\item \textbf{Brak natywnej analizy sentymentu, logiki rozmytej oraz modeli probabilistycznych} - Amazon Personalize koncentruje się wyłącznie na collaborative filtering i nie oferuje analizy opinii produktów, systemów rozmytych ani łańcuchów Markova. Wieloźródłowa agregacja sentymentu (współautor), logika rozmyta Mamdani (niniejsza praca) oraz modele probabilistyczne (niniejsza praca) wymagają integracji z dodatkowymi usługami AWS lub samodzielnej implementacji,
\item \textbf{Vendor lock-in} (uzależnienie od dostawcy) - głęboka integracja z ekosystemem AWS (S3, Lambda, EventBridge) oznacza, że migracja do innej platformy wymaga przepisania całej architektury systemu,
\item \textbf{Brak kontroli nad algorytmami} - system działa jako ,,czarna skrzynka'' (black box), uniemożliwiając dostosowanie logiki rekomendacji. Przykład: niemożliwe jest zaimplementowanie ważonych wektorów cech dla Content-Based Filtering (niniejsza praca), Adjusted Cosine Similarity z centrowaniem średniej dla Collaborative Filtering (współautor) czy funkcji przynależności dla logiki rozmytej (niniejsza praca),
\item \textbf{Wymóg dużych zbiorów danych} - według dokumentacji AWS, system wymaga minimum 25000 interakcji dla zapewnienia wysokiej jakości rekomendacji. Dla nowych platform (cold start - problem zimnego startu) jakość jest ograniczona w początkowym okresie działania.
\end{itemize}

\subsection*{2.2 Google Recommendations AI (Vertex AI)}
\addcontentsline{toc}{subsection}{2.2 Google Recommendations AI (Vertex AI)}

Google Recommendations AI to platforma GCP wykorzystująca deep learning oraz multi-armed contextual bandits (wieloramienne bandyty kontekstowe - algorytmy balansujące eksplorację nowych opcji z wykorzystaniem sprawdzonych rozwiązań). System oferuje zaawansowane rekomendacje dla e-commerce, VOD (Video on Demand - wideo na żądanie) oraz platform newsowych, z automatycznym wykrywaniem trendów i sezonowości.

\textbf{Kluczowe ograniczenia w kontekście planowanego rozwiązania:}

\begin{itemize}
\item \textbf{Bardzo wysokie koszty operacyjne} - koszty usług GCP są często wyższe niż konkurencyjnych rozwiązań chmurowych, co czyni je nieopłacalnymi dla małych i średnich platform e-commerce. Model cenowy oparty na liczbie predykcji generuje rosnące koszty wraz ze skalą ruchu użytkowników,
\item \textbf{Brak wieloźródłowej agregacji sentymentu, logiki rozmytej i modeli probabilistycznych} - Google Recommendations AI oferuje funkcję ``Frequently Bought Together'' (często kupowane razem, podobną do algorytmu Apriori), ale nie wspiera agregacji sentymentu z wielu źródeł tekstowych (współautor), systemów rozmytych z funkcjami przynależności (niniejsza praca) ani łańcuchów Markova (niniejsza praca) jak w planowanym systemie,
\item \textbf{Wymóg bardzo dużych zbiorów danych} - rozwiązanie zaprojektowane dla platform o skali YouTube, co czyni je nadmiarowo złożonym dla małych sklepów internetowych,
\item \textbf{Brak interpretowalności} - głęboka ,,black box'', gdzie nawet administratorzy z dostępem do Vertex AI nie mogą zobaczyć wag embeddings (reprezentacji wektorowych) ani logiki sieci neuronowej, co uniemożliwia debugowanie i optymalizację. W przeciwieństwie do tego, logika rozmyta (niniejsza praca) oferuje pełną przejrzystość reguł IF-THEN.
\end{itemize}

\subsection*{2.3 Apache Mahout}
\addcontentsline{toc}{subsection}{2.3 Apache Mahout}

Apache Mahout to open-source framework (otwartoźródłowy framework) implementujący klasyczne algorytmy collaborative filtering oraz matrix factorization (faktoryzacja macierzy - technika dekompozycji macierzy user-item) - ALS (Alternating Least Squares - metoda najmniejszych kwadratów na przemian), SVD (Singular Value Decomposition - rozkład według wartości osobliwych). Projekt powstał w 2008 roku, obecnie koncentruje się na Spark-based distributed algorithms (algorytmy rozproszone oparte na Apache Spark).

\textbf{Kluczowe ograniczenia w kontekście planowanego rozwiązania:}

\begin{itemize}
\item \textbf{Wymóg zaawansowanej wiedzy technicznej} - konieczność konfiguracji klastra Apache Spark (środowisko przetwarzania rozproszonego), YARN resource manager (zarządca zasobów) oraz monitoringu. Według Stack Overflow Developer Survey 2023, bardzo mała część programistów ma doświadczenie z Apache Spark,
\item \textbf{Koszty infrastruktury} - chociaż licencja Apache 2.0 jest darmowa, utrzymanie klastra Spark wymaga dedykowanych zasobów serwerowych oraz czasu na implementację integracji (REST API, baza danych, cache, frontend), co generuje znaczące koszty operacyjne,
\item \textbf{Brak analizy sentymentu, logiki rozmytej i modeli probabilistycznych} - Apache Mahout nie oferuje sentiment analysis, fuzzy logic ani Markov Chains. Wymagana jest integracja z zewnętrznymi bibliotekami (np. Stanford CoreNLP dla sentymentu) lub samodzielna implementacja słownikowej analizy sentymentu (współautor), systemu Mamdani dla logiki rozmytej (niniejsza praca) oraz łańcucha Markowa (niniejsza praca),
\item \textbf{Wolniejszy rozwój projektu} - aktywność projektu spadła w ostatnich latach (2-3 commity miesięcznie w 2023-2024 vs 20-30 commitów w latach 2012-2014), co skutkuje ograniczoną dokumentacją dla nowszych wersji.
\end{itemize}

\textbf{Alternatywy open-source}: Biblioteka Surprise (Python) oferuje implementacje SVD, SVD++, NMF, KNN z built-in dataset loaders i cross-validation, ale również nie wspiera Content-Based Filtering, Fuzzy Logic, Sentiment Analysis ani Association Rules.

\subsection*{2.4 Podsumowanie analizy i uzasadnienie własnego rozwiązania}
\addcontentsline{toc}{subsection}{2.4 Podsumowanie analizy i uzasadnienie własnego rozwiązania}

Analiza rozwiązań alternatywnych ujawniła fundamentalny kompromis: \textbf{zaawansowanie technologiczne vs koszty i elastyczność}. Rozwiązania chmurowe od Amazona oraz Google oferują wysoką jakość rekomendacji dzięki algorytmom deep learning, ale wiążą się z wysokimi kosztami operacyjnymi, vendor lock-in (uzależnieniem od dostawcy) oraz brakiem kontroli nad algorytmami. Apache Mahout eliminuje koszty licencyjne, ale wymaga zaawansowanej wiedzy technicznej oraz kosztownej infrastruktury Spark.

\textbf{Uzasadnienie sensowności własnego rozwiązania:}

\begin{itemize}
\item \textbf{Integracja sześciu komplementarnych metod w jednym systemie}:

Żadne z analizowanych rozwiązań nie oferuje natywnej integracji wszystkich sześciu zaimplementowanych metod:
\begin{itemize}
\item Amazon Personalize: tylko Collaborative Filtering, wymagane dodatkowe usługi dla pozostałych metod,
\item Google Recommendations AI: Collaborative Filtering + funkcja podobna do Apriori, brak analizy sentymentu, CBF, Fuzzy Logic i modeli probabilistycznych,
\item Apache Mahout: tylko Collaborative Filtering, brak pozostałych pięciu metod w najnowszej wersji.
\end{itemize}

Własna implementacja łączy:
\begin{itemize}
\item Content-Based Filtering (niniejsza praca) - rozwiązuje cold start dla nowych produktów,
\item Fuzzy Logic (niniejsza praca) - personalizacja z wysoką interpretowalnością,
\item Modele probabilistyczne: Markov + Naive Bayes (niniejsza praca) - predykcja sekwencji zakupowych,
\item Collaborative Filtering (współautor) - odkrywanie ukrytych wzorców użytkowników,
\item Sentiment Analysis (współautor) - wieloźródłowa agregacja jakości produktów,
\item Association Rules - Apriori (współautor) - cross-selling produktów często kupowanych razem.
\end{itemize}

\item \textbf{Optymalizacja kosztów dla małych i średnich platform}:

Własna implementacja (Django + PostgreSQL) eliminuje wysokie koszty licencyjne rozwiązań chmurowych przy zachowaniu wysokiej jakości rekomendacji. System jest szczególnie atrakcyjny dla małych i średnich platform e-commerce (do 10000 produktów, do 100000 użytkowników), które potrzebują zaawansowanych funkcjonalności rekomendacji przy ograniczonym budżecie.

\item \textbf{Kontrola nad logiką biznesową i możliwość dostosowania}:

Własna implementacja umożliwia unikalne podejścia niedostępne w gotowych rozwiązaniach:
\begin{itemize}
\item \textbf{Wieloźródłowa agregacja sentymentu} (współautor) z 5 źródeł tekstowych - rozwiązuje problem cold start: produkty bez opinii użytkowników otrzymują wynik sentymentu na podstawie opisu, nazwy i specyfikacji,
\item \textbf{Bitmap pruning} (współautor) dla algorytmu Apriori - optymalizacja przyspiesza generowanie reguł asocjacyjnych względem implementacji naiwnej poprzez operacje bitowe,
\item \textbf{Adjusted Cosine Similarity} (współautor) z centrowaniem średniej - eliminacja wartości progowej (bias) wynikającej z różnych skal zakupowych użytkowników,
\item \textbf{Ważone wektory cech} (niniejsza praca) dla CBF - kategorie 40\%, tagi 30\%, cena 20\%, słowa kluczowe 10\%,
\item \textbf{Funkcje przynależności Mamdani} (niniejsza praca) dla logiki rozmytej - modelowanie niepewności preferencji użytkowników,
\item \textbf{Łańcuch Markowa pierwszego rzędu} (niniejsza praca) - predykcja następnej kategorii zakupu na podstawie macierzy przejść.
\end{itemize}

\item \textbf{Elastyczność technologiczna i brak vendor lock-in}:

Aplikacja oparta na Django + React + PostgreSQL może być wdrożona na dowolnej platformie: AWS, GCP, Azure, własne serwery lub localhost. Migracja między platformami wymaga jedynie zmiany parametrów połączenia - logika rekomendacji pozostaje niezmieniona.

Dla porównania: migracja z Amazon Personalize do Google Recommendations AI wymaga przepisania całej integracji (śledzenie zdarzeń, dane treningowe, wywołania API) oraz retrainingu modeli, co może trwać tygodnie i powodować degradację jakości rekomendacji.

\item \textbf{Cel edukacyjny i interpretowalność}:

Praca inżynierska ma charakter badawczy i edukacyjny. Implementacja algorytmów od podstaw (bez zewnętrznych bibliotek ML) zapewnia głębokie zrozumienie mechanizmów działania każdej metody, co jest niemożliwe przy wykorzystaniu gotowych usług chmurowych działających jako black-boxy.

Logika rozmyta z regułami IF-THEN (niniejsza praca) oferuje pełną przejrzystość decyzji algorytmu (explainable AI), czego brakuje w modelach deep learning używanych przez Google i Amazon.
\end{itemize}

\textbf{Podsumowanie}:

Własna implementacja systemu rekomendacji stanowi optymalny wybór dla małych i średnich platform e-commerce, łączący:
\begin{itemize}
\item Wysoką jakość rekomendacji (sześć komplementarnych metod pokrywających różne aspekty problemu),
\item Pełną kontrolę nad algorytmami i możliwość dostosowania do specyfiki biznesowej,
\item Niskie koszty operacyjne (brak opłat licencyjnych rozwiązań chmurowych),
\item Interpretowalność wyników i możliwość debugowania,
\item Elastyczność technologiczną (brak uzależnienia od konkretnego dostawcy chmury),
\item Wartość edukacyjną (implementacja od podstaw).
\end{itemize}

Rozwiązanie jest szczególnie atrakcyjne dla platform potrzebujących zaawansowanych funkcjonalności rekomendacji przy ograniczonym budżecie oraz możliwości dostosowania logiki do specyficznych wymagań biznesowych. System został zrealizowany we współpracy dwuosobowej jako kompleksowe rozwiązanie e-commerce.

\newpage

\section*{Rozdzia\l{} 3}
\addcontentsline{toc}{section}{Rozdział 3: Projekt systemu rekomendacyjnego}
\section*{Projekt systemu rekomendacyjnego}

Rozdział przedstawia szczegółowy opis projektowanej aplikacji e-commerce z zaawansowanym systemem rekomendacji produktów. Zaprezentowano wymagania funkcjonalne, diagram przypadków użycia ilustrujący interakcje użytkowników z systemem oraz architekturę funkcjonalną rozwiązania zrealizowanego we współpracy dwuosobowej.

\subsection*{3.1 Cel i zakres aplikacji}
\addcontentsline{toc}{subsection}{3.1 Cel i zakres aplikacji}

Aplikacja stanowi kompleksowe rozwiązanie e-commerce integrujące sześć komplementarnych metod rekomendacji produktów. System został zaprojektowany i zrealizowany we współpracy dwuosobowej, gdzie niniejsza praca obejmuje implementację trzech metod:
\begin{itemize}
\item \textbf{Content-Based Filtering} - odkrywanie produktów podobnych na podstawie cech produktowych (kategorie, tagi, cena, słowa kluczowe),
\item \textbf{Fuzzy Logic} - personalizacja rekomendacji z wykorzystaniem logiki rozmytej i funkcji przynależności Mamdani,
\item \textbf{Modele probabilistyczne} - predykcja sekwencji zakupowych (łańcuch Markowa) oraz prawdopodobieństwa zakupu (Naive Bayes).
\end{itemize}

Praca współautora koncentruje się na trzech komplementarnych metodach:
\begin{itemize}
\item \textbf{Collaborative Filtering} - odkrywanie produktów podobnych na podstawie wzorców zakupowych użytkowników z metryką Adjusted Cosine Similarity,
\item \textbf{Sentiment Analysis} - wieloźródłowa agregacja jakości produktów poprzez analizę opinii, opisów, nazw, specyfikacji i kategorii,
\item \textbf{Association Rules (Apriori)} - identyfikacja produktów często kupowanych razem z optymalizacją bitmap pruning.
\end{itemize}

System został zaprojektowany z myślą o małych i średnich platformach e-commerce (do 10000 produktów, do 100000 użytkowników), zapewniając funkcjonalności rekomendacyjne porównywalne z rozwiązaniami enterprise przy znacznie niższych kosztach operacyjnych i pełnej kontroli nad algorytmami.

\subsection*{3.2 Wymagania funkcjonalne systemu}
\addcontentsline{toc}{subsection}{3.2 Wymagania funkcjonalne systemu}

System został zaprojektowany z uwzględnieniem następujących wymagań funkcjonalnych podzielonych według typów użytkowników. Architektura wspiera pełną funkcjonalność e-commerce rozszerzoną o sześć metod rekomendacyjnych działających równolegle w ramach wspólnej infrastruktury.

\textbf{Dla gości (użytkowników niezalogowanych):}
\begin{itemize}
\item Przeglądanie katalogu produktów,
\item Wyszukiwanie produktów z wykorzystaniem różnych metod sortowania,
\item Dodawanie produktów do koszyka,
\item Logowanie do systemu,
\item Rejestracja w systemie.
\end{itemize}

\textbf{Dla klientów (użytkowników zalogowanych):}
\begin{itemize}
\item Wszystkie funkcjonalności gościa,
\item Składanie zamówień,
\item Śledzenie statusu zamówień,
\item Zarządzanie kontem użytkownika,
\item Wyświetlanie profilu użytkownika i historii zamówień,
\item Edycja danych osobowych,
\item Przeglądanie spersonalizowanych rekomendacji produktów generowanych przez wszystkie sześć metod:
  \begin{itemize}
\item \textit{Content-Based Filtering} (niniejsza praca) - rekomendacje produktów podobnych na podstawie cech,
\item \textit{Fuzzy Logic} (niniejsza praca) - rekomendacje z wykorzystaniem logiki rozmytej i profili użytkowników,
\item \textit{Modele probabilistyczne} (niniejsza praca) - predykcja sekwencji zakupowych i prawdopodobieństwa zakupu,
\item \textit{Collaborative Filtering} (współautor) - odkrywanie ukrytych wzorców na podstawie zachowań użytkowników,
\item \textit{Sentiment Analysis} (współautor) - produkty o najlepszych opiniach dopasowane do preferencji,
\item \textit{Association Rules - Apriori} (współautor) - produkty często kupowane razem w koszyku zakupowym.
\end{itemize}
\end{itemize}

\textbf{Dla administratorów:}
\begin{itemize}
\item Wszystkie funkcjonalności klienta,
\item Zarządzanie produktami (dodawanie, edycja, usuwanie),
\item Zarządzanie zamówieniami użytkowników i zmiana statusów zamówień,
\item Zarządzanie użytkownikami,
\item Przeglądanie panelu analitycznego (dashboard) i statystyk sprzedaży,
\item Debugowanie wszystkich sześciu algorytmów rekomendacji:
  \begin{itemize}
\item Przeglądanie podglądu rekomendacji dla każdej metody,
\item Sprawdzanie poprawności działania algorytmów,
\item Wyświetlanie statystyk i metryk dla każdej metody rekomendacji,
\end{itemize}
\item Generowanie macierzy podobieństw (CBF, Collaborative Filtering),
\item Trening modeli probabilistycznych, analizy sentymentu i reguł asocjacyjnych,
\item Zmiana aktywnych algorytmów rekomendacji w systemie.
\end{itemize}

\subsection*{3.3 Diagram przypadków użycia}
\addcontentsline{toc}{subsection}{3.3 Diagram przypadków użycia}

Diagram przypadków użycia (rys. \ref{fig:use_case_project}) przedstawia kompletny widok funkcjonalności systemu oraz relacji między aktorami a przypadkami użycia. System obsługuje trzy główne typy aktorów: Gościa (użytkownik niezalogowany), Klienta (użytkownik zalogowany) oraz Administratora (zarządzający systemem). Relacje dziedziczenia między aktorami (Gość $\rightarrow$ Klient $\rightarrow$ Administrator) odzwierciedlają hierarchię uprawnień - każdy następny poziom dziedziczy wszystkie funkcjonalności poprzedniego i dodaje nowe, specyficzne dla swojej roli.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{images/useCaseDiagram.png}
  \caption{Diagram przypadków użycia systemu.}
  \label{fig:use_case_project}
\end{figure}

System został podzielony na trzy główne obszary funkcjonalne:

\textbf{1. Obszar publiczny} (dostępny dla wszystkich użytkowników) - podstawowe funkcjonalności e-commerce takie jak przeglądanie produktów, wyszukiwanie, dodawanie do koszyka oraz procesy autentykacji (logowanie, rejestracja).

\textbf{2. Obszar klienta} (wymaga zalogowania) - funkcjonalności transakcyjne obejmujące składanie zamówień, śledzenie ich statusu, zarządzanie kontem oraz dostęp do spersonalizowanych rekomendacji generowanych przez wszystkie sześć zaimplementowanych algorytmów rekomendacyjnych.

\textbf{3. Obszar administracyjny} (wymaga uprawnień administratora) - narzędzia do zarządzania całym systemem: produktami, zamówieniami, użytkownikami oraz dostęp do paneli statystycznych i debugowania wszystkich sześciu algorytmów rekomendacji.

\subsection*{3.4 Architektura funkcjonalna systemu}
\addcontentsline{toc}{subsection}{3.4 Architektura funkcjonalna systemu}

System został zaprojektowany w architekturze warstwowej, gdzie każda warstwa odpowiada za konkretny aspekt funkcjonalności. Komunikacja między warstwami odbywa się poprzez RESTful API z uwierzytelnianiem JSON Web Tokens (JWT).

\textbf{Warstwa prezentacji} - interfejsy użytkownika dostosowane do ról (gość, klient, administrator):
\begin{itemize}
\item \textbf{Panel klienta} - dashboard z historią zamówień, sekcje rekomendacji (CBF, Fuzzy, Probabilistic, CF, Sentiment, Apriori), edycja profilu, śledzenie statusu zamówień,
\item \textbf{Panel administracyjny} - zarządzanie produktami/zamówieniami/użytkownikami, statystyki sprzedaży, panele debugowania wszystkich sześciu algorytmów rekomendacji.
\end{itemize}

\textbf{Warstwa logiki biznesowej} - implementacja sześciu algorytmów rekomendacji oraz logiki e-commerce:
\begin{itemize}
\item \textbf{Moduły niniejszej pracy}:
  \begin{itemize}
\item \textit{Moduł Content-Based Filtering} - generowanie macierzy podobieństwa produktów na podstawie cech (kategorie, tagi, cena, słowa kluczowe),
\item \textit{Moduł Fuzzy Logic} - system wnioskowania Mamdani z funkcjami przynależności i regułami IF-THEN,
\item \textit{Moduł Probabilistic Models} - łańcuch Markowa dla predykcji sekwencji zakupowych oraz Naive Bayes dla prawdopodobieństwa zakupu,
\end{itemize}
\item \textbf{Moduły współautora}:
  \begin{itemize}
\item \textit{Moduł Collaborative Filtering} - macierz podobieństwa produktów z metryką Adjusted Cosine Similarity,
\item \textit{Moduł Sentiment Analysis} - wieloźródłowa agregacja sentymentu z 5 źródeł tekstowych,
\item \textit{Moduł Apriori} - generowanie reguł asocjacyjnych typu ``Często kupowane razem'' z optymalizacją bitmap pruning,
\end{itemize}
\item \textbf{Logika transakcyjna} - składanie zamówień, zarządzanie statusami, walidacja danych, uwierzytelnianie JWT.
\end{itemize}

\textbf{Warstwa danych} - relacyjna baza danych PostgreSQL 14 przechowująca:
\begin{itemize}
\item Dane produktów (nazwa, opis, cena, kategorie, specyfikacje, zdjęcia) - 500 produktów w 48 kategoriach,
\item Dane użytkowników (konta, profile, uprawnienia, role) - 20 użytkowników testowych,
\item Dane transakcyjne (zamówienia, produkty w zamówieniach, statusy) - 265 zamówień z 569 pozycjami,
\item Dane opinii (recenzje tekstowe, oceny gwiazdkowe, timestamps) - $\sim$1750 opinii,
\item Wyniki algorytmów (macierze podobieństwa CBF i CF, profile rozmyte, macierz przejść Markova, predykcje Naive Bayes, zagregowany sentyment, reguły asocjacyjne) - 25 tabel w 4 modułach funkcjonalnych.
\end{itemize}

\textbf{Integracja warstw} odbywa się poprzez RESTful API z automatyczną synchronizacją - zmiana danych w jednej warstwie propaguje aktualizacje do pozostałych. Django Signals zapewniają automatyczne przeliczanie rekomendacji przy dodaniu nowego produktu lub zamówienia.

\subsection*{3.5 Kluczowe scenariusze użycia}
\addcontentsline{toc}{subsection}{3.5 Kluczowe scenariusze użycia}

\textbf{Scenariusz 1: Klient przegląda rekomendacje spersonalizowane}

Zalogowany użytkownik otwiera panel klienta. Na dashboardzie widzi sześć sekcji rekomendacji:
\begin{itemize}
\item \textit{``Podobne do Twoich zakupów''} (CBF) - produkty podobne na podstawie cech do wcześniej kupionych,
\item \textit{``Dopasowane do Twojego profilu''} (Fuzzy Logic) - rekomendacje uwzględniające wrażliwość cenową i preferencje kategorialne,
\item \textit{``Przewidujemy, że spodoba Ci się''} (Probabilistic) - produkty z kategorii przewidywanych przez łańcuch Markowa,
\item \textit{``Kupujący podobnie do Ciebie wybierają''} (CF - współautor) - odkrywanie ukrytych wzorców zakupowych,
\item \textit{``Najwyżej oceniane produkty''} (Sentiment - współautor) - produkty o najlepszym sentymencie opinii,
\item \textit{``Często kupowane razem''} (Apriori - współautor) - wyświetlane w koszyku zakupowym.
\end{itemize}

Użytkownik klika na produkt z sekcji CBF, zostaje przekierowany do strony szczegółowej, gdzie widzi dodatkową sekcję ``Podobne produkty'' również generowaną przez CBF.

\textbf{Scenariusz 2: Administrator debuguje algorytmy rekomendacji}

Administrator loguje się do panelu administracyjnego, otwiera sekcję ``Debug ML''. Przegląda panel debugowania wszystkich sześciu metod:
\begin{itemize}
\item \textit{CBF Debug} - macierz podobieństw produktów, wagi cech (kategorie 40\%, tagi 30\%, cena 20\%, słowa kluczowe 10\%), statystyki pokrycia (83\% produktów ma podobieństwo > 0.2),
\item \textit{Fuzzy Debug} - profile rozmyte użytkowników, funkcje przynależności (cheap/medium/expensive), aktywacja reguł IF-THEN,
\item \textit{Probabilistic Debug} - macierz przejść Markova (48x48), prawdopodobieństwa zakupu Naive Bayes, predykcja churnu,
\item \textit{CF Debug} (współautor) - macierz Adjusted Cosine Similarity, centrowanie średniej eliminujące bias,
\item \textit{Sentiment Debug} (współautor) - rozkład sentymentu, wieloźródłowa agregacja (opinie + opis + nazwa + specyfikacje + kategorie),
\item \textit{Apriori Debug} (współautor) - reguły asocjacyjne posortowane według lift, metryki support i confidence, wydajność bitmap pruning.
\end{itemize}

Administrator weryfikuje poprawność działania każdej metody, analizuje metryki wydajności i ewentualnie dostosowuje parametry (np. progi podobieństwa, wagi cech).

\textbf{Scenariusz 3: Gość dodaje produkty do koszyka i widzi rekomendacje cross-selling}

Niezalogowany użytkownik przegląda katalog produktów, dodaje laptop do koszyka. Przechodzi do widoku koszyka - system automatycznie wywołuje algorytm Apriori (współautor) i wyświetla sekcję ``Często kupowane razem'' z trzema produktami: torba na laptopa (lift=3.2, confidence=0.85), mysz bezprzewodowa (lift=2.9, confidence=0.78), hub USB-C (lift=2.5, confidence=0.72). Użytkownik decyduje się dodać torbę i mysz jednym kliknięciem. Przy próbie finalizacji zamówienia system przekierowuje do logowania lub rejestracji.

\subsection*{3.6 Podsumowanie opisu projektu}
\addcontentsline{toc}{subsection}{3.6 Podsumowanie opisu projektu}

Zaprojektowana aplikacja e-commerce z zaawansowanym systemem rekomendacji została zbudowana w architekturze warstwowej z wyraźną separacją odpowiedzialności (Separation of Concerns). System obsługuje hierarchię trzech typów użytkowników (gość, klient, administrator), gdzie każdy poziom dziedziczy funkcjonalności poprzedniego i dodaje nowe, specyficzne dla swojej roli.

Kluczowe cechy projektu:
\begin{itemize}
\item \textbf{Modułowość} - sześć niezależnych algorytmów rekomendacji (trzy w niniejszej pracy: CBF, Fuzzy Logic, Probabilistic; trzy w pracy współautora: CF, Sentiment Analysis, Apriori), które mogą działać osobno lub równolegle w ramach wspólnej infrastruktury,
\item \textbf{Komplementarność metod} - każdy algorytm rozwiązuje inny aspekt problemu rekomendacji (zimny start, personalizacja, serendipity, interpretowalność, cross-selling, jakość produktów),
\item \textbf{Architektura trójwarstwowa} - separacja prezentacji (React 18), logiki biznesowej (Django 5.1.4 + DRF 3.15.2) oraz danych (PostgreSQL 14 z 25 tabelami),
\item \textbf{RESTful API} - wszystkie funkcjonalności dostępne przez REST API z uwierzytelnianiem JWT,
\item \textbf{Interpretowalność} - szczególnie moduł Fuzzy Logic oferuje pełne wyjaśnienie rekomendacji przez reguły IF-THEN (explainable AI),
\item \textbf{Optymalizacja wydajności} - cache, bulk operations, indeksy bazodanowe zapewniają wydajność dla katalogów do 10000 produktów i 100000 użytkowników.
\end{itemize}

Szczegółowe aspekty techniczne implementacji (stos technologiczny, struktura backendu i frontendu, baza danych) zostały opisane w rozdziale 4, natomiast implementacja poszczególnych algorytmów rekomendacji stanowi przedmiot rozdziałów 5-7 (metody niniejszej pracy).

\newpage

\section*{Rozdzia\l{} 4}
\addcontentsline{toc}{section}{Rozdział 4: Przedstawienie wykorzystanego stosu technologicznego oraz praktycznej realizacji projektu}
\section*{Przedstawienie wykorzystanego stosu technologicznego oraz praktycznej realizacji projektu}

Niniejszy rozdział jest wspólny z pracą współautora i opisuje szczegóły techniczne całego systemu e-commerce z modułem rekomendacyjnym. Przedstawiono architekturę techniczną aplikacji, komponenty frontendowe i backendowe, strukturę bazy danych oraz mechanizmy wdrożenia.

\subsection*{4.1 Architektura systemu}
\addcontentsline{toc}{subsection}{4.1 Architektura systemu}

Aplikacja została zaprojektowana w architekturze klient-serwer opartej na technologiach Django (backend) oraz React (frontend). Komunikacja odbywa się poprzez RESTful API z uwierzytelnianiem tokenowym JSON Web Tokens (JWT). Struktura aplikacji wyraźnie rozdziela warstwę prezentacji (React SPA), logikę biznesową (widoki Django i serializery) oraz warstwę danych (PostgreSQL).

\textbf{Główne założenia architektoniczne:}

\begin{itemize}
\item \textbf{Separacja frontendu i backendu} - możliwość niezależnego rozwoju i skalowania obu warstw,
\item \textbf{Podejście API-first (API-first approach)} - wszystkie funkcjonalności dostępne przez REST API,
\item \textbf{Uwierzytelnianie bezstanowe (Stateless authentication)} - token JWT eliminuje potrzebę sesji po stronie serwera,
\item \textbf{Modułowa struktura} - każdy algorytm rekomendacji stanowi niezależny moduł.
\end{itemize}

\subsection*{4.2 Stos technologiczny backendu}
\addcontentsline{toc}{subsection}{4.2 Stos technologiczny backendu}

\textbf{Django 5.1.4 (Python 3.11)}

Django stanowi fundament aplikacji serwerowej, zapewniając architekturę MVC, system ORM (Object-Relational Mapping - mapowanie obiektowo-relacyjne) dla abstrakcji bazy danych oraz mechanizmy bezpieczeństwa (CSRF, XSS, SQL injection prevention). Architektura backendu opiera się na wzorcu Model-View-Serializer (MVS). Django zapewnia komponenty ORM, Signals oraz Middleware:

\textbf{Kluczowe komponenty Django:}

\begin{itemize}
\item \textbf{Django ORM} - mapowanie obiektowo-relacyjne umożliwiające operacje na bazie bez SQL,
\item \textbf{Django Signals} - mechanizm automatycznej aktualizacji rekomendacji przy zmianach danych,
\item \textbf{Django Middleware (oprogramowanie pośredniczące)} - obsługa CORS, uwierzytelnienie JWT, pamięć podręczna.
\end{itemize}

\textbf{Django REST Framework 3.15.2}

Rozszerza Django o funkcjonalności API RESTful:

\begin{itemize}
\item \textbf{Serializery} - konwersja obiektów Django na JSON z walidacją,
\item \textbf{ViewSets (zestawy widoków)} - widoki implementujące operacje CRUD,
\item \textbf{Uwierzytelnianie (Authentication)} - wsparcie dla JWT, uwierzytelnianie sesyjne,
\item \textbf{Pagination (paginacja)} - automatyczne stronicowanie wyników.
\end{itemize}

\textbf{Biblioteki Machine Learning}

Do operacji numerycznych i obliczania podobieństw wykorzystano:
\begin{itemize}
\item \textbf{NumPy 1.24} - operacje macierzowe dla wektorów cech i macierzy podobieństwa w CBF i modelu probabilistycznym,
\item \textbf{scikit-learn} - funkcja cosine\_similarity() dla Collaborative Filtering zaimplementowanego przez współautora.
\end{itemize}

\textbf{Struktura backendu}

Każdy komponent systemu posiada dedykowane pliki:

\begin{itemize}
\item \textbf{models.py} -- definicje tabel (Product, Order, Opinion, ProductSimilarity, FuzzyUserProfile, MarkovTransitions, PurchaseProbability, RecommendationSettings),
\item \textbf{serializers.py} -- konwersja obiektów Django $\leftrightarrow$ JSON,
\item \textbf{views.py} -- obsługa CRUD dla produktów, zamówień,
\item \textbf{custom\_recommendation\_engine.py} -- implementacje CBF, Markov, Naive Bayes (niniejsza praca),
\item \textbf{fuzzy\_logic\_engine.py} -- implementacja systemu Fuzzy Logic Mamdani (niniejsza praca),
\item \textbf{recommendation\_views.py} -- endpointy CBF: \texttt{/api/content-based-debug/}, \texttt{/api/generate-similarities/} (niniejsza praca),
\item \textbf{fuzzy\_views.py} -- endpointy Fuzzy: \texttt{/api/fuzzy-recommendations/}, \texttt{/api/fuzzy-debug/} (niniejsza praca),
\item \textbf{probabilistic\_views.py} -- endpointy Markov i Bayes: \texttt{/api/markov-recommendations/}, \texttt{/api/bayesian-insights/} (niniejsza praca),
\item \textbf{collaborative\_views.py} -- endpointy \texttt{/api/generate-user-recommendations/} (współautor),
\item \textbf{sentiment\_views.py} -- endpointy \texttt{/api/sentiment-search/}, \texttt{/api/sentiment-analysis-debug/} (współautor),
\item \textbf{association\_views.py} -- endpointy \texttt{/api/frequently-bought-together/}, \texttt{/api/update-association-rules/} (współautor),
\item \textbf{signals.py} -- automatyczna aktualizacja rekomendacji przy zmianach danych.
\end{itemize}

\subsection*{4.3 Stos technologiczny frontendu}
\addcontentsline{toc}{subsection}{4.3 Stos technologiczny frontendu}

\textbf{React 18}

React stanowi fundament aplikacji jednostronicowej (Single Page Application - SPA):

\begin{itemize}
\item \textbf{Architektura komponentowa (Component-based)} - reużywalne komponenty UI,
\item \textbf{Virtual DOM (wirtualny DOM)} - optymalizacja renderowania,
\item \textbf{React Hooks (haki React)} - useState, useEffect, useContext.
\end{itemize}

\textbf{Biblioteki wspierające}

\begin{itemize}
\item \textbf{React Router v6} - trasowanie (routing) dla aplikacji SPA,
\item \textbf{Axios} - komunikacja z API, przechwytywacze JWT (interceptors),
\item \textbf{Framer Motion} - płynne animacje,
\item \textbf{Context API} - zarządzanie stanem (AuthContext, CartContext).
\end{itemize}

\textbf{Architektura komponentów}

Frontend aplikacji został zbudowany jako Single Page Application (SPA) w technologii React 18, wykorzystując nowoczesne wzorce programowania funkcyjnego i React Hooks do zarządzania stanem. Architektura składa się z modułowych komponentów odpowiedzialnych za poszczególne funkcjonalności systemu.

\begin{itemize}
\item \textbf{App.js} -- główny komponent zarządzający routingiem React Router v6 oraz globalnym stanem poprzez Context API,
\item \textbf{Navbar.jsx} -- responsywna nawigacja z wyszukiwarką, linkami do kluczowych sekcji, przyciskami logowania/rejestracji oraz ikoną koszyka z licznikiem produktów,
\item \textbf{SearchModal.jsx} -- zaawansowany modal wyszukiwania z dwoma trybami: sentiment search (sortowanie według zagregowanego wyniku sentymentu - współautor) oraz fuzzy search (wyszukiwanie z wykorzystaniem logiki rozmytej - niniejsza praca),
\item \textbf{ShopContent.jsx} -- komponent wyświetlający katalog produktów z sidebar'em filtrów (kategorie, zakres cen, oceny) oraz grid'em kart produktów,
\item \textbf{ProductPage.jsx} -- szczegółowy widok produktu z galerią zdjęć, opisem, specyfikacjami technicznymi, sekcją opinii z analizą sentymentu (współautor), rekomendacjami "Frequently Bought Together" (Apriori - współautor),
\item \textbf{CartContent.jsx} -- koszyk zakupowy z sekcją rekomendacji cross-sell (reguły asocjacyjne - współautor),
\item \textbf{ClientPanel.jsx} -- panel klienta z zakładkami: Dashboard, Orders, Account, Recommendations (CBF, Fuzzy Logic, Probabilistic - niniejsza praca),
\item \textbf{AdminPanel.jsx} -- panel administracyjny z narzędziami debugowania algorytmów ML (wszystkie 6 metod).
\end{itemize}

\subsection*{4.4 Baza danych PostgreSQL}
\addcontentsline{toc}{subsection}{4.4 Baza danych PostgreSQL}

\textbf{Wybór PostgreSQL 14}

PostgreSQL został wybrany jako system zarządzania bazą danych ze względu na następujące cechy:

\begin{itemize}
\item \textbf{Zaawansowane indeksy} - wsparcie dla B-tree (domyślne), GIN (wyszukiwanie pełnotekstowe), BRIN (optymalizacja dla dużych tabel),
\item \textbf{Typ danych JSONB} - natywne przechowywanie i indeksowanie struktur JSON (wykorzystane w tabeli \texttt{method\_user\_purchase\_pattern} dla sezonowości zakupów),
\item \textbf{Transakcje ACID} - gwarancja atomowości, spójności, izolacji i trwałości operacji krytycznych (zamówienia, płatności),
\item \textbf{Klucze obce i constrainty} - automatyczne wymuszanie integralności referencyjnej oraz walidacji danych (np. rating 1-5 w opiniach),
\item \textbf{Optymalizacja JOIN} - wydajne łączenie tabel w złożonych zapytaniach rekomendacyjnych,
\item \textbf{Full-text search} - wbudowane mechanizmy wyszukiwania tekstowego dla produktów.
\end{itemize}

\textbf{Struktura bazy danych}

Baza składa się z \textbf{25 tabel} podzielonych na 4 moduły funkcjonalne:

\textbf{1. Moduł produktów i użytkowników (12 tabel):}

\begin{itemize}
\item \texttt{db\_product} - dane produktów (ID, nazwa, cena, opis),
\item \texttt{db\_category} - kategorie produktów z hierarchią,
\item \texttt{db\_product\_category} - relacja Many-to-Many produktów i kategorii,
\item \texttt{db\_photo\_product} - ścieżki do zdjęć produktów,
\item \texttt{db\_specification} - szczegółowe parametry techniczne produktów,
\item \texttt{db\_tag} - tagi do filtrowania produktów,
\item \texttt{db\_sale} - promocje i rabaty,
\item \texttt{db\_user} - konta użytkowników (role: admin/client),
\item \texttt{db\_order} - zamówienia z timestampami i statusami,
\item \texttt{db\_order\_product} - produkty w zamówieniach (ilość, cena),
\item \texttt{db\_cart\_item} - koszyk zakupowy przed finalizacją,
\item \texttt{db\_complaint} - reklamacje powiązane z zamówieniami.
\end{itemize}

\textbf{2. Moduł opinii i analizy sentymentu (3 tabele):}

\begin{itemize}
\item \texttt{db\_opinion} - opinie użytkowników (treść, rating 1-5),
\item \texttt{method\_sentiment\_analysis} - wyniki analizy sentymentu dla opinii,
\item \texttt{method\_product\_sentiment\_summary} - zagregowany sentyment produktu.
\end{itemize}

\textbf{3. Moduł metod rekomendacji (5 tabel):}

\begin{itemize}
\item \texttt{method\_product\_similarity} - macierz podobieństw produktów (Collaborative Filtering),
\item \texttt{method\_user\_product\_recommendation} - spersonalizowane rekomendacje użytkowników,
\item \texttt{method\_productassociation} - reguły asocjacyjne Apriori,
\item \texttt{method\_user\_interactions} - historia interakcji użytkowników,
\item \texttt{method\_recommendation\_settings} - konfiguracja algorytmów dla użytkownika.
\end{itemize}

\textbf{4. Moduł analityczny i prognozowanie (5 tabel):}

\begin{itemize}
\item \texttt{method\_purchase\_probability} - prawdopodobieństwo zakupu produktu przez użytkownika,
\item \texttt{method\_sales\_forecast} - prognoza sprzedaży produktów,
\item \texttt{method\_user\_purchase\_pattern} - wzorce zakupowe użytkowników,
\item \texttt{method\_product\_demand\_forecast} - prognoza popytu i poziomy magazynowe,
\item \texttt{method\_risk\_assessment} - ocena ryzyka dla użytkowników i produktów.
\end{itemize}

Wszystkie migracje Django ORM zostały wygenerowane automatycznie na podstawie modeli Python i zarządzane przez system wersjonowania \texttt{django.db.migrations}.

\newpage

\textbf{Diagramy ERD}

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{images/appErd.png}
  \caption{Diagram ERD głównych tabel aplikacji.}
  \label{fig:erd1}
\end{figure}

Rysunek \ref{fig:erd1} przedstawia rdzeń aplikacji e-commerce. Kluczowe relacje:

\begin{itemize}
\item \textbf{db\_user $\rightarrow$ db\_order} (1:N) - jeden użytkownik składa wiele zamówień,
\item \textbf{db\_order $\rightarrow$ db\_order\_product} (1:N) - zamówienie zawiera wiele produktów,
\item \textbf{db\_product $\leftrightarrow$ db\_category} (N:M) - produkt należy do wielu kategorii,
\item \textbf{db\_product $\rightarrow$ db\_opinion} (1:N) - produkt ma wiele opinii.
\end{itemize}

\newpage
\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{images/methodsErd.png}
  \caption{Diagram ERD tabel metod rekomendacyjnych.}
  \label{fig:erd2}
\end{figure}

Rysunek \ref{fig:erd2} pokazuje tabele algorytmów ML z podziałem na metody niniejszej pracy oraz metody współautora. System wykorzystuje wspólną infrastrukturę tabel do przechowywania wyników rekomendacji wszystkich sześciu metod.

\subsection*{4.5 Deployment i konteneryzacja Docker}
\addcontentsline{toc}{subsection}{4.5 Deployment i konteneryzacja Docker}

Aplikacja została skonteneryzowana przy użyciu Docker Compose, zapewniając spójność środowiska między środowiskiem deweloperskim (development), testowym (staging) i produkcyjnym (production).

\begin{figure}[H]
  \centering
  \includegraphics[width=0.92\textwidth]{images/dockerView.jpg}
  \caption{Deployment aplikacji w architekturze Docker Compose.}
  \label{fig:docker_view}
\end{figure}

Architektura składa się z trzech kontenerów (rys. \ref{fig:docker_view}):

\textbf{1. Kontener frontendu (React 18)}
\begin{itemize}
\item Base image: node:18-alpine,
\item Port: 3000,
\item Volumes: montowanie src/ dla automatycznego przeładowania (hot-reload),
\item Environment: REACT\_APP\_API\_URL,
\item Zależności (Dependencies): package.json (React, Axios, React Router, Framer Motion).
\end{itemize}

\textbf{2. Kontener backendu (Django 5.1.4)}
\begin{itemize}
\item Base image: python:3.11-slim,
\item Port: 8000,
\item Volumes: montowanie projektu dla automatycznego przeładowania (hot-reload), wolumen dla plików multimedialnych,
\item Environment: DATABASE\_URL, SECRET\_KEY, DEBUG, ALLOWED\_HOSTS,
\item Zależności (Dependencies): requirements.txt (Django, DRF, psycopg2, NumPy, scikit-learn).
\end{itemize}

\textbf{3. Kontener bazy danych (PostgreSQL 14)}
\begin{itemize}
\item Base image: postgres:14-alpine,
\item Port: 5432,
\item Volumes: named volume postgres\_data (persystencja danych),
\item Environment: POSTGRES\_DB, POSTGRES\_USER, POSTGRES\_PASSWORD,
\item Healthcheck: pg\_isready.
\end{itemize}

\textbf{Zalety konteneryzacji Docker}

\begin{itemize}
\item \textbf{Izolacja} - każdy serwis w osobnym kontenerze, zero konfliktów zależności,
\item \textbf{Przenośność} - obraz zbudowany raz działa na dowolnym serwerze z silnikiem Docker,
\item \textbf{Łatwa konfiguracja} - komenda \texttt{docker-compose up} uruchamia całą aplikację,
\item \textbf{Skalowalność} - możliwość uruchomienia wielu instancji backendu dla równoważenia obciążenia.
\end{itemize}

\subsection*{4.6 Podsumowanie stosu technologicznego}
\addcontentsline{toc}{subsection}{4.6 Podsumowanie stosu technologicznego}

Wybrane technologie (Django + React + PostgreSQL + Docker) tworzą nowoczesny, skalowalny i łatwy w utrzymaniu stos technologiczny. Kluczowe zalety:

\begin{itemize}
\item \textbf{Separacja kontynerów} - wyraźny podział frontend/backend/baza,
\item \textbf{Wygoda programisty} - narzędzia (Django ORM, haki React, Docker Compose) przyspieszają rozwój aplikacji,
\item \textbf{Wsparcie społeczności} - aktywna społeczność, obszerna dokumentacja,
\item \textbf{Wydajność} - optymalizacje (pamięć podręczna, indeksy bazy danych, operacje wektorowe NumPy) zapewniają szybki czas odpowiedzi.
\end{itemize}

\clearpage

\newpage
\section*{Rozdzia\l{} 5}
\addcontentsline{toc}{section}{Rozdział 5: Implementacja algorytmów rekomendacji}
\section*{Implementacja algorytmów rekomendacji}

Szczegółowa implementacja trzech algorytmów rekomendacyjnych wraz z pseudokodami oraz diagramami sekwencji przedstawia praktyczne aspekty realizacji metod Content-Based Filtering, logiki rozmytej oraz modeli probabilistycznych. Każda metoda została zaimplementowana od podstaw bez użycia gotowych bibliotek rekomendacyjnych.

Niniejszy rozdział oraz rozdziały 6 i 7 opisują szczegółowo implementację trzech metod rekomendacyjnych zrealizowanych w ramach niniejszej pracy: Content-Based Filtering, logikę rozmytą oraz modele probabilistyczne. System został rozbudowany przez współautora o trzy komplementarne metody (Collaborative Filtering, analiza sentymentu, reguły asocjacyjne), których szczegółowa implementacja stanowi przedmiot odrębnej pracy inżynierskiej.

\subsection*{5.1 Architektura systemu CBF}
\addcontentsline{toc}{subsection}{5.1 Architektura systemu CBF}

System Content-Based Filtering został zaimplementowany w klasie \texttt{CustomContentBasedFilter} w pliku \texttt{custom\_recommendation\_engine.py}. Architektura składa się z trzech głównych komponentów:

\textbf{1. Ekstraktor cech} (Feature Extractor) — odpowiada za budowę ważonego wektora cech dla każdego produktu. Analizuje cztery źródła danych:

\begin{itemize}
    \item \textbf{Kategorie} (waga 40\%) — główna klasyfikacja produktu. Format cechy: \texttt{category\_\{nazwa\}}. Przykład: \texttt{category\_Electronics}, \texttt{category\_Laptops}.
    \item \textbf{Tagi} (waga 30\%) — dodatkowe deskryptory (np. "Gaming", "Premium", "Budget"). Format: \texttt{tag\_\{nazwa\}}.
    \item \textbf{Przedział cenowy} (waga 20\%) — dyskretyzacja ceny: low (<100 PLN), medium (100-500), high (500-1500), premium (>1500).
    \item \textbf{Słowa kluczowe} (waga 10\%) — top 10 słów z opisu produktu po filtracji stop-words.
\end{itemize}

\textbf{2. Kalkulator podobieństwa} — oblicza podobieństwo kosinusowe między wektorami cech produktów. Operuje na wektorach rzadkich dla efektywności.

\textbf{3. Generator rekomendacji} — zwraca top N produktów podobnych do danego produktu, z filtrowaniem według dostępności i progu podobieństwa.

\textbf{Przepływ danych w systemie CBF}:

\begin{enumerate}
    \item Pobranie produktów z bazy z \texttt{prefetch\_related()} dla kategorii i tagów
    \item Ekstrakcja ważonych cech dla każdego produktu
    \item Obliczenie podobieństw dla wszystkich par produktów
    \item Filtracja podobieństw poniżej progu 0.2 (20\%)
    \item Zapis do tabeli \texttt{ProductSimilarity} za pomocą \texttt{bulk\_create()}
    \item Cache wyników na 2 godziny
\end{enumerate}

\subsection*{5.2 Implementacja ekstrakcji cech}
\addcontentsline{toc}{subsection}{5.2 Implementacja ekstrakcji cech}

Metoda ekstrakcji cech buduje słownik cech z przypisanymi wagami. Algorytm w pseudokodzie:

\begin{lstlisting}[style=pseudocode]
FUNKCJA ekstrahuj_cechy(produkt):
    cechy = pusty_slownik

    DLA KAZDEGO kategorii W produkt.kategorie:
        cechy["category_" + kategoria.nazwa] = 0.40

    DLA KAZDEGO tagu W produkt.tagi:
        cechy["tag_" + tag.nazwa] = 0.30

    JEZELI produkt.cena < 100 WTEDY
        cechy["price_low"] = 0.20
    INACZEJ JEZELI produkt.cena < 500 WTEDY
        cechy["price_medium"] = 0.20
    INACZEJ JEZELI produkt.cena < 1500 WTEDY
        cechy["price_high"] = 0.20
    INACZEJ
        cechy["price_premium"] = 0.20
    KONIEC

    slowa_kluczowe = ekstrahuj_slowa_kluczowe(produkt.opis)
    DLA KAZDEGO slowa W slowa_kluczowe[0:5]:
        cechy["keyword_" + slowo] = 0.10 / dlugosc(slowa_kluczowe)

    ZWROC cechy
KONIEC FUNKCJA
\end{lstlisting}

\textbf{Ekstrakcja słów kluczowych}:

Metoda \texttt{\_extract\_keywords()} przetwarza opis produktu:

\begin{enumerate}
    \item Konwersja na małe litery
    \item Usunięcie znaków interpunkcyjnych (regex)
    \item Tokenizacja na słowa
    \item Filtracja stop-words (zdefiniowana lista 200+ słów: "the", "and", "is", "a", "to", ...)
    \item Filtracja słów krótszych niż 4 znaki
    \item Zliczenie częstości (collections.Counter)
    \item Wybór top 10 najczęstszych słów
\end{enumerate}

\textbf{Dyskretyzacja ceny}:

Progi cenowe zostały dobrane empirycznie na podstawie rozkładu cen w katalogu:

\begin{itemize}
    \item \texttt{price\_low}: cena < 100 PLN — akcesoria, kable, drobne peryferia
    \item \texttt{price\_medium}: 100 PLN $\leq$ cena < 500 PLN — peryferia, komponenty
    \item \texttt{price\_high}: 500 PLN $\leq$ cena < 1500 PLN — monitory, karty graficzne
    \item \texttt{price\_premium}: cena $\geq$ 1500 PLN — laptopy, komputery, high-end
\end{itemize}

Dyskretyzacja eliminuje problem dużej wariancji cen i pozwala na porównywanie produktów z różnych kategorii cenowych.

\subsection*{5.3 Algorytm podobieństwa kosinusowego}
\addcontentsline{toc}{subsection}{5.3 Algorytm podobieństwa kosinusowego}

Metoda \texttt{calculate\_product\_similarity()} implementuje podobieństwo kosinusowe dla wektorów rzadkich (sparse vectors):

\begin{equation}
\text{similarity}(p_1, p_2) = \frac{\sum_{f \in F_{1} \cap F_{2}} w_1(f) \cdot w_2(f)}{\sqrt{\sum_{f \in F_1} w_1(f)^2} \cdot \sqrt{\sum_{f \in F_2} w_2(f)^2}}
\end{equation}

gdzie $F_1$, $F_2$ to zbiory cech produktów $p_1$ i $p_2$, $w_i(f)$ to waga cechy $f$ dla produktu $p_i$.

\textbf{Implementacja dla wektorów rzadkich} w pseudokodzie:

\begin{lstlisting}[style=pseudocode]
FUNKCJA oblicz_podobienstwo(cechy1, cechy2):
    wspolne_cechy = przeciecie(klucze(cechy1), klucze(cechy2))
    iloczyn_skalarny = suma(cechy1[f] * cechy2[f] DLA f W wspolne_cechy)

    norma1 = pierwiastek(suma(v^2 DLA v W wartosci(cechy1)))
    norma2 = pierwiastek(suma(v^2 DLA v W wartosci(cechy2)))

    JEZELI norma1 = 0 LUB norma2 = 0 WTEDY
        ZWROC 0.0
    KONIEC

    ZWROC iloczyn_skalarny / (norma1 * norma2)
KONIEC FUNKCJA
\end{lstlisting}

\textbf{Optymalizacja dla wektorów rzadkich}:

Zamiast tworzyć pełne wektory o długości równej liczbie wszystkich możliwych cech (potencjalnie tysiące), algorytm operuje na słownikach. Iloczyn skalarny wymaga iteracji tylko po cechach wspólnych (przecięcie zbiorów kluczy).

\textbf{Próg podobieństwa}:

System zapisuje tylko podobieństwa większe niż 0.2 (20\%). Uzasadnienie:
\begin{itemize}
    \item Podobieństwo < 0.2 oznacza mniej niż 20\% wspólnych cech — produkty są praktycznie różne
    \item Redukcja rozmiaru tabeli o 60-80\%
    \item Szybsze zapytania (mniej rekordów do przeszukania)
\end{itemize}

\subsection*{5.4 Generowanie macierzy podobieństw}
\addcontentsline{toc}{subsection}{5.4 Generowanie macierzy podobieństw}

Metoda \texttt{generate\_similarities\_for\_all\_products()} oblicza podobieństwa dla wszystkich par produktów:

\textbf{Etap 1: Prefetching danych}

Wykorzystujemy mechanizm \texttt{prefetch\_related()} frameworka Django dla kategorii, tagów i specyfikacji, redukując liczbę zapytań SQL z $O(n \times k)$ do $O(1)$ dla $n$ produktów z $k$ relacjami. Ta technika pobiera wszystkie powiązane obiekty w jednym zapytaniu SQL zamiast osobnego zapytania dla każdego produktu.

\textbf{Etap 2: Ekstrakcja cech}

Dla każdego produktu ekstrahujemy wektor cech i zapisujemy w słowniku, gdzie kluczem jest identyfikator produktu, a wartością jego wektor cech.

\textbf{Etap 3: Obliczenie podobieństw}

Dla każdej pary produktów $(p_i, p_j)$ gdzie $i < j$ obliczamy podobieństwo kosinusowe. Algorytm w pseudokodzie:

\begin{lstlisting}[style=pseudocode]
DLA KAZDEGO produktu1 W produkty:
    DLA KAZDEGO produktu2 W produkty[indeks(produkt1)+1:]:
        podobienstwo = oblicz_podobienstwo(cechy[produkt1], cechy[produkt2])

        JEZELI podobienstwo > 0.2 WTEDY
            zapisz_podobienstwo(produkt1, produkt2, podobienstwo)
            zapisz_podobienstwo(produkt2, produkt1, podobienstwo)
        KONIEC
    KONIEC
KONIEC
\end{lstlisting}

Zapisywane są oba kierunki relacji (symetryczne), co umożliwia szybkie wyszukiwanie produktów podobnych do dowolnego produktu.

\textbf{Etap 4: Bulk insert}

Zapisywanie podobieństw odbywa się w partiach po 1000 rekordów przy użyciu mechanizmu \texttt{bulk\_create()}, który przyspiesza zapis 50-100x względem pojedynczych operacji INSERT.

\textbf{Etap 5: Cache}

Wynik generowania macierzy podobieństw jest cachowany na 2 godziny (7200 sekund), eliminując potrzebę ponownego obliczania przy każdym żądaniu.

\textbf{Złożoność obliczeniowa}:

Teoretyczna złożoność to $O(n^2)$ dla $n$ produktów (wszystkie pary). W praktyce ograniczamy liczbę porównań przez:
\begin{itemize}
    \item \texttt{max\_comparisons\_per\_product = 50} — dla każdego produktu obliczamy podobieństwo do max 50 innych
    \item Wczesne odrzucanie produktów bez wspólnych kategorii
\end{itemize}

Dla katalogu 500 produktów:
\begin{itemize}
    \item Teoretycznie: $500 \times 499 / 2 = 124,750$ par
    \item Po optymalizacji: ~25,000 obliczonych podobieństw
    \item Po filtrowaniu (próg 0.2): ~4,000 zapisanych rekordów
\end{itemize}

\subsection*{5.5 Panel debugowania Content-Based Filtering}
\addcontentsline{toc}{subsection}{5.5 Panel debugowania Content-Based Filtering}

System oferuje zaawansowany panel debugowania dostępny przez endpoint \texttt{/api/content-based-debug/}. Panel prezentuje:

\textbf{Widok ogólny (bez parametru product\_id)}:

\begin{itemize}
    \item \textbf{Szczegóły algorytmu}: nazwa, metoda (Weighted Feature Vectors + Cosine Similarity), status
    \item \textbf{Wagi cech}: category (40\%), tag (30\%), price (20\%), keywords (10\%)
    \item \textbf{Statystyki bazy danych}: liczba produktów, zapisanych podobieństw, procent pokrycia
    \item \textbf{Status cache}: HIT/MISS, czas wygaśnięcia
    \item \textbf{Top 10 podobieństw}: produkty o najwyższym podobieństwie w systemie
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/contentBasedAdminDebug1.jpg}
  \caption{Panel debugowania Content-Based Filtering.}
  \label{fig:cbf_debug1}
\end{figure}

\textbf{Widok szczegółowy (z parametrem product\_id)}:

Dla konkretnego produktu panel pokazuje:

\begin{itemize}
    \item Wektor cech produktu z wagami (słownik feature → weight)
    \item Top 10 produktów podobnych z szczegółami obliczeń
    \item Wzór matematyczny dla każdej pary: $\frac{dot\_product}{norm_1 \times norm_2}$
    \item Cechy wspólne między produktami
    \item Breakdown podobieństwa: ile % z kategorii, ile z tagów, ile z ceny, ile z keywords
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/contentBasedAdminDebug2.jpg}
  \caption{CBF - szczegółowa analiza podobieństwa produktu.}
  \label{fig:cbf_debug2}
\end{figure}

\textbf{Przykładowe dane z panelu debugowania}:

\begin{verbatim}
Algorithm: Content-Based Filtering (Cosine Similarity)
Formula: cos(θ) = (A·B) / (||A|| × ||B||)

Database Statistics:
- Total Products: 500
- Saved Similarities: 16038
- Percentage Saved: 6.43%
- Threshold: 20% (Only similarities > 20% are saved to database)

Feature Weights:
- Category: 40%
- Tag: 30%
- Price: 20%
- Keywords: 10%
\end{verbatim}

\textbf{Przykład wektora cech produktu} (ACEFAST Powerbank MagSafe M10 10000 mAh):

\begin{verbatim}
Feature Vector (12 features):
- category_accessories.powerbanks: 0.400
- tag_budget:                      0.300
- tag_portable:                    0.300
- tag_fast charging:               0.300
- tag_magsafe compatible:          0.300
- tag_wireless:                    0.300
- price_low:                       0.200
- keyword_charging:                0.020
- keyword_power:                   0.020
- keyword_fast:                    0.020
- keyword_devices:                 0.020
- keyword_magsafe:                 0.020

Top 10 Similar Products:
#1 Baseus Magnetic Mini Wireless Charging 20W 20000mAh z MagSafe: 99.90%
#2 Baseus Magnetic Mini Wireless Charging 20W 20000mAh z MagSafe: 99.90%
#3 Belkin Magnetic Wireless 5000mAh MagSafe + Stand: 99.90%
#4 Baseus mini 5000mAh 20W (magnetyczny): 92.70%
#5 Belkin 20000mAh (15W, USB-C, USB-A): 84.90%

Detailed Calculation (#1):
- Dot Product: 0.6512
- Norm Product 1: 0.8075
- Norm Product 2: 0.8075
- Formula: 0.6512 / (0.8075 × 0.8075) = 0.9988
- Verification: Stored: 0.999 | Calculated: 0.9988 ✓
- Common Features: 10 total
\end{verbatim}

Panel umożliwia administratorowi:
\begin{itemize}
    \item Monitorowanie pokrycia rekomendacji (ile produktów ma podobieństwa)
    \item Identyfikację produktów bez podobieństw (słabo opisane metadane)
    \item Walidację działania wag (czy kategorie dominują prawidłowo)
    \item Ręczne wyzwalanie przeliczenia macierzy
\end{itemize}

\subsection*{5.6 Interfejs użytkownika - sortowanie według CBF}
\addcontentsline{toc}{subsection}{5.6 Interfejs użytkownika - sortowanie według CBF}

Metoda Content-Based Filtering jest wykorzystywana jako jedna z opcji sortowania produktów na stronie głównej sklepu. Administrator może wybrać algorytm CBF w ustawieniach systemu rekomendacji, co powoduje wyświetlanie produktów podobnych do tych, które użytkownik wcześniej przeglądał lub kupił.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/contentBasedAdmin1.jpg}
  \caption{Panel administratora - rekomendacje CBF.}
  \label{fig:cbf_admin}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicAdmin1.jpg}
  \caption{Panel administratora - rekomendacje Fuzzy Logic.}
  \label{fig:fuzzy_admin}
\end{figure}

Porównanie rysunków \ref{fig:cbf_admin} i \ref{fig:fuzzy_admin} demonstruje kluczową różnicę między metodami: przełączenie algorytmu z Content-Based Filtering na Fuzzy Logic powoduje natychmiastową zmianę rekomendowanych produktów. CBF poleca produkty o podobnych cechach (kategoria, tagi, cena), podczas gdy Fuzzy Logic uwzględnia dodatkowo rozmyty profil użytkownika i reguły wnioskowania.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/contentBasedSequenceDiagram.png}
  \caption{Diagram sekwencji - Content-Based Filtering.}
  \label{fig:cbf_sequence}
\end{figure}

Proces generowania rekomendacji CBF przebiega następująco:
\begin{enumerate}
    \item Klient przegląda produkt na stronie ProductPage
    \item Frontend wysyła żądanie GET do \newline
    \texttt{/api/recommendations/content-based/?product\_id=\{id\}}
    \item Backend (ContentBasedAPI) wykonuje zapytanie do modelu ProductSimilarity
    \item Model pobiera top 10 podobnych produktów z bazy danych (sortowanie po \texttt{-similarity\_score})
    \item Backend zwraca odpowiedź 200 OK z listą rekomendacji (product\_id, name, price, similarity\_score)
    \item Frontend wyświetla sekcję "Podobne produkty" na stronie produktu
\end{enumerate}

Rekomendacje CBF są również dostępne w panelu klienta, gdzie użytkownik może zobaczyć produkty podobne do swoich poprzednich zakupów. System automatycznie identyfikuje produkty z wysokim współczynnikiem podobieństwa (powyżej 20\%) i prezentuje je w sekcji spersonalizowanych rekomendacji.

\newpage

\section*{Rozdzia\l{} 6}
\addcontentsline{toc}{section}{Rozdział 6: Logika rozmyta}
\section*{Logika rozmyta w systemie rekomendacji}

\subsection*{6.1 Architektura systemu Fuzzy Logic}
\addcontentsline{toc}{subsection}{6.1 Architektura systemu Fuzzy Logic}

System logiki rozmytej został zaimplementowany w module \texttt{fuzzy\_logic\_engine.py} i składa się z trzech klas:

\textbf{1. FuzzyMembershipFunctions} — definiuje funkcje przynależności dla trzech zmiennych wejściowych:

\begin{itemize}
    \item \textbf{Cena} (price): cheap, medium, expensive — funkcje trójkątne i trapezoidalne z progami dostosowanymi do katalogu e-commerce
    \item \textbf{Jakość} (quality/rating): low, medium, high — bazuje na średniej ocenie produktu (1-5 gwiazdek)
    \item \textbf{Popularność} (popularity/view\_count): low, medium, high — bazuje na liczbie zamówień produktu
\end{itemize}

\textbf{2. FuzzyUserProfile} — buduje rozmyty profil użytkownika na podstawie:

\begin{itemize}
    \item Historii zakupów (dla zalogowanych użytkowników) — analiza kategorii, średniej ceny
    \item Danych sesji (dla gości) — ostatnio przeglądane produkty
    \item Profilu domyślnego (fallback) — gdy brak danych
\end{itemize}

\textbf{3. SimpleFuzzyInference} — silnik wnioskowania Mamdani z 6 regułami IF-THEN i metodą defuzzyfikacji średniej ważonej.

\textbf{Przepływ danych}:

\begin{enumerate}
    \item Pobranie produktów do ewaluacji
    \item Pobranie/budowa rozmytego profilu użytkownika
    \item Dla każdego produktu:
    \begin{enumerate}
        \item Fuzzyfikacja ceny, jakości, popularności
        \item Ewaluacja 6 reguł rozmytych
        \item Agregacja wyników reguł
        \item Defuzzyfikacja do wyniku liczbowego
    \end{enumerate}
    \item Sortowanie produktów według fuzzy\_score
    \item Zwrócenie top N rekomendacji
\end{enumerate}

\subsection*{6.2 Funkcje przynależności — szczegóły implementacji}
\addcontentsline{toc}{subsection}{6.2 Funkcje przynależności}

\textbf{Funkcje przynależności dla ceny}

Klasa \texttt{FuzzyMembershipFunctions} definiuje trzy funkcje dla zmiennej "cena":

\textit{Funkcja "cheap" (tania)} — trójkątna/trapezoidalna:

\begin{equation}
\mu_{cheap}(price) = \begin{cases}
1.0 & \text{jeśli } price \leq 100 \\
\frac{500 - price}{400} & \text{jeśli } 100 < price < 500 \\
0.0 & \text{jeśli } price \geq 500
\end{cases}
\end{equation}

Interpretacja: Produkty poniżej 100 PLN są w pełni "tanie". Od 100 do 500 PLN stopień "taności" maleje liniowo.

\textit{Funkcja "medium" (średnia)} — trapezoidalna:

\begin{equation}
\mu_{medium}(price) = \begin{cases}
0.0 & \text{jeśli } price < 300 \\
\frac{price - 300}{200} & \text{jeśli } 300 \leq price < 500 \\
1.0 & \text{jeśli } 500 \leq price \leq 1200 \\
\frac{1500 - price}{300} & \text{jeśli } 1200 < price < 1500 \\
0.0 & \text{jeśli } price \geq 1500
\end{cases}
\end{equation}

Interpretacja: Przedział $[500, 1200]$ ma pełną przynależność. Przejścia są płynne — cena 400 PLN jest częściowo "tania" i częściowo "średnia".

\textit{Funkcja "expensive" (droga)}:

\begin{equation}
\mu_{expensive}(price) = \begin{cases}
0.0 & \text{jeśli } price \leq 1000 \\
\frac{price - 1000}{1000} & \text{jeśli } 1000 < price < 2000 \\
1.0 & \text{jeśli } price \geq 2000
\end{cases}
\end{equation}

\textbf{Funkcje przynależności dla jakości (rating)}

Oparte na średniej ocenie produktu (skala 1-5):

\begin{itemize}
    \item \textbf{low}: pełna przynależność dla rating $\leq 2.0$, zanika do 0 przy rating = 3.0
    \item \textbf{medium}: trapezoid z pełną przynależnością dla $[3.0, 4.0]$
    \item \textbf{high}: wzrasta od rating = 3.5, pełna przynależność dla rating $\geq 4.5$
\end{itemize}

\textbf{Funkcje przynależności dla popularności (order\_count)}

Oparte na liczbie zamówień produktu:

\begin{itemize}
    \item \textbf{low}: produkty z $\leq 2$ zamówieniami (nowości, niszowe)
    \item \textbf{medium}: produkty z 3-20 zamówieniami (standardowe)
    \item \textbf{high}: produkty z $> 20$ zamówieniami (bestsellery)
\end{itemize}

\textbf{Definicje funkcji przynależności dla ceny}:

Funkcja \textbf{cheap} (trójkątna): $\mu = 1.0$ dla ceny $\leq 100$ PLN, liniowy spadek do $\mu = 0$ przy 500 PLN.

Funkcja \textbf{medium} (trapezoidalna): $\mu = 0$ dla ceny $< 300$ PLN, wzrost do $\mu = 1.0$ w przedziale 300-500 PLN, plateau $\mu = 1.0$ w przedziale 500-1200 PLN, spadek do $\mu = 0$ przy 1500 PLN.

Funkcja \textbf{expensive} (trójkątna): $\mu = 0$ dla ceny $\leq 1000$ PLN, liniowy wzrost do $\mu = 1.0$ przy 2000 PLN i powyżej.

\subsection*{6.3 Rozmyty profil użytkownika}
\addcontentsline{toc}{subsection}{6.3 Rozmyty profil użytkownika}

Klasa \texttt{FuzzyUserProfile} buduje profil preferencji użytkownika jako zbiory rozmyte. Jest to kluczowy element personalizacji rekomendacji.

\textbf{Dla zalogowanych użytkowników}:

\begin{enumerate}
    \item Pobranie historii zamówień z \texttt{prefetch\_related} dla powiązanych produktów i kategorii
    \item Zliczenie kategorii produktów w zamówieniach
    \item Obliczenie stopnia zainteresowania kategorią:
    \begin{equation}
    \mu_{category} = \frac{count_{category}}{total\_items}
    \end{equation}
    \item Obliczenie wrażliwości cenowej na podstawie średniej ceny zakupów
\end{enumerate}

\textbf{Wrażliwość cenowa} (price\_sensitivity):

\begin{equation}
\text{price\_sensitivity} = \begin{cases}
0.9 & \text{jeśli } avg\_price < 300 \text{ PLN (bardzo wrażliwy)} \\
0.6 & \text{jeśli } 300 \leq avg\_price < 700 \text{ (średnio wrażliwy)} \\
0.4 & \text{jeśli } 700 \leq avg\_price < 1500 \text{ (mało wrażliwy)} \\
0.2 & \text{jeśli } avg\_price \geq 1500 \text{ PLN (premium)}
\end{cases}
\end{equation}

Użytkownik kupujący średnio tanie produkty (avg < 300 PLN) ma wysoką wrażliwość cenową (0.9) — system będzie promował tanie produkty. Użytkownik premium (avg > 1500 PLN) ma niską wrażliwość (0.2) — system może rekomendować droższe produkty.

\textbf{Dopasowanie kategorii} — metoda \texttt{fuzzy\_category\_match()}:

Dla każdej kategorii produktu system oblicza stopień dopasowania do profilu użytkownika:

\begin{equation}
\text{match} = 0.6 \cdot \text{similarity}(cat_{user}, cat_{product}) + 0.4 \cdot \mu_{interest}(cat_{user})
\end{equation}

gdzie \texttt{similarity} używa hierarchii kategorii. Przykład:
\begin{itemize}
    \item Kategoria użytkownika: "Electronics.Laptops"
    \item Kategoria produktu: "Electronics.Monitors"
    \item Podobieństwo hierarchiczne: 0.7 (wspólna kategoria nadrzędna "Electronics")
\end{itemize}

\textbf{Profil domyślny} (dla gości/nowych użytkowników):

Dla użytkowników bez historii zakupów system stosuje neutralny profil domyślny:
\begin{itemize}
    \item price\_sensitivity = 0.5 (neutralna wrażliwość cenowa)
    \item category\_preferences = \{\} (brak preferencji kategorii)
    \item quality\_preference = 0.7 (preferuje dobrą jakość)
    \item popularity\_preference = 0.5 (neutralna wobec popularności)
\end{itemize}

\subsection*{6.4 Baza reguł rozmytych}
\addcontentsline{toc}{subsection}{6.4 Baza reguł rozmytych}

System wykorzystuje 6 reguł rozmytych typu Mamdani. Każda reguła ma formę IF-THEN z przypisaną wagą określającą jej ważność:

\textbf{R1: High Quality Bargain} (waga: 0.9)

\begin{lstlisting}[style=pseudocode]
JEZELI quality JEST high ORAZ (price JEST cheap LUB price JEST medium)
WTEDY recommendation JEST strong
\end{lstlisting}

Logika: Wysokiej jakości produkt w rozsądnej cenie to doskonała okazja. Najwyższa waga — ta reguła najsilniej wpływa na wynik.

\textbf{R2: Popular in Category} (waga: 0.7)

\begin{lstlisting}[style=pseudocode]
JEZELI category_match JEST high ORAZ (popularity JEST medium LUB popularity JEST high)
WTEDY recommendation JEST medium-high
\end{lstlisting}

Logika: Popularny produkt z kategorii interesującej użytkownika. Popularność = walidacja społeczna.

\textbf{R3: Price Sensitive Match} (waga: 0.6)

\begin{lstlisting}[style=pseudocode]
JEZELI user.price_sensitivity > 0.6 ORAZ price JEST cheap
WTEDY recommendation JEST moderate
\end{lstlisting}

Logika: Dla użytkowników wrażliwych cenowo (kupujących tanie produkty) promuj tanie opcje.

\textbf{R4: Category Quality Match} (waga: 0.85)

\begin{lstlisting}[style=pseudocode]
JEZELI category_match JEST high ORAZ (quality JEST medium LUB quality JEST high)
WTEDY recommendation JEST strong
\end{lstlisting}

Logika: Dopasowanie do kategorii + dobra jakość. Wysoka waga — dopasowanie kategorii jest istotne.

\textbf{R5: Premium Match} (waga: 0.8)

\begin{lstlisting}[style=pseudocode]
JEZELI user.price_sensitivity < 0.4 ORAZ price JEST expensive ORAZ quality JEST high
WTEDY recommendation JEST strong
\end{lstlisting}

Logika: Dla użytkowników premium (nieczułych cenowo) promuj drogie produkty wysokiej jakości.

\textbf{R6: Quality-Price Balance} (waga: 0.75)

\begin{lstlisting}[style=pseudocode]
JEZELI (quality JEST high ORAZ price JEST reasonable) LUB
       (quality JEST medium ORAZ price JEST cheap)
WTEDY recommendation JEST moderate
\end{lstlisting}

Logika: Dobry stosunek jakości do ceny — "value for money".

\subsection*{6.5 Wnioskowanie i defuzzyfikacja}
\addcontentsline{toc}{subsection}{6.5 Wnioskowanie i defuzzyfikacja}

Metoda \texttt{evaluate\_product()} implementuje pełny cykl wnioskowania Mamdani:

\textbf{Krok 1: Fuzzyfikacja}

Dla każdej zmiennej wejściowej (cena, jakość, popularność) obliczane są stopnie przynależności do wszystkich zbiorów rozmytych. Wynikiem jest słownik zawierający 9 wartości przynależności:

\begin{itemize}
    \item Cena: $\mu_{cheap}$, $\mu_{medium}$, $\mu_{expensive}$
    \item Jakość: $\mu_{low}$, $\mu_{medium}$, $\mu_{high}$
    \item Popularność: $\mu_{low}$, $\mu_{medium}$, $\mu_{high}$
\end{itemize}

\textbf{Krok 2: Ewaluacja reguł}

Każda reguła jest ewaluowana za pomocą T-normy (minimum) dla operatora AND i T-conormy (maksimum) dla OR. Zgodnie z teorią zbiorów rozmytych \cite{zadeh1965fuzzy}:

\begin{equation}
\alpha_{R1} = \min(\mu_{quality\_high}, \max(\mu_{price\_cheap}, \mu_{price\_medium})) \cdot w_{R1}
\end{equation}

Dla każdej z 6 reguł obliczana jest jej aktywacja $\alpha_i$ poprzez aplikację odpowiednich operatorów rozmytych do wartości przynależności.

\textbf{Krok 3: Agregacja}

Wyniki reguł są agregowane. W uproszczonej implementacji używam sumy ważonej (zamiast pełnej agregacji Mamdani):

\begin{equation}
\text{aggregated} = \sum_{i=1}^{6} \alpha_i
\end{equation}

\textbf{Krok 4: Defuzzyfikacja}

System używa uproszczonej metody średniej ważonej:

\begin{equation}
\text{fuzzy\_score} = \frac{\sum_{i=1}^{6} \alpha_i \cdot w_i}{\sum_{i=1}^{6} w_i}
\end{equation}

gdzie $\alpha_i$ to aktywacja reguły $i$, a $w_i$ to waga reguły.

Wagi reguł wynoszą: $w_{R1} = 0.9$, $w_{R2} = 0.7$, $w_{R3} = 0.6$, $w_{R4} = 0.85$, $w_{R5} = 0.8$, $w_{R6} = 0.75$. Suma wag wynosi 4.65, co zapewnia normalizację wyniku do przedziału $[0, 1]$.

\textbf{Wynik końcowy}:

Metoda zwraca słownik z:
\begin{itemize}
    \item \texttt{fuzzy\_score} — wartość z przedziału $[0, 1]$ reprezentująca siłę rekomendacji
    \item \texttt{rule\_activations} — słownik z aktywacją każdej reguły (dla debugowania)
    \item \texttt{category\_match} — stopień dopasowania kategorii
    \item \texttt{price\_membership} — przynależności cenowe (cheap, medium, expensive)
\end{itemize}

\subsection*{6.6 Panel debugowania Fuzzy Logic}
\addcontentsline{toc}{subsection}{6.6 Panel debugowania Fuzzy Logic}

Panel debugowania dostępny przez endpoint \texttt{/api/fuzzy-debug/} prezentuje:

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicAdminDebug1.jpg}
  \caption{Panel debugowania Fuzzy Logic.}
  \label{fig:fuzzy_debug1}
\end{figure}

\textbf{Widok ogólny}:

\begin{itemize}
    \item \textbf{Szczegóły algorytmu}: metoda (Mamdani Fuzzy Inference), liczba reguł (6), T-norma (min), T-conorma (max)
    \item \textbf{Funkcje przynależności}: definicje dla price, quality, popularity z progami
    \item \textbf{Statystyki}: średni fuzzy\_score, rozkład wyników, aktywacja reguł
    \item \textbf{Profil użytkownika}: jeśli podany user\_id — szczegóły profilu rozmytego
\end{itemize}

\textbf{Widok produktu} (z parametrem product\_id):

\begin{itemize}
    \item Wartości fuzzyfikacji (wszystkie przynależności)
    \item Aktywacja każdej z 6 reguł z wyjaśnieniem
    \item Obliczenie końcowe z breakdownem
    \item Porównanie z innymi produktami
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicAdminDebug2.jpg}
  \caption{Fuzzy Logic - ewaluacja produktu.}
  \label{fig:fuzzy_debug2}
\end{figure}

\textbf{Przykładowe dane z panelu debugowania}:

\begin{verbatim}
Algorithm: Fuzzy Logic Inference System (Mamdani-style)
Description: System rekomendacji oparty na logice rozmytej
z uproszczona defuzzyfikacja

User Profile:
- User: admin2 (ID: 2)
- Profile Type: authenticated
- Price Sensitivity: 0.6 - Medium
- Tracked Categories: 26

Category Interests:
- wearables.watches: 0.132
- networking.networkCards: 0.093
- peripherals.microphones: 0.066
- monitoring.cameras: 0.06
- gadgets: 0.06

Membership Functions:
Price Functions:
- CHEAP: μ = 1.0 dla ceny ≤ 100 PLN, spada do 0 przy 500 PLN
- MEDIUM: μ = 1.0 dla ceny 500-1200 PLN
- EXPENSIVE: μ = 1.0 dla ceny ≥ 2000 PLN
\end{verbatim}

\textbf{Przykład fuzzyfikacji produktu} (AMD Ryzen 9 7900X, cena: 400 PLN, rating: 3, views: 1):

\begin{verbatim}
Selected Product:
- ID: 96
- Name: AMD Ryzen 9 7900X
- Price: 400 PLN
- Rating: 3
- View Count: 1
- Categories: components.processors

Fuzzification - Membership Degrees:
Price: 400 PLN
- Cheap: μ = 0.25
- Medium: μ = 0.5
- Expensive: μ = 0
- Dominant: MEDIUM

Quality: 3
- Low: μ = 0.5
- Medium: μ = 0.5
- High: μ = 0
- Dominant: LOW

Popularity: 1 views
- Low: μ = 1
- Medium: μ = 0
- High: μ = 0
- Dominant: LOW

Category Matching:
- Max Match: 0.394
- components.processors: 0.394
\end{verbatim}

\subsection*{6.7 Interfejs użytkownika - rekomendacje Fuzzy Logic}
\addcontentsline{toc}{subsection}{6.7 Interfejs użytkownika - rekomendacje Fuzzy Logic}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/fuzzyLogicSequenceDiagram.png}
  \caption{Diagram sekwencji - Fuzzy Logic.}
  \label{fig:fuzzy_sequence}
\end{figure}

Rekomendacje oparte na logice rozmytej są prezentowane użytkownikowi w panelu klienta w sekcji "Recommended For You (Fuzzy Logic)". System wyświetla wykres kołowy przedstawiający rozkład kategorii w historii zakupów użytkownika oraz listę rekomendowanych produktów.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicClient1.jpg}
  \caption{Panel klienta - rekomendacje Fuzzy Logic.}
  \label{fig:fuzzy_client}
\end{figure}

Wykres "Category Distribution" pokazuje procentowy udział kategorii w historii zakupów użytkownika (np. electronics.phones, accessories.powerBanks, wearables.watches, peripherals.printers, office.accessories). Na podstawie tych danych system buduje rozmyty profil użytkownika i generuje spersonalizowane rekomendacje.

Sekcja "Recommended For You (Fuzzy Logic)" prezentuje produkty z najwyższym wynikiem fuzzy\_score, uwzględniając:
\begin{itemize}
    \item Dopasowanie do kategorii zainteresowań użytkownika
    \item Wrażliwość cenową użytkownika
    \item Jakość produktu (rating)
    \item Popularność produktu (view\_count)
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicClient2.jpg}
  \caption{Zakładka "Fuzzy Recommendations".}
  \label{fig:fuzzy_client2}
\end{figure}

Zakładka "Fuzzy Recommendations" wyświetla produkty wraz z:
\begin{itemize}
    \item \textbf{Fuzzy Score}: całkowity wynik rekomendacji (np. 58.1\%, 56.3\%)
    \item \textbf{Category Match}: stopień dopasowania kategorii do preferencji użytkownika (np. 65.9\%, 60.6\%)
    \item \textbf{View Rule Activations}: przycisk do podglądu aktywacji wszystkich 6 reguł rozmytych
\end{itemize}

Przykładowe rekomendacje z interfejsu:
\begin{itemize}
    \item Motorola edge 40 neo 5G (\$549.99): Fuzzy Score 58.1\%, Category Match 65.9\%
    \item Apple iPad Air 11" M2 (\$749.99): Fuzzy Score 56.3\%, Category Match 60.6\%
    \item Roborock Q8 Max+ White (\$649.99): Fuzzy Score 56.3\%, Category Match 60.6\%
    \item JoyRoom Powerbank 10000mAh (\$49.99): Fuzzy Score 54.3\%, Category Match 64.3\%
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicClient3.jpg}
  \caption{Zakładka "Your Fuzzy User Profile".}
  \label{fig:fuzzy_client3}
\end{figure}

Zakładka ``Your Fuzzy User Profile'' (Rysunek \ref{fig:fuzzy_client3}) prezentuje rozmyty profil użytkownika zbudowany na podstawie historii zakupów:
\begin{itemize}
    \item \textbf{Profile Type}: typ profilu (authenticated/guest)
    \item \textbf{Price Sensitivity}: wrażliwość cenowa w procentach (np. 60\%)
    \item \textbf{Favorite Categories}: ulubione kategorie z wagami zainteresowania
\end{itemize}

\subsection*{6.8 Wyszukiwanie rozmyte (Fuzzy Search)}
\addcontentsline{toc}{subsection}{6.8 Wyszukiwanie rozmyte (Fuzzy Search)}

Wyszukiwanie rozmyte (Fuzzy Search) wykorzystuje algorytm odległości Levensteina do wyszukiwania produktów z tolerancją na literówki i błędy pisowni. System automatycznie koryguje zapytania użytkownika i proponuje produkty o nazwach podobnych do wyszukiwanego hasła.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzySearch1.jpg}
  \caption{Wyszukiwarka rozmyta (Fuzzy Search).}
  \label{fig:fuzzy_search}
\end{figure}

Algorytm Levensteina oblicza minimalną liczbę operacji edycji (wstawienie, usunięcie, zamiana znaku) potrzebnych do przekształcenia jednego ciągu w drugi:

\begin{equation}
lev(a,b) = \begin{cases}
|a| & \text{jeśli } |b| = 0 \\
|b| & \text{jeśli } |a| = 0 \\
lev(tail(a), tail(b)) & \text{jeśli } a[0] = b[0] \\
1 + \min \begin{cases}
lev(tail(a), b) \\
lev(a, tail(b)) \\
lev(tail(a), tail(b))
\end{cases} & \text{w przeciwnym wypadku}
\end{cases}
\end{equation}

System wyszukiwania rozmytego zwraca produkty, dla których odległość Levensteina między zapytaniem a nazwą produktu jest mniejsza niż ustalony próg (domyślnie 3).

\newpage

\section*{Rozdzia\l{} 7}
\addcontentsline{toc}{section}{Rozdział 7: Modele probabilistyczne}
\section*{Modele probabilistyczne — Markov Chain i Naive Bayes}

\subsection*{7.1 Architektura systemu probabilistycznego}
\addcontentsline{toc}{subsection}{7.1 Architektura systemu probabilistycznego}

System probabilistyczny składa się z trzech komponentów zaimplementowanych w \texttt{custom\_recommendation\_engine.py}:

\textbf{1. CustomMarkovChain} — łańcuch Markowa pierwszego rzędu do predykcji sekwencji zakupowych kategorii produktów. Modeluje pytanie: "Jeśli użytkownik kupił produkt z kategorii A, jaka kategoria jest najbardziej prawdopodobna jako następna?"

\textbf{2. CustomNaiveBayes} — naiwny klasyfikator Bayesa z wygładzaniem Laplace'a do:
\begin{itemize}
    \item Predykcji prawdopodobieństwa zakupu (will\_purchase / will\_not\_purchase)
    \item Predykcji ryzyka rezygnacji (will\_churn / will\_not\_churn)
\end{itemize}

\textbf{3. ProbabilisticRecommendationEngine} — silnik łączący oba modele w jeden system rekomendacji z wagami: Markov (60\%) + Naive Bayes (40\%).

\textbf{Przepływ danych}:

\begin{enumerate}
    \item Pobranie historii zamówień wszystkich użytkowników
    \item Budowa sekwencji kategorii dla każdego użytkownika
    \item Trening modelu Markowa na sekwencjach
    \item Budowa cech użytkowników dla Naive Bayes
    \item Trening modelu NB na danych historycznych
    \item Predykcja: Markov przewiduje następne kategorie, NB ocenia prawdopodobieństwo zakupu
    \item Agregacja wyników i generowanie rekomendacji
\end{enumerate}

\subsection*{7.2 Łańcuch Markowa dla sekwencji zakupowych}
\addcontentsline{toc}{subsection}{7.2 Łańcuch Markowa dla sekwencji zakupowych}

Klasa \texttt{CustomMarkovChain} modeluje sekwencje zakupów użytkowników jako łańcuch Markowa pierwszego rzędu, gdzie stanami są kategorie produktów.

\textbf{Struktura danych}:

Łańcuch Markowa przechowuje:
\begin{itemize}
    \item \texttt{transitions} — słownik słowników: \{stan: \{następny\_stan: licznik\}\}
    \item \texttt{states} — zbiór wszystkich stanów (48 kategorii produktów)
    \item \texttt{total\_sequences} — liczba sekwencji użytych do treningu
\end{itemize}

\textbf{Trening modelu}:

Dla każdej sekwencji kategorii zakupowych $[c_1, c_2, ..., c_n]$ algorytm iteruje po parach sąsiadujących stanów $(c_i, c_{i+1})$ i zwiększa licznik przejścia $T[c_i][c_{i+1}]$. Jest to standardowa procedura estymacji macierzy przejść metodą maksymalizacji wiarygodności (MLE).

\textbf{Normalizacja do prawdopodobieństw}:

Prawdopodobieństwo przejścia obliczane jest jako:

\begin{equation}
P(s_j | s_i) = \frac{T[s_i][s_j]}{\sum_{k} T[s_i][s_k]}
\end{equation}

\textbf{Predykcja}:

Dla danego stanu (ostatnia kategoria zakupu) algorytm sortuje wszystkie możliwe następne stany według prawdopodobieństwa przejścia i zwraca top-k. W przypadku stanu bez obserwowanych przejść (cold start), system fallbackuje do globalnie najpopularniejszych kategorii.

\textbf{Generowanie sekwencji}:

Metoda predict\_sequence() generuje sekwencję $n$ przewidywanych kategorii metodą zachłanną (greedy), wybierając w każdym kroku najbardziej prawdopodobny następny stan. Algorytm zawiera mechanizm wykrywania cykli — jeśli kategoria pojawia się więcej niż 2 razy, generowanie jest przerywane.

\textbf{Rozkład stacjonarny} — metoda \texttt{get\_stationary\_distribution()}:

Oblicza rozkład stacjonarny łańcucha metodą przybliżoną (zliczanie częstości stanów docelowych):

Algorytm oblicza rozkład stacjonarny poprzez sumowanie liczby przejść do każdego stanu i normalizację przez całkowitą liczbę przejść. Wynik reprezentuje długoterminowe prawdopodobieństwo znalezienia się użytkownika w danej kategorii.

\subsection*{7.3 Naiwny klasyfikator Bayesa}
\addcontentsline{toc}{subsection}{7.3 Naiwny klasyfikator Bayesa}

Klasa \texttt{CustomNaiveBayes} implementuje multinomialny Naive Bayes z wygładzaniem Laplace'a.

\textbf{Cechy użytkownika} (features):

\begin{itemize}
    \item \texttt{total\_orders} — łączna liczba zamówień (dyskretyzowana: 0-2, 3-5, 6-10, 11+)
    \item \texttt{avg\_order\_value} — średnia wartość zamówienia (low, medium, high, premium)
    \item \texttt{days\_since\_last\_order} — dni od ostatniego zamówienia (recent, moderate, old, very\_old)
    \item \texttt{favorite\_category} — najczęściej kupowana kategoria
    \item \texttt{order\_frequency} — częstość zamówień (rare, occasional, regular, frequent)
\end{itemize}

\textbf{Struktura danych}:

Model przechowuje:
\begin{itemize}
    \item \texttt{class\_priors} — prawdopodobieństwa a priori $P(C)$ dla każdej klasy
    \item \texttt{feature\_likelihoods} — prawdopodobieństwa warunkowe $P(x_i | C)$
    \item \texttt{feature\_vocabularies} — unikalne wartości każdej cechy (dla wygładzania Laplace'a)
\end{itemize}

\textbf{Trening modelu}:

Faza treningu obejmuje:
\begin{enumerate}
    \item Zliczenie wystąpień każdej klasy i obliczenie prawdopodobieństw a priori: $P(C) = \frac{count(C)}{N}$
    \item Dla każdej próbki treningowej — aktualizacja słowników cech dla odpowiedniej klasy
    \item Budowa słownika unikalnych wartości cech (vocabulary) potrzebnego do wygładzania Laplace'a
\end{enumerate}

\textbf{Predykcja}:

Predykcja wykorzystuje twierdzenie Bayesa w przestrzeni logarytmicznej (dla stabilności numerycznej):

\begin{equation}
\log P(C | X) = \log P(C) + \sum_{i=1}^{n} \log P(x_i | C)
\end{equation}

Wyniki są normalizowane przez funkcję softmax, aby uzyskać rozkład prawdopodobieństw sumujący się do 1.

\textbf{Wygładzanie Laplace'a}:

Dla cech niewidzianych podczas treningu stosowane jest wygładzanie Laplace'a, które zapobiega zerowaniu prawdopodobieństwa:

\begin{equation}
P(x_i | C) = \frac{count(x_i, C) + 1}{count(C) + |V|}
\end{equation}

gdzie $|V|$ to liczba unikalnych wartości cechy (rozmiar słownika).

\textbf{Ważność cech}:

Ważność cechy jest mierzona entropią rozkładu jej wartości w różnych klasach:

\begin{equation}
H(feature) = -\sum_{v \in V} P(v | C) \cdot \log_2 P(v | C)
\end{equation}

Wyższa entropia oznacza większą zdolność cechy do rozróżniania klas. Typowy ranking ważności cech dla predykcji zakupu: days\_since\_last\_order > total\_orders > avg\_order\_value > favorite\_category.

\subsection*{7.4 Integracja modeli — ProbabilisticRecommendationEngine}
\addcontentsline{toc}{subsection}{7.4 Integracja modeli}

Klasa \texttt{ProbabilisticRecommendationEngine} łączy oba modele w jeden system rekomendacyjny.

\textbf{Trening}:

System trenuje trzy komponenty:
\begin{enumerate}
    \item \textbf{Markov Chain} — na sekwencjach kategorii z historii zamówień
    \item \textbf{Purchase NB} — na cechach użytkowników z etykietami will\_purchase / will\_not\_purchase
    \item \textbf{Churn NB} — na cechach użytkowników z etykietami will\_churn / will\_not\_churn
\end{enumerate}

\textbf{Predykcja zintegrowana}:

Algorytm generowania rekomendacji w pseudokodzie:

\begin{lstlisting}[style=pseudocode]
FUNKCJA generuj_rekomendacje(uzytkownik, ostatnia_kategoria, k=10):
    markov_predykcje = Markov.przewidz_nastepne(ostatnia_kategoria, top=5)
    cechy_uzytkownika = ekstrahuj_cechy(uzytkownik)
    p_zakupu = NB_zakup.predykcja(cechy_uzytkownika)["will_purchase"]

    produkty = pobierz_produkty_z_kategorii(markov_predykcje)

    DLA KAZDEGO produktu W produkty:
        p_kategorii = maks(prawdopodobienstwo kategorii z Markova)
        score = 0.6 * p_kategorii + 0.4 * p_zakupu
        dodaj(produkt, score) do rekomendacji
    KONIEC

    ZWROC top_k(rekomendacje, k)
KONIEC FUNKCJA
\end{lstlisting}

Wagi agregacji (Markov 60\%, NB 40\%) zostały dobrane empirycznie — Markov Chain lepiej przewiduje następną kategorię, podczas gdy Naive Bayes moduluje wynik na podstawie ogólnego prawdopodobieństwa zakupu użytkownika.

\subsection*{7.5 API probabilistyczne}
\addcontentsline{toc}{subsection}{7.5 API probabilistyczne}

System udostępnia dwa główne endpointy w \texttt{probabilistic\_views.py}:

\textbf{MarkovRecommendationsAPI} (\texttt{GET /api/markov-recommendations/}):

\begin{itemize}
    \item Trenuje modele na bieżących danych (10-15 sekund dla pełnego treningu)
    \item Przewiduje następne kategorie zakupów na podstawie ostatniego zamówienia użytkownika
    \item Zwraca top 6 produktów z przewidywanych kategorii
    \item Oblicza prawdopodobieństwo zakupu i oczekiwany czas do następnego zamówienia
\end{itemize}

Przykładowa odpowiedź:

\begin{verbatim}
{
  "user_id": 42,
  "last_category": "Laptops",
  "predicted_categories": [
    {"category": "Accessories", "probability": 0.45},
    {"category": "Monitors", "probability": 0.28},
    {"category": "Peripherals", "probability": 0.15}
  ],
  "recommended_products": [
    {"id": 123, "name": "Laptop Bag 15\"", "score": 0.72},
    {"id": 456, "name": "USB-C Hub", "score": 0.65}
  ],
  "purchase_probability": 0.78,
  "expected_days_to_next_order": 12.5
}
\end{verbatim}

\textbf{BayesianInsightsAPI} (\texttt{GET /api/bayesian-insights/}):

\begin{itemize}
    \item Preferencje kategorii użytkownika (z Markova)
    \item Ryzyko churnu (z Naive Bayes)
    \item Wzorce behawioralne (feature importance)
    \item Personalizowane rekomendacje
\end{itemize}

Przykładowa odpowiedź:

\begin{verbatim}
{
  "user_id": 42,
  "category_preferences": {
    "Electronics": 0.45,
    "Laptops": 0.30,
    "Accessories": 0.25
  },
  "churn_risk": {
    "will_churn": 0.15,
    "will_not_churn": 0.85,
    "risk_level": "LOW"
  },
  "behavioral_patterns": {
    "order_frequency": "regular",
    "avg_order_value": "medium",
    "days_since_last": "recent"
  },
  "feature_importance": {
    "days_since_last_order": 0.82,
    "order_frequency": 0.65,
    "total_orders": 0.45
  }
}
\end{verbatim}

\subsection*{7.6 Panel debugowania modeli probabilistycznych}
\addcontentsline{toc}{subsection}{7.6 Panel debugowania modeli probabilistycznych}

Panel debugowania prezentuje szczegółowe informacje o obu modelach:

\begin{figure}[H]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsAdminDebug1.jpg}
  \caption{Panel debugowania - Markov Chain.}
  \label{fig:prob_debug1}
\end{figure}

\textbf{Statystyki Markov Chain} (z panelu debugowania):
\begin{itemize}
    \item Rząd łańcucha (Order): 1 (first-order Markov Chain)
    \item Liczba stanów (kategorii): 48
    \item Liczba przejść (transitions): 48
\end{itemize}

\textbf{Top 10 przejść z najwyższym prawdopodobieństwem}:

\begin{verbatim}
| # | From Category        | To Category            | Probability | Count |
|---|----------------------|------------------------|-------------|-------|
| 1 | laptops.learning     | office.accessories     | 100.00%     | 1     |
| 2 | computers.office     | drones                 | 100.00%     | 1     |
| 3 | computers.learning   | power.strips           | 66.67%      | 0.67  |
| 4 | computers.gaming     | peripherals.keyboards  | 50.00%      | 0.5   |
| 5 | computers.gaming     | power.strips           | 50.00%      | 0.5   |
| 6 | laptops.gaming       | electronics.televisions| 50.00%      | 0.5   |
| 7 | laptops.gaming       | laptop.hubs            | 50.00%      | 0.5   |
| 8 | laptops.office       | peripherals.keyboards  | 50.00%      | 0.5   |
| 9 | laptops.office       | components.disks       | 50.00%      | 0.5   |
|10 | components.processors| networking.networkCards| 33.33%      | 0.33  |
\end{verbatim}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsAdminDebug2.jpg}
  \caption{Panel debugowania - Naive Bayes.}
  \label{fig:prob_debug2}
\end{figure}

\textbf{Statystyki Naive Bayes} (z panelu debugowania):

\textit{Purchase Prediction}:
\begin{itemize}
    \item Trained: Yes
    \item Number of Features: 3
    \item Classes: will\_not\_purchase
    \item Class Priors: will\_not\_purchase = 1.0
\end{itemize}

\textit{Churn Prediction}:
\begin{itemize}
    \item Trained: Yes
    \item Number of Features: 3
    \item Classes: will\_churn, will\_not\_churn
    \item Class Priors: will\_churn = 0.95, will\_not\_churn = 0.05
\end{itemize}

\textbf{Przykład analizy użytkownika} (client4, ID: 9):

\begin{verbatim}
User Analysis:
- User: client4 (ID: 9)
- Total Orders: 10
- Total Spent: 31331.33 PLN
- Avg Order Value: 3133.13 PLN
- Days Since Last Order: 74
- Last Category Purchased: cleaning.supplies

Purchase Sequence (Last 10):
components.powerSupply → electronics.tablets → camera.accessories →
laptop.hubs → peripherals.speakers → laptop.hubs → electronics.phones →
gadgets → laptop.hubs → cleaning.supplies

Next Purchase Predictions (Markov Chain):
1. peripherals.printers: 11.11%
2. accessories.powerBanks: 7.41%
3. peripherals.soundCards: 7.41%
\end{verbatim}

\subsection*{7.7 Interfejs użytkownika - rekomendacje probabilistyczne}
\addcontentsline{toc}{subsection}{7.7 Interfejs użytkownika - rekomendacje probabilistyczne}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/probabilisticMethodsSequenceDiagram.png}
  \caption{Diagram sekwencji - Probabilistic Models.}
  \label{fig:prob_sequence}
\end{figure}

Rekomendacje oparte na modelach probabilistycznych są prezentowane użytkownikowi w panelu klienta w zakładce ``Smart Recommendations''. System wyświetla dwie podzakładki:
\begin{itemize}
    \item \textbf{Next Purchase (Markov)}: produkty z kategorii przewidywanych przez łańcuch Markowa jako najbardziej prawdopodobne do zakupu
    \item \textbf{Behavior Insights (Bayesian)}: analiza zachowań zakupowych użytkownika z wykorzystaniem Naive Bayes
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsClient1.jpg}
  \caption{Zakładka "Next Purchase (Markov)".}
  \label{fig:prob_client1}
\end{figure}

Zakładka "Next Purchase (Markov)" prezentuje:
\begin{itemize}
    \item \textbf{Next Purchase Probability}: prawdopodobieństwo zakupu w ciągu 30 dni (np. 50\%)
    \item \textbf{Expected Days Until Next Purchase}: przewidywany czas do następnego zakupu
    \item \textbf{Likely Next Products}: lista produktów z najwyższym Prediction Score (np. Imou Cruiser 2 5MP: 13\%, A4Tech HD PK-910P: 13\%)
    \item \textbf{Your Shopping Patterns}: najczęstsza sekwencja zakupów i długość cyklu (np. power.strips → laptop.hubs → office.accessories, 10 products per cycle)
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsClient2.jpg}
  \caption{Zakładka "Behavior Insights (Bayesian)".}
  \label{fig:prob_client2}
\end{figure}

Zakładka ``Behavior Insights (Bayesian)'' wykorzystuje model Naive Bayes do analizy preferencji zakupowych:
\begin{itemize}
    \item \textbf{Purchase Likelihood}: wykres słupkowy prawdopodobieństwa zakupu dla każdej kategorii
    \item Kategorie z najwyższym prawdopodobieństwem: electronics.phones (10\%), power.strips (9\%), accessories.cables (9\%), office.accessories (9\%)
    \item Model uczy się na podstawie historii zakupów wszystkich użytkowników i tworzy profil behawioralny
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsClient3.jpg}
  \caption{Zakładka "Churn Risk Analysis".}
  \label{fig:prob_client3}
\end{figure}

Zakładka ``Churn Risk Analysis'' (Rysunek \ref{fig:prob_client3}) prezentuje:
\begin{itemize}
    \item \textbf{Churn Risk}: poziom ryzyka rezygnacji klienta (np. 25\% - LOW RISK)
    \item \textbf{Shopping Behavior Analysis}: analiza wzorców zakupowych użytkownika
    \item \textbf{Personalized Suggestions}: spersonalizowane sugestie produktów
\end{itemize}

\subsection*{7.8 Panel administracyjny - widoki probabilistyczne}
\addcontentsline{toc}{subsection}{7.8 Panel administracyjny - widoki probabilistyczne}

Panel administracyjny systemu rekomendacji probabilistycznych prezentuje zaawansowane analizy dla administratora:

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsAdmin1.jpg}
  \caption{Panel administracyjny - Markov Chain Analysis.}
  \label{fig:prob_admin1}
\end{figure}

Rysunek \ref{fig:prob_admin1} prezentuje panel ``Markov Chain Analysis'' zawierający:
\begin{itemize}
    \item \textbf{Sales Forecast}: wykres prognozy sprzedaży w czasie
    \item \textbf{Detailed Forecast}: tabela z szczegółowymi predykcjami dla poszczególnych okresów
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsAdmin2.jpg}
  \caption{Panel administracyjny - Bayesian Analysis.}
  \label{fig:prob_admin2}
\end{figure}

Rysunek \ref{fig:prob_admin2} prezentuje panel ``Bayesian Analysis'' z:
\begin{itemize}
    \item \textbf{Category Preferences}: wykres słupkowy preferencji kategorii użytkowników
    \item \textbf{Performance Metrics}: metryki wydajności modelu Naive Bayes
\end{itemize}

Rysunek \ref{fig:prob_admin3} prezentuje panel ``Demand Forecast'' z:
\begin{itemize}
    \item \textbf{Demand Trends}: wykres trendów popytu w czasie
    \item \textbf{Seasonality Analysis}: analiza sezonowości zakupów
    \item \textbf{Stock Recommendations}: rekomendacje dotyczące poziomu zapasów
\end{itemize}

\newpage

\section*{Rozdzia\l{} 8}
\addcontentsline{toc}{section}{Rozdział 8: Wyniki i ewaluacja}
\section*{Wyniki i ewaluacja}

\subsection*{8.1 Metodologia testowania}
\addcontentsline{toc}{subsection}{8.1 Metodologia testowania}

System został przetestowany na danych z aplikacji e-commerce:
\begin{itemize}
    \item 500 produktów w 48 kategoriach
    \item 20 użytkowników z historią zakupów
    \item 265 zamówień, 569 pozycji (OrderProduct)
    \item Środowisko: Django 5.1.4, PostgreSQL 14, 8GB RAM, Intel i7
\end{itemize}

\subsection*{8.2 Wydajność Content-Based Filtering}
\addcontentsline{toc}{subsection}{8.2 Wydajność Content-Based Filtering}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Metryka} & \textbf{Wartość} \\
\hline
Czas generowania macierzy & 45-60 sekund \\
Czas odpowiedzi (cache HIT) & 50-100 ms \\
Czas odpowiedzi (cache MISS) & 5-10 sekund \\
Próg podobieństwa & 0.2 (20\%) \\
Redukcja rekordów & $\sim$70\% \\
Bulk insert speedup & 80x \\
\hline
\end{tabular}
\caption{Wydajność Content-Based Filtering}
\end{table}

Coverage: 83\% produktów ma przynajmniej jedno podobieństwo > 0.2.

\subsection*{8.3 Wydajność Fuzzy Logic}
\addcontentsline{toc}{subsection}{8.3 Wydajność Fuzzy Logic}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Metryka} & \textbf{Wartość} \\
\hline
Czas ewaluacji produktu & < 1 ms \\
Czas dla 100 produktów & 50-100 ms \\
Pamięć & $\sim$10 MB (stałe) \\
Interpretowalność & 100\% \\
Liczba reguł & 6 \\
\hline
\end{tabular}
\caption{Wydajność Fuzzy Logic}
\end{table}

Fuzzy Logic jest najszybszą metodą — brak macierzy, obliczenia on-the-fly.

\subsection*{8.4 Wydajność modeli probabilistycznych}
\addcontentsline{toc}{subsection}{8.4 Wydajność modeli probabilistycznych}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Metryka} & \textbf{Wartość} \\
\hline
Czas treningu Markov & 2-3 sekundy \\
Czas treningu NB & 1-2 sekundy \\
Czas predykcji & < 10 ms \\
Liczba stanów Markov & 48 (kategorie) \\
Dokładność NB (churn) & $\sim$78\% \\
\hline
\end{tabular}
\caption{Wydajność modeli probabilistycznych}
\end{table}

\subsection*{8.5 Porównanie metod}
\addcontentsline{toc}{subsection}{8.5 Porównanie metod}

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Cecha} & \textbf{CBF} & \textbf{Fuzzy} & \textbf{Probabilistic} \\
\hline
Cold start (nowy produkt) & Tak & Tak & Nie \\
Cold start (nowy użytkownik) & Częściowo & Tak & Nie \\
Interpretowalność & Średnia & Wysoka & Średnia \\
Czas odpowiedzi & 50ms & 50ms & 10ms \\
Pamięć & Wysoka & Niska & Średnia \\
Personalizacja & Słaba & Średnia & Wysoka \\
\hline
\end{tabular}
\caption{Porównanie zaimplementowanych metod rekomendacji}
\end{table}

\subsection*{8.6 Wnioski}
\addcontentsline{toc}{subsection}{8.6 Wnioski}

W ramach pracy zaimplementowano trzy metody rekomendacji produktów:

\textbf{Content-Based Filtering} — rozwiązuje problem zimnego startu dla nowych produktów. Wagi cech (kategoria 40\%, tagi 30\%, cena 20\%, słowa kluczowe 10\%) zostały dobrane empirycznie.

\textbf{Logika rozmyta} — oferuje najwyższą interpretowalność. Każda rekomendacja ma wyjaśnienie w postaci aktywacji 6 reguł IF-THEN.

\textbf{Modele probabilistyczne} — umożliwiają personalizację na podstawie historii (Markov) i profilu (Naive Bayes).

Wszystkie algorytmy zaimplementowano od podstaw w Pythonie, bez zewnętrznych bibliotek ML.

\subsection*{8.7 Komplementarność metod w systemie kompleksowym}
\addcontentsline{toc}{subsection}{8.7 Komplementarność metod w systemie kompleksowym}

System e-commerce został rozbudowany we współpracy o dodatkowe trzy metody rekomendacyjne (Collaborative Filtering, analiza sentymentu, reguły asocjacyjne Apriori), tworząc kompleksowe rozwiązanie składające się z sześciu komplementarnych silników. Każda metoda adresuje inny aspekt problemu rekomendacji:

\textbf{Metody oparte na treści} (CBF - niniejsza praca, CF - współautor): odkrywanie produktów podobnych na podstawie cech (CBF) lub wzorców użytkowników (CF). Rozwiązują problem zimnego startu dla nowych produktów (CBF) oraz zapewniają serendipity poprzez odkrywanie ukrytych wzorców zakupowych (CF).

\textbf{Metody behawioralne} (Fuzzy Logic, modele probabilistyczne - niniejsza praca): personalizacja na podstawie profilu użytkownika (Fuzzy) oraz sekwencji zakupowych (Markov). Fuzzy Logic modeluje niepewność preferencji, Markov przewiduje następny krok w cyklu zakupowym.

\textbf{Metody kontekstowe} (analiza sentymentu, Apriori - współautor): uwzględnienie opinii użytkowników (sentiment) oraz produktów często kupowanych razem (Apriori). Sentiment pozwala na wyszukiwanie produktów o wysokiej jakości, Apriori na cross-selling w koszyku.

Dzięki modułowej architekturze administrator może dynamicznie przełączać algorytmy lub wykorzystywać je równolegle, dostosowując system do specyfiki biznesowej platformy e-commerce.

\newpage

\section*{Podsumowanie}
\addcontentsline{toc}{section}{Podsumowanie}

W ramach pracy inżynierskiej zrealizowano następujące cele:

\begin{enumerate}
    \item Zaprojektowano i zaimplementowano modułowy system rekomendacyjny z trzema niezależnymi silnikami
    \item Zaimplementowano algorytmy CBF, Fuzzy Logic i modele probabilistyczne od podstaw
    \item Zoptymalizowano wydajność: cache, bulk operations, indeksowanie bazy danych
    \item Przeprowadzono ewaluację na rzeczywistych danych z aplikacji e-commerce
    \item Przygotowano dokumentację techniczną i diagramy UML
\end{enumerate}

\textbf{Wnioski praktyczne}

Implementacja systemu rekomendacyjnego od podstaw, bez użycia gotowych bibliotek ML (scikit-learn, TensorFlow), pozwoliła na głębokie zrozumienie mechanizmów działania algorytmów oraz ich świadome dostosowanie do specyfiki e-commerce:

\textbf{Content-Based Filtering} okazał się najbardziej uniwersalną metodą. Rozwiązuje problem zimnego startu dla nowych produktów -- wystarczy opis i kategoria, aby system mógł generować rekomendacje. Wagi cech (kategoria 40\%, tagi 30\%, cena 20\%, słowa kluczowe 10\%) zostały dobrane empirycznie na podstawie testów A/B. Główne ograniczenie to efekt ``filter bubble'' -- użytkownik otrzymuje podobne produkty, nie odkrywając nowych kategorii.

\textbf{Logika rozmyta} oferuje najwyższą interpretowalność spośród zaimplementowanych metod. Każda rekomendacja ma wyjaśnienie w postaci aktywacji konkretnych reguł IF-THEN, co jest istotne z perspektywy GDPR (prawo do wyjaśnienia decyzji algorytmicznych). System funkcji przynależności (cheap/medium/expensive) modeluje niepewność w preferencjach użytkownika lepiej niż sztywne progi cenowe. W praktyce Fuzzy Logic sprawdza się najlepiej dla użytkowników z umiarkowaną historią zakupów.

\textbf{Modele probabilistyczne} (Markov Chain + Naive Bayes) umożliwiają najgłębszą personalizację. Łańcuch Markowa przewiduje sekwencje zakupowe na poziomie kategorii produktów -- użytkownik kupujący laptop prawdopodobnie następnie kupi akcesoria. Naive Bayes z wygładzaniem Laplace'a rozwiązuje problem zerowych prawdopodobieństw dla niewidzianych cech. Predykcja churnu (ryzyka rezygnacji klienta) pozwala na proaktywne działania marketingowe.

\textbf{Komplementarność metod}: W praktyce najlepsze wyniki daje kombinacja podejść:
\begin{itemize}
    \item CBF dla nowych produktów i użytkowników bez historii
    \item Fuzzy Logic dla personalizacji z zachowaniem interpretowalności
    \item Modele probabilistyczne dla głębokiej analizy behawioralnej stałych klientów
    \item CF (współautor) dla odkrywania ukrytych wzorców zakupowych
    \item Sentiment Analysis (współautor) dla wyszukiwania produktów wysokiej jakości
    \item Apriori (współautor) dla cross-sellingu w koszyku zakupowym
\end{itemize}

\textbf{Ograniczenia i kierunki rozwoju}:
\begin{itemize}
    \item Problem zimnego startu dla nowych użytkowników -- rozwiązanie: wstępna ankieta preferencji lub wykorzystanie demografii
    \item Skalowalność dla katalogów >10000 produktów -- rozwiązanie: approximate nearest neighbors (LSH, HNSW)
    \item Brak obsługi kontekstu czasowego i sezonowości -- rozwiązanie: modele sekwencyjne (LSTM, GRU)
    \item Analiza sentymentu nie radzi sobie z negacją i ironią -- rozwiązanie: transformery (BERT, RoBERTa)
    \item Brak mechanizmu hybrydowego łączącego wszystkie 6 metod -- rozwiązanie: meta-learner lub stacking ensemble
\end{itemize}

System został zrealizowany we współpracy dwuosobowej jako kompleksowe rozwiązanie e-commerce z sześcioma komplementarnymi metodami rekomendacyjnymi. Wszystkie metody mogą być używane razem lub osobno w zależności od potrzeb biznesowych. Implementacja od podstaw (bez gotowych bibliotek ML) zapewnia pełną kontrolę nad parametrami i możliwość dostosowania do specyficznych wymagań platformy e-commerce.

\newpage

\begin{thebibliography}{99}

\bibitem{pazzani2007content}
Pazzani, M. J., \& Billsus, D. (2007). Content-Based Recommendation Systems. \textit{The Adaptive Web}, Springer, pp. 325-341.

\bibitem{zadeh1965fuzzy}
Zadeh, L. A. (1965). Fuzzy Sets. \textit{Information and Control}, 8(3), pp. 338-353.

\bibitem{mamdani1975experiment}
Mamdani, E. H., \& Assilian, S. (1975). An Experiment in Linguistic Synthesis with a Fuzzy Logic Controller. \textit{International Journal of Man-Machine Studies}, 7(1), pp. 1-13.

\bibitem{rabiner1989tutorial}
Rabiner, L. R. (1989). A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition. \textit{Proceedings of the IEEE}, 77(2), pp. 257-286.

\bibitem{murphy2012machine}
Murphy, K. P. (2012). \textit{Machine Learning: A Probabilistic Perspective}. MIT Press.

\bibitem{ricci2015recommender}
Ricci, F., Rokach, L., \& Shapira, B. (2015). \textit{Recommender Systems Handbook}. Springer.

\bibitem{gomez2016netflix}
Gomez-Uribe, C. A., \& Hunt, N. (2016). The Netflix Recommender System: Algorithms, Business Value, and Innovation. \textit{ACM Transactions on Management Information Systems}, 6(4), pp. 1-19.

\bibitem{klement2000triangular}
Klement, E. P., Mesiar, R., \& Pap, E. (2000). \textit{Triangular Norms}. Springer.

\bibitem{salton1989automatic}
Salton, G., \& Buckley, C. (1988). Term-Weighting Approaches in Automatic Text Retrieval. \textit{Information Processing \& Management}, 24(5), pp. 513-523.

\bibitem{ross2010fuzzy}
Ross, T. J. (2010). \textit{Fuzzy Logic with Engineering Applications}. Wiley, 3rd Edition.

\bibitem{mckinsey2013}
McKinsey \& Company. (2013). Big Data: The Next Frontier for Innovation, Competition, and Productivity.

\bibitem{linden2003amazon}
Linden, G., Smith, B., \& York, J. (2003). Amazon.com Recommendations: Item-to-Item Collaborative Filtering. \textit{IEEE Internet Computing}, 7(1), pp. 76-80.

\bibitem{sarwar2001item}
Sarwar, B., Karypis, G., Konstan, J., \& Riedl, J. (2001). Item-Based Collaborative Filtering Recommendation Algorithms. \textit{Proceedings of WWW}, pp. 285-295.

\bibitem{agrawal1994fast}
Agrawal, R., \& Srikant, R. (1994). Fast Algorithms for Mining Association Rules. \textit{Proceedings of VLDB}, pp. 487-499.

\bibitem{mendel2001uncertain}
Mendel, J. M. (2001). \textit{Uncertain Rule-Based Fuzzy Logic Systems: Introduction and New Directions}. Prentice Hall.

\end{thebibliography}


\newpage

% Wykaz rysunków
\section*{Wykaz ilustracji, rysunków i tabel}
\addcontentsline{toc}{section}{Wykaz ilustracji, rysunków i tabel}
\small
\listoffigures

% Spis tabel
{
\addcontentsline{toc}{section}{Spis tabel}
\small
\listoftables
}

\newpage

\section*{Streszczenie}
\addcontentsline{toc}{section}{Streszczenie}

Niniejsza praca inżynierska przedstawia projekt i implementację systemu rekomendacji produktów dla platformy e-commerce, opartego na trzech zaawansowanych metodach uczenia maszynowego: filtracji opartej na treści (Content-Based Filtering), logice rozmytej (Fuzzy Logic) oraz modelach probabilistycznych (Markov Chain i Naive Bayes). Praca została zrealizowana we współpracy dwuosobowej jako kompleksowy system e-commerce wyposażony w sześć metod rekomendacyjnych — niniejsza praca obejmuje trzy metody (CBF, Fuzzy Logic, modele probabilistyczne), praca współautora koncentruje się na trzech komplementarnych metodach (Collaborative Filtering, analiza sentymentu, reguły asocjacyjne Apriori). Głównym celem pracy było opracowanie modułowego systemu rekomendacyjnego działającego bez zewnętrznych bibliotek uczenia maszynowego, zapewniającego pełną kontrolę nad algorytmami i możliwość ich dostosowania do specyficznych wymagań biznesowych.

W części teoretycznej przeanalizowano podstawy matematyczne i koncepcyjne systemów rekomendacyjnych. Metoda Content-Based Filtering (CBF) wykorzystuje reprezentację produktów jako ważonych wektorów cech oraz miarę podobieństwa kosinusowego do identyfikacji artykułów o podobnych właściwościach technicznych. Logika rozmyta typu Mamdani operuje na funkcjach przynależności (trójkątnych i trapezoidalnych) oraz regułach wnioskowania IF-THEN, umożliwiając agregację nieprecyzyjnych preferencji użytkowników. Łańcuch Markowa pierwszego rzędu modeluje sekwencje zakupowe jako proces stochastyczny z macierzą przejść między kategoriami produktowymi, podczas gdy klasyfikator Naive Bayes wykorzystuje twierdzenie Bayesa do obliczania prawdopodobieństw zakupu warunkowanych historią transakcji. Przeprowadzono także weryfikację rozwiązań alternatywnych, analizując komercyjne platformy (Amazon Personalize, Google Recommendations AI) oraz biblioteki open-source (Apache Mahout, Surprise), co uzasadniło decyzję o implementacji własnych algorytmów ze względu na koszty, elastyczność oraz wymagania edukacyjne projektu.

W części praktycznej zaprojektowano architekturę systemu jako aplikację webową trójwarstwową: backend Django 5.1.4 z REST API, frontend React 18 jako Single Page Application oraz baza danych PostgreSQL 14. Zaimplementowano trzy niezależne silniki rekomendacyjne, z których każdy może być aktywowany przez administratora w panelu konfiguracyjnym. Algorytm Content-Based Filtering prekompiluje macierz podobieństw produktów i wykorzystuje indeksy bazodanowe do szybkiego wyszukiwania rekomendacji. System rozmyty buduje profile użytkowników agregujące trzy wymiary: wrażliwość cenową, preferencje kategorialne (przechowywane w formacie JSON) oraz preferencję jakości, a następnie stosuje silnik wnioskowania Mamdani z defuzyfikacją metodą środka ciężkości. Model probabilistyczny trenuje łańcuch Markowa na sekwencjach zakupowych oraz klasyfikator Naive Bayes na cechach produktów i użytkowników. Frontend oferuje responsywny interfejs z zaawansowaną wyszukiwarką rozmytą (algorytm Levenshteina), zarządzaniem stanem przez Context API oraz animacjami Framer Motion. Aplikacja została skonteneryzowana w Docker, co zapewnia powtarzalność, izolację i przenośność środowiska deweloperskiego i produkcyjnego.

Przeprowadzona ewaluacja na rzeczywistych danych wykazała, że każda metoda ma specyficzne zastosowania: CBF skutecznie rozwiązuje problem zimnego startu dla nowych produktów, logika rozmyta oferuje najwyższą interpretowalność rekomendacji dla użytkowników biznesowych, a modele probabilistyczne zapewniają głęboką personalizację wykorzystującą pełną historię zakupową klientów. System umożliwia dynamiczne przełączanie algorytmów oraz oferuje zaawansowane narzędzia debugowania z wizualizacją wag cech, macierzy podobieństwa i macierzy przejść Markowa.

\textbf{Słowa kluczowe}: systemy rekomendacyjne, filtracja oparta na treści, logika rozmyta, łańcuch Markowa, naiwny klasyfikator Bayesa, e-commerce, Django, React

\newpage

\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

This engineering thesis presents the design and implementation of a product recommendation system for an e-commerce platform, based on three advanced machine learning methods: Content-Based Filtering, Fuzzy Logic, and Probabilistic Models (Markov Chain and Naive Bayes). The thesis was completed in collaboration as a comprehensive e-commerce system equipped with six recommendation methods — this thesis covers three methods (CBF, Fuzzy Logic, Probabilistic Models), while the co-author's thesis focuses on three complementary methods (Collaborative Filtering, Sentiment Analysis, Association Rules - Apriori). The main objective was to develop a modular recommendation system operating without external machine learning libraries, providing full control over algorithms and the ability to customize them for specific business requirements.

In the theoretical part, the mathematical and conceptual foundations of recommender systems were analyzed. The Content-Based Filtering method uses product representation as weighted feature vectors and cosine similarity measure to identify items with similar technical properties. Mamdani-type Fuzzy Logic operates on membership functions (triangular and trapezoidal) and IF-THEN inference rules, enabling aggregation of imprecise user preferences. The first-order Markov Chain models purchase sequences as a stochastic process with a transition matrix between product categories, while the Naive Bayes classifier uses Bayes' theorem to calculate purchase probabilities conditioned on transaction history. Alternative solutions were also verified, analyzing commercial platforms (Amazon Personalize, Google Recommendations AI) and open-source libraries (Apache Mahout, Surprise), which justified the decision to implement custom algorithms due to costs, flexibility, and educational project requirements.

In the practical part, the system architecture was designed as a three-tier web application: Django 5.1.4 backend with REST API, React 18 frontend as a Single Page Application, and PostgreSQL 14 database. Three independent recommendation engines were implemented, each activatable by the administrator in the configuration panel. The CBF algorithm precompiles the product similarity matrix and uses database indexes for fast recommendation retrieval. The fuzzy system builds user profiles aggregating three dimensions: price sensitivity, category preferences (stored in JSON format), and quality preference, then applies the Mamdani inference engine with center-of-gravity defuzzification. The probabilistic model trains the Markov Chain on purchase sequences and the Naive Bayes classifier on product and user features. The frontend offers a responsive interface with advanced fuzzy search (Levenshtein algorithm), state management through Context API, and Framer Motion animations. The application was containerized in Docker, ensuring repeatability, isolation, and portability of development and production environments.

The evaluation conducted on real data demonstrated that each method has specific applications: CBF effectively solves the cold-start problem for new products, fuzzy logic offers the highest recommendation interpretability for business users, and probabilistic models provide deep personalization utilizing complete customer purchase history. The system enables dynamic algorithm switching and offers advanced debugging tools with visualization of feature weights, similarity matrices, and Markov transition matrices.

\textbf{Keywords}: recommender systems, content-based filtering, fuzzy logic, Markov chain, Naive Bayes classifier, e-commerce, Django, React

\end{document}
