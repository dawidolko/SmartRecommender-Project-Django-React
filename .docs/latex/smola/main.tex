% filepath: /SmartRecommender-Project-Django-React/.docs/latex/smola/main.tex

\documentclass[a4paper,12pt,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amsmath, amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage{url}
\usepackage{titlesec}
\usepackage{tocloft}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{placeins}
\usepackage{float}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}

% Marginesy zgodnie z wytycznymi
\geometry{left=3.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% Numeracja stron u dołu, wyrównana do zewnętrznego marginesu
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[LE,RO]{\thepage}
\renewcommand{\headrulewidth}{0pt}

% Interlinia 1,5
\onehalfspacing

% Wcięcia akapitów
\setlength{\parindent}{1cm}

% Zapobieganie dużym odstępom pionowym - strony nie muszą być wyrównane do dołu
\raggedbottom

% Tytuły - czcionka pogrubiona
\titleformat{\section}[block]{\bfseries\Large\raggedright}{}{1em}{}
\titleformat{\subsection}[block]{\bfseries\large\raggedright}{}{1em}{}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red}
}

% Styl dla pseudokodu
\lstdefinelanguage{Pseudocode}{
  morekeywords={FUNKCJA, ZWROC, DLA, KAZDEGO, W, JEZELI, WTEDY, INACZEJ, KONIEC, LUB, I, NIE, DOPOKI, WYKONUJ, ORAZ, ZWRACA, GDZIE, OD, DO, KROK},
  sensitive=false,
  morecomment=[l]{//},
  morestring=[b]"
}

\lstdefinestyle{pseudocode}{
  language=Pseudocode,
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries\color{blue},
  commentstyle=\color{gray},
  frame=single,
  numbers=left,
  numberstyle=\tiny,
  breaklines=true,
  xleftmargin=2em,
  framexleftmargin=1.5em,
  literate={ą}{{\k{a}}}1 {ć}{{\'c}}1 {ę}{{\k{e}}}1 {ł}{{\l{}}}1 {ń}{{\'n}}1 {ó}{{\'o}}1 {ś}{{\'s}}1 {ź}{{\'z}}1 {ż}{{\.z}}1
           {Ą}{{\k{A}}}1 {Ć}{{\'C}}1 {Ę}{{\k{E}}}1 {Ł}{{\L{}}}1 {Ń}{{\'N}}1 {Ó}{{\'O}}1 {Ś}{{\'S}}1 {Ź}{{\'Z}}1 {Ż}{{\.Z}}1
}

\begin{document}

\begin{titlepage}

\begin{minipage}{0.7\textwidth}
    {\large\bf UNIWERSYTET RZESZOWSKI}\\
    {\large\bf Wydział Nauk Ścisłych i Technicznych}
\end{minipage}
\hfill
\begin{minipage}{0.25\textwidth}
    \centering
    \includegraphics[width=8em]{images/UR.png}
\end{minipage}


\vspace{3cm}

\begin{center}
    {\Large Piotr Smoła} \\
    {\large nr albumu: 125162} \\
    {\large Kierunek: Informatyka}
\end{center}

\vspace{2cm}

\begin{center}
    {\LARGE\bf System rekomendacji produktów oparty na filtracji treści, logice rozmytej i modelach probabilistycznych}
\end{center}

\vspace{1.5cm}

\begin{center}
    {\large Praca inżynierska}
\end{center}

\vspace{1.5cm}

\begin{flushright}
    {\large Praca wykonana pod kierunkiem}\\
    {\large dr inż. Piotra Grochowalskiego}
\end{flushright}

\vspace{3cm}

\begin{center}
    {\large Rzesz\'ow, 2026}
\end{center}

\end{titlepage}

\section*{Streszczenie}
\addcontentsline{toc}{section}{Streszczenie}

Niniejsza praca inżynierska przedstawia projekt i implementację systemu rekomendacji produktów dla platformy e-commerce, opartego na trzech zaawansowanych metodach uczenia maszynowego: filtracji opartej na treści (Content-Based Filtering), logice rozmytej (Fuzzy Logic) oraz modelach probabilistycznych (Markov Chain i Naive Bayes). Głównym celem pracy było opracowanie modułowego systemu rekomendacyjnego działającego bez zewnętrznych bibliotek uczenia maszynowego, zapewniającego pełną kontrolę nad algorytmami i możliwość ich dostosowania do specyficznych wymagań biznesowych.

W części teoretycznej przeanalizowano podstawy matematyczne i koncepcyjne systemów rekomendacyjnych. Metoda Content-Based Filtering wykorzystuje reprezentację produktów jako ważonych wektorów cech oraz miarę podobieństwa kosinusowego do identyfikacji artykułów o podobnych właściwościach technicznych. Logika rozmyta typu Mamdani operuje na funkcjach przynależności (trójkątnych i trapezoidalnych) oraz regułach wnioskowania IF-THEN, umożliwiając agregację nieprecyzyjnych preferencji użytkowników. Łańcuch Markowa pierwszego rzędu modeluje sekwencje zakupowe jako proces stochastyczny z macierzą przejść między kategoriami produktowymi, podczas gdy klasyfikator Naive Bayes wykorzystuje twierdzenie Bayesa do obliczania prawdopodobieństw zakupu warunkowanych historią transakcji. Przeprowadzono także weryfikację rozwiązań alternatywnych, analizując komercyjne platformy (Amazon Personalize, Google Recommendations AI) oraz biblioteki open-source (Apache Mahout, Surprise), co uzasadniło decyzję o implementacji własnych algorytmów ze względu na koszty, elastyczność oraz wymagania edukacyjne projektu.

W części praktycznej zaprojektowano architekturę systemu jako aplikację webową trójwarstwową: backend Django 4.2 z REST API, frontend React 18 jako Single Page Application oraz baza danych PostgreSQL 14. Zaimplementowano trzy niezależne silniki rekomendacyjne, z których każdy może być aktywowany przez administratora w panelu konfiguracyjnym. Algorytm Content-Based Filtering (CBF) prekompiluje macierz podobieństw produktów i wykorzystuje indeksy bazodanowe do szybkiego wyszukiwania rekomendacji. System rozmyty buduje profile użytkowników agregujące trzy wymiary: wrażliwość cenową, preferencje kategorialne (przechowywane w formacie JSON) oraz preferencję jakości, a następnie stosuje silnik wnioskowania Mamdani z defuzyfikacją metodą środka ciężkości. Model probabilistyczny trenuje łańcuch Markowa na sekwencjach zakupowych oraz klasyfikator Naive Bayes na cechach produktów i użytkowników. Frontend oferuje responsywny interfejs z zaawansowaną wyszukiwarką rozmytą (algorytm Levenshteina), zarządzaniem stanem przez Context API oraz animacjami Framer Motion. Aplikacja została skonteneryzowana w Docker, co zapewnia powtarzalność, izolację i przenośność środowiska deweloperskiego i produkcyjnego.

Przeprowadzona ewaluacja na rzeczywistych danych wykazała, że każda metoda ma specyficzne zastosowania: CBF skutecznie rozwiązuje problem zimnego startu dla nowych produktów, logika rozmyta oferuje najwyższą interpretowalność rekomendacji dla użytkowników biznesowych, a modele probabilistyczne zapewniają głęboką personalizację wykorzystującą pełną historię zakupową klientów. System umożliwia dynamiczne przełączanie algorytmów oraz oferuje zaawansowane narzędzia debugowania z wizualizacją wag cech, macierzy podobieństwa i macierzy przejść Markowa.

\textbf{Słowa kluczowe}: systemy rekomendacyjne, filtracja oparta na treści, logika rozmyta, łańcuch Markowa, naiwny klasyfikator Bayesa, e-commerce, Django, React

\newpage

\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

This engineering thesis presents the design and implementation of a product recommendation system for an e-commerce platform, based on three advanced machine learning methods: Content-Based Filtering, Fuzzy Logic, and Probabilistic Models (Markov Chain and Naive Bayes). The main objective was to develop a modular recommendation system operating without external machine learning libraries, providing full control over algorithms and the ability to customize them for specific business requirements.

In the theoretical part, the mathematical and conceptual foundations of recommender systems were analyzed. The Content-Based Filtering method uses product representation as weighted feature vectors and cosine similarity measure to identify items with similar technical properties. Mamdani-type Fuzzy Logic operates on membership functions (triangular and trapezoidal) and IF-THEN inference rules, enabling aggregation of imprecise user preferences. The first-order Markov Chain models purchase sequences as a stochastic process with a transition matrix between product categories, while the Naive Bayes classifier uses Bayes' theorem to calculate purchase probabilities conditioned on transaction history. Alternative solutions were also verified, analyzing commercial platforms (Amazon Personalize, Google Recommendations AI) and open-source libraries (Apache Mahout, Surprise), which justified the decision to implement custom algorithms due to costs, flexibility, and educational project requirements.

In the practical part, the system architecture was designed as a three-tier web application: Django 4.2 backend with REST API, React 18 frontend as a Single Page Application, and PostgreSQL 14 database. Three independent recommendation engines were implemented, each activatable by the administrator in the configuration panel. The CBF algorithm precompiles the product similarity matrix and uses database indexes for fast recommendation retrieval. The fuzzy system builds user profiles aggregating three dimensions: price sensitivity, category preferences (stored in JSON format), and quality preference, then applies the Mamdani inference engine with center-of-gravity defuzzification. The probabilistic model trains the Markov Chain on purchase sequences and the Naive Bayes classifier on product and user features. The frontend offers a responsive interface with advanced fuzzy search (Levenshtein algorithm), state management through Context API, and Framer Motion animations. The application was containerized in Docker, ensuring repeatability, isolation, and portability of development and production environments.

The evaluation conducted on real data demonstrated that each method has specific applications: CBF effectively solves the cold-start problem for new products, fuzzy logic offers the highest recommendation interpretability for business users, and probabilistic models provide deep personalization utilizing complete customer purchase history. The system enables dynamic algorithm switching and offers advanced debugging tools with visualization of feature weights, similarity matrices, and Markov transition matrices.

\textbf{Keywords}: recommender systems, content-based filtering, fuzzy logic, Markov chain, Naive Bayes classifier, e-commerce, Django, React

\newpage

% Spis treści
\tableofcontents
\newpage


\section*{Wstęp}
\addcontentsline{toc}{section}{Wstęp}

Współczesne platformy e-commerce oferują dziesiątki tysięcy produktów, co prowadzi do problemu przeładowania informacją. Użytkownik poszukujący konkretnego produktu musi przeszukać setki ofert, często rezygnując z zakupu z powodu trudności w podjęciu decyzji. Systemy rekomendacyjne rozwiązują ten problem poprzez automatyczne dopasowanie produktów do preferencji i potrzeb klienta, zwiększając jednocześnie konwersję i wartość sprzedaży \cite{ricci2015recommender}.

\subsection*{Motywacja i kontekst problemu}
\addcontentsline{toc}{subsection}{Motywacja i kontekst problemu}

Problem rekomendacji w platformach e-commerce jest złożony i wieloaspektowy. Preferencje użytkowników są subiektywne i trudne do modelowania matematycznego. Dane o użytkownikach są często niekompletne lub niedostępne, zwłaszcza dla nowych użytkowników i produktów - zjawisko znane jako problem zimnego startu (cold start problem). Katalogi produktów dynamicznie się zmieniają, co wymaga ciągłej aktualizacji modeli rekomendacyjnych. Dodatkowo, użytkownicy oczekują nie tylko trafnych rekomendacji, ale również ich wyjaśnienia - dlaczego dany produkt został zaproponowany.

Istniejące rozwiązania komercyjne (Amazon Personalize, Google Recommendations AI) oferują zaawansowane mechanizmy rekomendacji, jednak działają jako czarne skrzynki (black-box), nie pozwalając na kontrolę nad algorytmami ani ich dostosowanie do specyficznych wymagań biznesowych. Biblioteki open-source (Apache Mahout, Surprise) rozwiązują problem kosztów, ale nie oferują implementacji logiki rozmytej ani zaawansowanych modeli probabilistycznych w jednym spójnym systemie.

Niniejsza praca odpowiada na powyższe wyzwania poprzez zaprojektowanie i implementację modułowego systemu rekomendacyjnego łączącego trzy komplementarne podejścia: filtrację opartą na treści (Content-Based Filtering, CBF), logikę rozmytą (Fuzzy Logic) oraz modele probabilistyczne (łańcuchy Markowa i naiwny klasyfikator Bayesa). Każda z tych metod rozwiązuje inne aspekty problemu rekomendacji i oferuje unikalne możliwości personalizacji. System został zaimplementowany od podstaw, bez wykorzystania zewnętrznych bibliotek uczenia maszynowego, co zapewnia pełną kontrolę nad algorytmami oraz możliwość ich dostosowania do specyficznych wymagań platformy e-commerce.

\subsection*{Cel i zakres pracy}
\addcontentsline{toc}{subsection}{Cel i zakres pracy}

Głównym celem pracy jest zaprojektowanie i implementacja systemu rekomendacji produktów dla platformy e-commerce, który łączy trzy zaawansowane metody uczenia maszynowego. System został zbudowany od podstaw, bez wykorzystania gotowych bibliotek uczenia maszynowego, co zapewniło pełną kontrolę nad algorytmami i możliwość ich dostosowania do specyficznych wymagań biznesowych.

W ramach realizacji celu głównego zdefiniowano następujące cele szczegółowe:

\begin{itemize}
    \item Zaprojektowanie architektury modułowego systemu rekomendacyjnego z trzema niezależnymi silnikami
    \item Implementacja algorytmu filtracji opartej na treści (Content-Based Filtering) z wykorzystaniem ważonych wektorów cech i miary podobieństwa kosinusowego
    \item Opracowanie systemu wnioskowania rozmytego typu Mamdani z regułami IF-THEN i funkcjami przynależności
    \item Zbudowanie modeli probabilistycznych: łańcucha Markowa pierwszego rzędu oraz naiwnego klasyfikatora Bayesa
    \item Optymalizacja wydajności systemu dla wdrożenia produkcyjnego
    \item Przeprowadzenie ewaluacji jakości rekomendacji na rzeczywistych danych
\end{itemize}

Zakres pracy obejmuje trzy główne obszary: podstawy teoretyczne metod rekomendacyjnych, projekt i implementację systemu oraz ewaluację jego działania. System został zintegrowany z aplikacją webową e-commerce, umożliwiającą weryfikację wszystkich zaimplementowanych algorytmów w warunkach zbliżonych do rzeczywistych.

Praca koncentruje się na aspektach algorytmicznych i jakościowych systemów rekomendacji, z uwzględnieniem problemu zimnego startu, interpretowalności wyników oraz personalizacji doświadczenia użytkownika. Każda z trzech metod rozwiązuje inne wyzwania: Content-Based Filtering umożliwia rekomendacje dla nowych produktów, logika rozmyta oferuje przejrzystość decyzji algorytmu, a modele probabilistyczne przewidują zachowania zakupowe na podstawie historii transakcji.


\subsection*{Struktura pracy}

Praca składa się z siedmiu rozdziałów. Rozdział pierwszy przedstawia podstawy teoretyczne metod rekomendacyjnych. Rozdział drugi zawiera przegląd i analizę istniejących rozwiązań w obszarze systemów rekomendacyjnych. Rozdział trzeci opisuje projekt systemu z wykorzystaniem diagramów UML. Rozdział czwarty przedstawia wykorzystany stos technologiczny i architekturę aplikacji. Rozdział piąty opisuje implementację algorytmów rekomendacyjnych. Rozdział szósty dokumentuje funkcjonowanie systemu. Rozdział siódmy zawiera wyniki eksperymentów i analizę jakości rekomendacji. Pracę zamyka podsumowanie oraz wykaz wykorzystanej literatury.

\newpage

\section*{Rozdzia\l{} 1}
\addcontentsline{toc}{section}{Rozdział 1: Teoretyczne podstawy metod rekomendacyjnych}
\section*{Teoretyczne podstawy metod rekomendacyjnych}

\subsection*{1.1 Content-Based Filtering — podstawy teoretyczne}
\addcontentsline{toc}{subsection}{1.1 Content-Based Filtering — podstawy teoretyczne}

Content-Based Filtering (CBF, filtracja oparta na treści) jest jedną z fundamentalnych metod systemów rekomendacyjnych. W przeciwieństwie do Collaborative Filtering, CBF analizuje cechy samych produktów, a nie wzorce zachowań użytkowników. Metoda została szczegółowo opisana w literaturze \cite{pazzani2007content}.

\textbf{Zasada działania}: System buduje profil cech każdego produktu (wektor cech) i oblicza podobieństwo między produktami na podstawie ich cech. Użytkownikowi rekomendowane są produkty podobne do tych, które wcześniej przeglądał lub kupił.

\textbf{Reprezentacja produktu jako wektora cech}

Każdy produkt $p$ jest reprezentowany jako wektor w wielowymiarowej przestrzeni cech:

\begin{equation}
\vec{p} = (f_1, f_2, ..., f_n)
\end{equation}

gdzie $f_i$ to waga cechy $i$ (np. należenie do kategorii, posiadanie tagu, przedział cenowy). W ogólnym przypadku stosuje się wagi różnicujące znaczenie poszczególnych cech:

\begin{equation}
\vec{p} = \sum_{i} w_i \cdot f_i(p)
\end{equation}

gdzie $w_i$ to waga cechy $i$, a $f_i(p)$ to wartość cechy dla produktu $p$. Funkcja indykatorowa $\mathbf{1}_{feature}(p)$ przyjmuje wartość 1 jeśli produkt posiada daną cechę, 0 w przeciwnym razie.

\textbf{Zalety CBF}:
\begin{itemize}
    \item Brak problemu zimnego startu dla nowych produktów — wystarczy opis i cechy
    \item Przejrzystość rekomendacji — można wyjaśnić dlaczego produkt został polecony ("podobna kategoria", "podobne tagi")
    \item Niezależność od innych użytkowników — działa nawet dla pierwszego klienta w systemie
    \item Szybka aktualizacja — dodanie nowego produktu nie wymaga przeliczenia całej macierzy
\end{itemize}

\textbf{Wady CBF}:
\begin{itemize}
    \item Problem "filter bubble" — rekomenduje tylko podobne produkty, użytkownik nie odkrywa nowych kategorii
    \item Wymaga dobrze opisanych cech produktów — jakość rekomendacji zależy od jakości metadanych
    \item Nie odkrywa nieoczywistych powiązań między produktami (np. "użytkownicy kupujący kawę często kupują cukier")
    \item Ograniczenie do podobieństwa cech — nie uwzględnia kontekstu użytkownika
\end{itemize}

\textbf{Podobieństwo kosinusowe} (Cosine Similarity) jest standardową metryką w CBF \cite{salton1989automatic}. Dla dwóch wektorów $\vec{A}$ i $\vec{B}$:

\begin{equation}
\text{cos}(\theta) = \frac{\vec{A} \cdot \vec{B}}{||\vec{A}|| \times ||\vec{B}||} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \times \sqrt{\sum_{i=1}^{n} B_i^2}}
\end{equation}

gdzie $\vec{A}$ i $\vec{B}$ to wektory cech dwóch produktów. Wynik mieści się w przedziale $[0, 1]$ dla nieujemnych wektorów (w kontekście TF-IDF i wag binarnych).

\textbf{Interpretacja podobieństwa kosinusowego}:
\begin{itemize}
    \item $cos(\theta) = 1$ — wektory identyczne (produkty mają te same cechy)
    \item $cos(\theta) = 0$ — wektory ortogonalne (brak wspólnych cech)
    \item $cos(\theta) \in (0, 1)$ — częściowe podobieństwo
\end{itemize}

\textbf{TF-IDF (Term Frequency - Inverse Document Frequency)}

W kontekście ekstrakcji słów kluczowych z opisów tekstowych stosuje się miarę TF-IDF (Term Frequency - Inverse Document Frequency) \cite{salton1989automatic}:

\begin{equation}
TF(t, d) = \frac{count(t, d)}{|d|}
\end{equation}

gdzie $count(t, d)$ to liczba wystąpień terminu $t$ w dokumencie $d$, a $|d|$ to długość dokumentu (liczba słów).

Pełna wersja TF-IDF uwzględnia rzadkość terminu w całym korpusie:

\begin{equation}
TF\text{-}IDF(t, d, D) = TF(t, d) \times IDF(t, D)
\end{equation}

gdzie $IDF(t, D) = \log\frac{|D|}{|\{d \in D : t \in d\}|}$ to odwrócona częstość dokumentowa, penalizująca terminy występujące w wielu dokumentach.

\subsection*{1.2 Logika rozmyta — podstawy teoretyczne}
\addcontentsline{toc}{subsection}{1.2 Logika rozmyta — podstawy teoretyczne}

Logika rozmyta (Fuzzy Logic) została wprowadzona przez Lotfi Zadeha w przełomowej pracy \cite{zadeh1965fuzzy}. Rozszerza klasyczną logikę dwuwartościową (prawda/fałsz) o stopnie przynależności w przedziale $[0, 1]$.

\textbf{Motywacja}: Klasyczna logika wymaga precyzyjnych granic. Pytanie "Czy produkt za 450 PLN jest tani?" nie ma jednoznacznej odpowiedzi — zależy od kontekstu, kategorii produktu i preferencji użytkownika. Logika rozmyta pozwala odpowiedzieć: "Produkt jest tani ze stopniem 0.3 i średnio drogi ze stopniem 0.7".

\textbf{Zbiory rozmyte} (Fuzzy Sets): W klasycznej teorii zbiorów element należy lub nie należy do zbioru. W zbiorach rozmytych element ma stopień przynależności $\mu(x) \in [0, 1]$. Formalnie, zbiór rozmyty $A$ na uniwersum $X$ jest zdefiniowany przez funkcję przynależności:

\begin{equation}
\mu_A : X \rightarrow [0, 1]
\end{equation}

gdzie $\mu_A(x)$ oznacza stopień przynależności elementu $x$ do zbioru $A$.

\textbf{Przykład}: Dla zmiennej "cena" możemy zdefiniować trzy zbiory rozmyte:
\begin{itemize}
    \item \textbf{cheap}: ceny niskie (pełna przynależność dla cen < 100 PLN)
    \item \textbf{medium}: ceny średnie (pełna przynależność dla cen 500-1200 PLN)
    \item \textbf{expensive}: ceny wysokie (pełna przynależność dla cen > 2000 PLN)
\end{itemize}

Produkt za 350 PLN może mieć: $\mu_{cheap}(350) = 0.3$, $\mu_{medium}(350) = 0.5$, $\mu_{expensive}(350) = 0.0$.

\textbf{Funkcje przynależności} (Membership Functions) definiują stopień przynależności elementu do zbioru rozmytego. Najczęściej stosowane typy:

\textit{Funkcja trójkątna} (Triangular MF):
\begin{equation}
\mu_{triangle}(x; a, b, c) = \max\left(0, \min\left(\frac{x-a}{b-a}, \frac{c-x}{c-b}\right)\right)
\end{equation}

gdzie $a$ to dolna granica, $b$ to punkt maksymalny ($\mu=1$), $c$ to górna granica.

\textit{Funkcja trapezoidalna} (Trapezoidal MF):
\begin{equation}
\mu_{trapezoid}(x; a, b, c, d) = \max\left(0, \min\left(\frac{x-a}{b-a}, 1, \frac{d-x}{d-c}\right)\right)
\end{equation}

gdzie przedział $[b, c]$ ma pełną przynależność ($\mu=1$), a $[a, b)$ i $(c, d]$ to obszary przejściowe.

\textit{Funkcja gaussowska} (Gaussian MF):
\begin{equation}
\mu_{gaussian}(x; c, \sigma) = e^{-\frac{(x-c)^2}{2\sigma^2}}
\end{equation}

gdzie $c$ to środek (mean), a $\sigma$ to odchylenie standardowe kontrolujące szerokość.

\textbf{Operacje na zbiorach rozmytych}

\textit{Uzupełnienie} (Negacja):
\begin{equation}
\mu_{\bar{A}}(x) = 1 - \mu_A(x)
\end{equation}

\textit{Przecięcie} (AND) — T-norma:
\begin{equation}
\mu_{A \cap B}(x) = T(\mu_A(x), \mu_B(x))
\end{equation}

Najczęściej używane T-normy:
\begin{itemize}
    \item Minimum (Gödel): $T_{min}(a, b) = \min(a, b)$
    \item Iloczyn algebraiczny: $T_{prod}(a, b) = a \cdot b$
    \item Łukasiewicz: $T_L(a, b) = \max(0, a + b - 1)$
\end{itemize}

\textit{Suma} (OR) — T-conorma (S-norma):
\begin{equation}
\mu_{A \cup B}(x) = S(\mu_A(x), \mu_B(x))
\end{equation}

Najczęściej używane T-conormy:
\begin{itemize}
    \item Maksimum: $S_{max}(a, b) = \max(a, b)$
    \item Suma algebraiczna: $S_{sum}(a, b) = a + b - a \cdot b$
    \item Łukasiewicz: $S_L(a, b) = \min(1, a + b)$
\end{itemize}

\textbf{System wnioskowania Mamdani} \cite{mamdani1975experiment} jest najbardziej rozpowszechnioną metodą wnioskowania rozmytego. Składa się z czterech etapów:

\begin{enumerate}
    \item \textbf{Fuzzyfikacja} — przekształcenie wartości wejściowych na stopnie przynależności do zbiorów rozmytych. Przykład: cena 450 PLN → $\mu_{cheap}=0.1$, $\mu_{medium}=0.6$, $\mu_{expensive}=0.0$.

    \item \textbf{Ewaluacja reguł} — obliczenie aktywacji reguł IF-THEN za pomocą T-norm. Dla reguły "IF price IS cheap AND quality IS high THEN recommendation IS strong":
    \begin{equation}
    \alpha = T(\mu_{cheap}(price), \mu_{high}(quality)) = \min(\mu_{cheap}, \mu_{high})
    \end{equation}

    \item \textbf{Agregacja} — połączenie wyników wszystkich reguł za pomocą T-conormy. Jeśli wiele reguł prowadzi do tego samego konsekwentu:
    \begin{equation}
    \mu_{output} = S(\alpha_1, \alpha_2, ..., \alpha_n) = \max(\alpha_1, \alpha_2, ..., \alpha_n)
    \end{equation}

    \item \textbf{Defuzzyfikacja} — przekształcenie wyniku rozmytego na wartość liczbową.
\end{enumerate}

\textbf{Metody defuzzyfikacji}:

\textit{Centroid} (środek ciężkości):
\begin{equation}
y^* = \frac{\int y \cdot \mu(y) dy}{\int \mu(y) dy}
\end{equation}

\textit{Średnia ważona} (Weighted Average) — uproszczona metoda używana w implementacji:
\begin{equation}
y^* = \frac{\sum_{i=1}^{n} \alpha_i \cdot w_i}{\sum_{i=1}^{n} w_i}
\end{equation}

gdzie $\alpha_i$ to aktywacja reguły $i$, a $w_i$ to waga reguły.

\textit{Mean of Maximum} (MoM):
\begin{equation}
y^* = \frac{1}{|M|} \sum_{y \in M} y, \quad M = \{y : \mu(y) = \max_z \mu(z)\}
\end{equation}

\textbf{Reguły rozmyte IF-THEN}

Reguła rozmyta ma postać \cite{ross2010fuzzy}:
\begin{equation}
\text{IF } x_1 \text{ IS } A_1 \text{ AND } x_2 \text{ IS } A_2 \text{ THEN } y \text{ IS } B
\end{equation}

gdzie $A_1$, $A_2$, $B$ to zbiory rozmyte definiujące warunki i konsekwencje reguły. Operator AND realizowany jest przez T-normę, najczęściej minimum lub iloczyn algebraiczny.

\subsection*{1.3 Modele probabilistyczne — podstawy teoretyczne}
\addcontentsline{toc}{subsection}{1.3 Modele probabilistyczne — podstawy teoretyczne}

\textbf{Łańcuchy Markowa} (Markov Chains) zostały wprowadzone przez Andrieja Markowa w 1906 roku. Są procesami stochastycznymi spełniającymi własność Markowa — przyszły stan zależy tylko od stanu obecnego, nie od historii \cite{rabiner1989tutorial}.

\textit{Definicja formalna}: Łańcuch Markowa to ciąg zmiennych losowych $X_0, X_1, X_2, ...$ przyjmujących wartości ze zbioru stanów $S = \{s_1, s_2, ..., s_n\}$, spełniający własność Markowa:

\begin{equation}
P(X_{t+1} = s_{j} | X_t = s_i, X_{t-1} = s_{i-1}, ..., X_0 = s_0) = P(X_{t+1} = s_j | X_t = s_i)
\end{equation}

Oznacza to, że prawdopodobieństwo przejścia do stanu $s_j$ zależy tylko od obecnego stanu $s_i$, nie od tego jak do niego dotarliśmy.

\textit{Macierz przejść} (Transition Matrix) $P$ zawiera prawdopodobieństwa przejść między stanami:

\begin{equation}
P_{ij} = P(X_{t+1} = s_j | X_t = s_i)
\end{equation}

Macierz $P$ spełnia warunki:
\begin{itemize}
    \item $P_{ij} \geq 0$ dla wszystkich $i, j$
    \item $\sum_j P_{ij} = 1$ dla wszystkich $i$ (wiersze sumują się do 1)
\end{itemize}

\textit{Estymacja prawdopodobieństw przejść} z danych:
\begin{equation}
\hat{P}_{ij} = \frac{count(s_i \rightarrow s_j)}{\sum_k count(s_i \rightarrow s_k)}
\end{equation}

gdzie $count(s_i \rightarrow s_j)$ to liczba obserwowanych przejść ze stanu $s_i$ do stanu $s_j$.

\textit{Rozkład stacjonarny} (Stationary Distribution) $\pi$ spełnia:
\begin{equation}
\pi = \pi P, \quad \sum_i \pi_i = 1
\end{equation}

Jest to rozkład prawdopodobieństwa, który pozostaje niezmieniony po przejściu — reprezentuje długoterminowe prawdopodobieństwa przebywania w każdym stanie. Rozkład stacjonarny jest istotny w analizie długoterminowego zachowania systemu.

\textbf{Naiwny klasyfikator Bayesa} (Naive Bayes, NB) opiera się na twierdzeniu Bayesa z założeniem niezależności cech \cite{murphy2012machine}.

\textit{Twierdzenie Bayesa}:
\begin{equation}
P(C | X) = \frac{P(X | C) \cdot P(C)}{P(X)}
\end{equation}

gdzie:
\begin{itemize}
    \item $P(C | X)$ — prawdopodobieństwo a posteriori klasy $C$ przy cechach $X$
    \item $P(C)$ — prawdopodobieństwo a priori klasy $C$
    \item $P(X | C)$ — wiarygodność (likelihood) — prawdopodobieństwo obserwacji cech $X$ w klasie $C$
    \item $P(X)$ — prawdopodobieństwo marginalne cech (stałe dla wszystkich klas)
\end{itemize}

\textit{Założenie naiwne} (Naive assumption) — niezależność warunkowa cech:
\begin{equation}
P(X | C) = P(x_1, x_2, ..., x_n | C) = \prod_{i=1}^{n} P(x_i | C)
\end{equation}

Założenie to jest "naiwne" bo w rzeczywistości cechy są często skorelowane. Jednak Naive Bayes działa zaskakująco dobrze w praktyce.

\textit{Klasyfikacja}:
\begin{equation}
\hat{C} = \arg\max_C P(C) \prod_{i=1}^{n} P(x_i | C)
\end{equation}

Ponieważ $P(X)$ jest stałe dla wszystkich klas, można je pominąć przy porównywaniu.

\textit{Problem zerowych prawdopodobieństw}: Jeśli cecha $x_i$ nie wystąpiła w klasie $C$ w danych treningowych, to $P(x_i | C) = 0$, co zeruje całe prawdopodobieństwo.

\textbf{Wygładzanie Laplace'a} (Laplace Smoothing / Add-one Smoothing) rozwiązuje ten problem:
\begin{equation}
P(x_i = v | C) = \frac{count(x_i = v, C) + 1}{count(C) + |V_i|}
\end{equation}

gdzie $|V_i|$ to liczba unikalnych wartości cechy $x_i$. Dodanie 1 do licznika i $|V|$ do mianownika zapewnia, że żadne prawdopodobieństwo nie będzie zerowe.

\textit{Logarytm dla stabilności numerycznej}: Iloczyn wielu małych prawdopodobieństw prowadzi do underflow. Rozwiązanie — praca w przestrzeni logarytmów:
\begin{equation}
\log P(C | X) = \log P(C) + \sum_{i=1}^{n} \log P(x_i | C) + const
\end{equation}

\textit{Warianty Naive Bayes}:
\begin{itemize}
    \item \textbf{Multinomial NB} — dla danych zliczeniowych (np. częstość słów)
    \item \textbf{Bernoulli NB} — dla cech binarnych (obecność/brak)
    \item \textbf{Gaussian NB} — dla cech ciągłych (zakłada rozkład normalny)
\end{itemize}

Naive Bayes jest szeroko stosowany w klasyfikacji tekstu, filtracji spamu oraz systemach rekomendacyjnych ze względu na prostotę implementacji i niskie wymagania obliczeniowe.

\subsection*{1.4 Metryki oceny systemów rekomendacyjnych}
\addcontentsline{toc}{subsection}{1.4 Metryki oceny systemów rekomendacyjnych}

Ewaluacja systemów rekomendacyjnych wymaga odpowiednich metryk jakości. Najpopularniejsze:

\textbf{Precision@K} — jaka część top K rekomendacji była faktycznie kupiona/polubiona:
\begin{equation}
Precision@K = \frac{|Recommended@K \cap Relevant|}{K}
\end{equation}

\textbf{Recall@K} — jaka część produktów istotnych dla użytkownika została trafiona:
\begin{equation}
Recall@K = \frac{|Recommended@K \cap Relevant|}{|Relevant|}
\end{equation}

\textbf{F1-Score} — harmoniczna średnia Precision i Recall:
\begin{equation}
F1@K = 2 \cdot \frac{Precision@K \cdot Recall@K}{Precision@K + Recall@K}
\end{equation}

\textbf{Mean Reciprocal Rank (MRR)} — pozycja pierwszego trafienia:
\begin{equation}
MRR = \frac{1}{|U|} \sum_{u \in U} \frac{1}{rank_u}
\end{equation}

gdzie $rank_u$ to pozycja pierwszego istotnego produktu w rankingu dla użytkownika $u$.

\textbf{Coverage} — procent produktów, które system jest w stanie rekomendować:
\begin{equation}
Coverage = \frac{|\text{products with recommendations}|}{|\text{all products}|}
\end{equation}

\newpage

\section*{Rozdzia\l{} 2}
\addcontentsline{toc}{section}{Rozdział 2: Weryfikacja rozwiązań alternatywnych}
\section*{Weryfikacja rozwiązań alternatywnych}

\subsection*{2.1 Przegląd istniejących systemów rekomendacyjnych}
\addcontentsline{toc}{subsection}{2.1 Przegląd istniejących systemów rekomendacyjnych}

Przed przystąpieniem do implementacji własnego rozwiązania przeprowadzono analizę istniejących systemów i bibliotek dedykowanych rekomendacjom produktów. Analiza objęła zarówno komercyjne usługi chmurowe, jak i narzędzia open-source, z uwzględnieniem ich funkcjonalności, kosztów oraz ograniczeń.

\subsection*{2.2 Amazon Personalize}
\addcontentsline{toc}{subsection}{2.2 Amazon Personalize}

Amazon Personalize to w pełni zarządzana usługa uczenia maszynowego oferowana przez Amazon Web Services, dedykowana tworzeniu spersonalizowanych rekomendacji w czasie rzeczywistym. System wykorzysta tę samą technologię, która napędza rekomendacje na platformie Amazon.com.

\textbf{Funkcjonalność}:
\begin{itemize}
    \item Automatyczne dostosowywanie modeli na podstawie danych użytkownika (AutoML)
    \item Obsługa trzech rodzajów rekomendacji: user personalization, similar items, personalized ranking
    \item Real-time personalization z aktualizacją modeli co 2 godziny
    \item Wsparcie dla cold-start poprzez item metadata
    \item Integracja z AWS ekosystemem (S3, CloudWatch, IAM)
\end{itemize}

\textbf{Koszty}: Model cenowy pay-per-use:
\begin{itemize}
    \item Trening modelu: \$0.24 za godzinę treningu
    \item Hosting modelu: \$0.054 za godzinę TPS (Transactions Per Second)
    \item Inference: \$0.0417 za 1000 requestów
    \item Szacowany koszt miesięczny dla małej aplikacji: \$150-300
\end{itemize}

\textbf{Ograniczenia}:
\begin{itemize}
    \item Brak pełnej kontroli nad algorytmami (black-box)
    \item Wymaga minimum 1000 interakcji użytkowników do treningu
    \item Vendor lock-in (uzależnienie od AWS)
    \item Wysokie koszty dla małych projektów edukacyjnych
    \item Brak wsparcia dla custom feature engineering
\end{itemize}

\subsection*{2.3 Google Recommendations AI}
\addcontentsline{toc}{subsection}{2.3 Google Recommendations AI}

Google Recommendations AI (obecnie część Vertex AI) to usługa Google Cloud Platform wykorzystująca modele deep learning do generowania rekomendacji produktów w sklepach e-commerce.

\textbf{Funkcjonalność}:
\begin{itemize}
    \item Modele oparte na deep learning (neural networks)
    \item Cztery typy rekomendacji: others you may like, frequently bought together, recommended for you, recently viewed
    \item Automatyczna optymalizacja modeli na podstawie konwersji
    \item Wsparcie dla A/B testing
    \item Integracja z Google Analytics
\end{itemize}

\textbf{Koszty}:
\begin{itemize}
    \item Model cenowy oparty na liczbie predykcji
    \item \$0.30 za 1000 predykcji (pierwsze 10M/miesiąc)
    \item \$0.15 za 1000 predykcji (następne 90M)
    \item Szacowany koszt miesięczny: \$200-500 dla średniej aplikacji
\end{itemize}

\textbf{Ograniczenia}:
\begin{itemize}
    \item Brak możliwości implementacji własnych algorytmów
    \item Wymaga integracji z Google Cloud Platform
    \item Długi czas wdrożenia (konfiguracja, import danych, trening)
    \item Brak wsparcia dla logiki rozmytej i custom probabilistic models
    \item Nieodpowiednie dla projektów badawczych wymagających kontroli nad algorytmami
\end{itemize}

\subsection*{2.4 Apache Mahout i biblioteki open-source}
\addcontentsline{toc}{subsection}{2.4 Apache Mahout i biblioteki open-source}

Apache Mahout to biblioteka open-source zapewniająca skalowalne implementacje algorytmów uczenia maszynowego, w tym systemów rekomendacyjnych. Alternatywami są biblioteki Surprise (Python) i LensKit (Java).

\textbf{Funkcjonalność Apache Mahout}:
\begin{itemize}
    \item Collaborative Filtering: User-based CF, Item-based CF, Matrix Factorization (SVD, ALS)
    \item Wsparcie dla Apache Spark (przetwarzanie rozproszone)
    \item Możliwość implementacji custom similarity metrics
    \item Integracja z Hadoop dla big data
\end{itemize}

\textbf{Funkcjonalność Surprise (Python)}:
\begin{itemize}
    \item Implementacje SVD, SVD++, NMF, KNN
    \item Built-in dataset loaders i cross-validation
    \item Evaluation metrics (RMSE, MAE, Precision@K)
    \item Brak wsparcia dla content-based filtering
\end{itemize}

\textbf{Koszty}:
\begin{itemize}
    \item Darmowe (licencja Apache 2.0 / BSD)
    \item Koszty infrastruktury (serwery, maintenance)
\end{itemize}

\textbf{Ograniczenia}:
\begin{itemize}
    \item Mahout: stroma krzywa uczenia, wymaga znajomości Spark/Hadoop
    \item Surprise: brak wsparcia dla Fuzzy Logic i Markov Chains
    \item Wszystkie biblioteki: brak implementacji logiki rozmytej
    \item Brak gotowych implementacji hybrydowych systemów (CBF + Fuzzy + Probabilistic)
    \item Ograniczona możliwość edukacyjna (gotowe black-boxy zamiast implementacji od podstaw)
\end{itemize}

\subsection*{2.5 Analiza porównawcza}
\addcontentsline{toc}{subsection}{2.5 Analiza porównawcza}

Tabela \ref{tab:comparison} przedstawia syntetyczne porównanie analizowanych rozwiązań.

\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Kryterium} & \textbf{Amazon} & \textbf{Google} & \textbf{Mahout} & \textbf{Własne} \\
\hline
Koszt miesięczny & \$150-300 & \$200-500 & \$0 & \$0 \\
\hline
Kontrola algorytmów & Niska & Niska & Średnia & Pełna \\
\hline
Fuzzy Logic & Nie & Nie & Nie & Tak \\
\hline
Markov Chains & Nie & Nie & Nie & Tak \\
\hline
Content-Based & Tak & Tak & Nie & Tak \\
\hline
Cold-start & Tak & Tak & Częściowo & Tak \\
\hline
Interpretowalność & Niska & Niska & Średnia & Wysoka \\
\hline
Vendor lock-in & Tak & Tak & Nie & Nie \\
\hline
Cel edukacyjny & Nie & Nie & Częściowo & Tak \\
\hline
\end{tabular}
\caption{Porównanie rozwiązań systemów rekomendacyjnych.}
\label{tab:comparison}
\end{table}

\subsection*{2.6 Uzasadnienie własnej implementacji}
\addcontentsline{toc}{subsection}{2.6 Uzasadnienie własnej implementacji}

Na podstawie przeprowadzonej analizy podjęto decyzję o implementacji własnego systemu rekomendacyjnego od podstaw. Decyzję uzasadniają następujące argumenty:

\textbf{1. Cel edukacyjny}: Praca inżynierska ma charakter badawczy i edukacyjny. Implementacja algorytmów od podstaw zapewnia głębokie zrozumienie mechanizmów działania każdej metody, co jest niemożliwe przy wykorzystaniu gotowych usług chmurowych działających jako black-boxy.

\textbf{2. Pełna kontrola nad algorytmami}: Komercyjne rozwiązania nie oferują możliwości implementacji logiki rozmytej ani custom probabilistic models. Własna implementacja umożliwia eksperymentowanie z wagami cech, regułami rozmytymi i parametrami modeli.

\textbf{3. Brak kosztów operacyjnych}: Usługi Amazon Personalize i Google Recommendations AI generują koszty od \$150 do \$500 miesięcznie, co jest nieuzasadnione dla projektu akademickiego. Własne rozwiązanie działa na lokalnej infrastrukturze bez recurring costs.

\textbf{4. Unikalne połączenie metod}: Żadne z analizowanych rozwiązań nie oferuje kombinacji Content-Based Filtering, Fuzzy Logic i Markov Chains w jednym systemie. Ta hybryda jest innowacyjna i stanowi wartość dodaną pracy.

\textbf{5. Interpretowalność}: Logika rozmyta z regułami IF-THEN oferuje pełną przejrzystość decyzji algorytmu (explainable AI), czego brakuje w modelach deep learning używanych przez Google i Amazon.

\textbf{6. Brak vendor lock-in}: Własne rozwiązanie nie uzależnia projektu od konkretnego dostawcy usług chmurowych, zapewniając pełną niezależność i możliwość wdrożenia na dowolnej platformie.

\textbf{7. Możliwość dostosowania}: System został zaprojektowany modułowo, co umożliwia łatwe dodawanie nowych metod, modyfikację wag i reguł oraz integrację z różnymi źródłami danych.

Podsumowując, własna implementacja stanowi optymalne rozwiązanie dla celów pracy inżynierskiej, łącząc wartość edukacyjną z praktyczną użytecznością systemu. W kolejnych rozdziałach opisano szczegółowy projekt i implementację zaprojektowanego rozwiązania.

\newpage

\section*{Rozdzia\l{} 3}
\addcontentsline{toc}{section}{Rozdział 3: Content-Based Filtering}
\section*{Content-Based Filtering — implementacja}

\subsection*{3.1 Architektura systemu CBF}
\addcontentsline{toc}{subsection}{3.1 Architektura systemu CBF}

System Content-Based Filtering został zaimplementowany w klasie \texttt{CustomContentBasedFilter} w pliku \texttt{custom\_recommendation\_engine.py}. Architektura składa się z trzech głównych komponentów:

\textbf{1. Ekstraktor cech} (Feature Extractor) — odpowiada za budowę ważonego wektora cech dla każdego produktu. Analizuje cztery źródła danych:

\begin{itemize}
    \item \textbf{Kategorie} (waga 40\%) — główna klasyfikacja produktu. Format cechy: \texttt{category\_\{nazwa\}}. Przykład: \texttt{category\_Electronics}, \texttt{category\_Laptops}.
    \item \textbf{Tagi} (waga 30\%) — dodatkowe deskryptory (np. "Gaming", "Premium", "Budget"). Format: \texttt{tag\_\{nazwa\}}.
    \item \textbf{Przedział cenowy} (waga 20\%) — dyskretyzacja ceny: low (<100 PLN), medium (100-500), high (500-1500), premium (>1500).
    \item \textbf{Słowa kluczowe} (waga 10\%) — top 10 słów z opisu produktu po filtracji stop-words.
\end{itemize}

\textbf{2. Kalkulator podobieństwa} — oblicza podobieństwo kosinusowe między wektorami cech produktów. Operuje na wektorach rzadkich dla efektywności.

\textbf{3. Generator rekomendacji} — zwraca top N produktów podobnych do danego produktu, z filtrowaniem według dostępności i progu podobieństwa.

\textbf{Przepływ danych w systemie CBF}:

\begin{enumerate}
    \item Pobranie produktów z bazy z \texttt{prefetch\_related()} dla kategorii i tagów
    \item Ekstrakcja ważonych cech dla każdego produktu
    \item Obliczenie podobieństw dla wszystkich par produktów
    \item Filtracja podobieństw poniżej progu 0.2 (20\%)
    \item Zapis do tabeli \texttt{ProductSimilarity} za pomocą \texttt{bulk\_create()}
    \item Cache wyników na 2 godziny
\end{enumerate}

\subsection*{3.2 Implementacja ekstrakcji cech}
\addcontentsline{toc}{subsection}{3.2 Implementacja ekstrakcji cech}

Metoda ekstrakcji cech buduje słownik cech z przypisanymi wagami. Algorytm w pseudokodzie:

\begin{lstlisting}[style=pseudocode]
FUNKCJA ekstrahuj_cechy(produkt):
    cechy = pusty_slownik

    DLA KAZDEGO kategorii W produkt.kategorie:
        cechy["category_" + kategoria.nazwa] = 0.40

    DLA KAZDEGO tagu W produkt.tagi:
        cechy["tag_" + tag.nazwa] = 0.30

    JEZELI produkt.cena < 100 WTEDY
        cechy["price_low"] = 0.20
    INACZEJ JEZELI produkt.cena < 500 WTEDY
        cechy["price_medium"] = 0.20
    INACZEJ JEZELI produkt.cena < 1500 WTEDY
        cechy["price_high"] = 0.20
    INACZEJ
        cechy["price_premium"] = 0.20
    KONIEC

    slowa_kluczowe = ekstrahuj_slowa_kluczowe(produkt.opis)
    DLA KAZDEGO slowa W slowa_kluczowe[0:5]:
        cechy["keyword_" + slowo] = 0.10 / dlugosc(slowa_kluczowe)

    ZWROC cechy
KONIEC FUNKCJA
\end{lstlisting}

\textbf{Ekstrakcja słów kluczowych}:

Metoda \texttt{\_extract\_keywords()} przetwarza opis produktu:

\begin{enumerate}
    \item Konwersja na małe litery
    \item Usunięcie znaków interpunkcyjnych (regex)
    \item Tokenizacja na słowa
    \item Filtracja stop-words (zdefiniowana lista 200+ słów: "the", "and", "is", "a", "to", ...)
    \item Filtracja słów krótszych niż 4 znaki
    \item Zliczenie częstości (collections.Counter)
    \item Wybór top 10 najczęstszych słów
\end{enumerate}

\textbf{Dyskretyzacja ceny}:

Progi cenowe zostały dobrane empirycznie na podstawie rozkładu cen w katalogu:

\begin{itemize}
    \item \texttt{price\_low}: cena < 100 PLN — akcesoria, kable, drobne peryferia
    \item \texttt{price\_medium}: 100 PLN $\leq$ cena < 500 PLN — peryferia, komponenty
    \item \texttt{price\_high}: 500 PLN $\leq$ cena < 1500 PLN — monitory, karty graficzne
    \item \texttt{price\_premium}: cena $\geq$ 1500 PLN — laptopy, komputery, high-end
\end{itemize}

Dyskretyzacja eliminuje problem dużej wariancji cen i pozwala na porównywanie produktów z różnych kategorii cenowych.

\subsection*{3.3 Algorytm podobieństwa kosinusowego}
\addcontentsline{toc}{subsection}{3.3 Algorytm podobieństwa kosinusowego}

Metoda \texttt{calculate\_product\_similarity()} implementuje podobieństwo kosinusowe dla wektorów rzadkich (sparse vectors):

\begin{equation}
\text{similarity}(p_1, p_2) = \frac{\sum_{f \in F_{1} \cap F_{2}} w_1(f) \cdot w_2(f)}{\sqrt{\sum_{f \in F_1} w_1(f)^2} \cdot \sqrt{\sum_{f \in F_2} w_2(f)^2}}
\end{equation}

gdzie $F_1$, $F_2$ to zbiory cech produktów $p_1$ i $p_2$, $w_i(f)$ to waga cechy $f$ dla produktu $p_i$.

\textbf{Implementacja dla wektorów rzadkich} w pseudokodzie:

\begin{lstlisting}[style=pseudocode]
FUNKCJA oblicz_podobienstwo(cechy1, cechy2):
    wspolne_cechy = przeciecie(klucze(cechy1), klucze(cechy2))
    iloczyn_skalarny = suma(cechy1[f] * cechy2[f] DLA f W wspolne_cechy)

    norma1 = pierwiastek(suma(v^2 DLA v W wartosci(cechy1)))
    norma2 = pierwiastek(suma(v^2 DLA v W wartosci(cechy2)))

    JEZELI norma1 = 0 LUB norma2 = 0 WTEDY
        ZWROC 0.0
    KONIEC

    ZWROC iloczyn_skalarny / (norma1 * norma2)
KONIEC FUNKCJA
\end{lstlisting}

\textbf{Optymalizacja dla wektorów rzadkich}:

Zamiast tworzyć pełne wektory o długości równej liczbie wszystkich możliwych cech (potencjalnie tysiące), algorytm operuje na słownikach. Iloczyn skalarny wymaga iteracji tylko po cechach wspólnych (przecięcie zbiorów kluczy).

\textbf{Próg podobieństwa}:

System zapisuje tylko podobieństwa większe niż 0.2 (20\%). Uzasadnienie:
\begin{itemize}
    \item Podobieństwo < 0.2 oznacza mniej niż 20\% wspólnych cech — produkty są praktycznie różne
    \item Redukcja rozmiaru tabeli o 60-80\%
    \item Szybsze zapytania (mniej rekordów do przeszukania)
\end{itemize}

\subsection*{3.4 Generowanie macierzy podobieństw}
\addcontentsline{toc}{subsection}{3.4 Generowanie macierzy podobieństw}

Metoda \texttt{generate\_similarities\_for\_all\_products()} oblicza podobieństwa dla wszystkich par produktów:

\textbf{Etap 1: Prefetching danych}

Wykorzystujemy mechanizm \texttt{prefetch\_related()} frameworka Django dla kategorii, tagów i specyfikacji, redukując liczbę zapytań SQL z $O(n \times k)$ do $O(1)$ dla $n$ produktów z $k$ relacjami. Ta technika pobiera wszystkie powiązane obiekty w jednym zapytaniu SQL zamiast osobnego zapytania dla każdego produktu.

\textbf{Etap 2: Ekstrakcja cech}

Dla każdego produktu ekstrahujemy wektor cech i zapisujemy w słowniku, gdzie kluczem jest identyfikator produktu, a wartością jego wektor cech.

\textbf{Etap 3: Obliczenie podobieństw}

Dla każdej pary produktów $(p_i, p_j)$ gdzie $i < j$ obliczamy podobieństwo kosinusowe. Algorytm w pseudokodzie:

\begin{lstlisting}[style=pseudocode]
DLA KAZDEGO produktu1 W produkty:
    DLA KAZDEGO produktu2 W produkty[indeks(produkt1)+1:]:
        podobienstwo = oblicz_podobienstwo(cechy[produkt1], cechy[produkt2])

        JEZELI podobienstwo > 0.2 WTEDY
            zapisz_podobienstwo(produkt1, produkt2, podobienstwo)
            zapisz_podobienstwo(produkt2, produkt1, podobienstwo)
        KONIEC
    KONIEC
KONIEC
\end{lstlisting}

Zapisywane są oba kierunki relacji (symetryczne), co umożliwia szybkie wyszukiwanie produktów podobnych do dowolnego produktu.

\textbf{Etap 4: Bulk insert}

Zapisywanie podobieństw odbywa się w partiach po 1000 rekordów przy użyciu mechanizmu \texttt{bulk\_create()}, który przyspiesza zapis 50-100x względem pojedynczych operacji INSERT.

\textbf{Etap 5: Cache}

Wynik generowania macierzy podobieństw jest cachowany na 2 godziny (7200 sekund), eliminując potrzebę ponownego obliczania przy każdym żądaniu.

\textbf{Złożoność obliczeniowa}:

Teoretyczna złożoność to $O(n^2)$ dla $n$ produktów (wszystkie pary). W praktyce ograniczamy liczbę porównań przez:
\begin{itemize}
    \item \texttt{max\_comparisons\_per\_product = 50} — dla każdego produktu obliczamy podobieństwo do max 50 innych
    \item Wczesne odrzucanie produktów bez wspólnych kategorii
\end{itemize}

Dla katalogu 500 produktów:
\begin{itemize}
    \item Teoretycznie: $500 \times 499 / 2 = 124,750$ par
    \item Po optymalizacji: ~25,000 obliczonych podobieństw
    \item Po filtrowaniu (próg 0.2): ~4,000 zapisanych rekordów
\end{itemize}

\subsection*{3.5 Panel debugowania Content-Based Filtering}
\addcontentsline{toc}{subsection}{3.5 Panel debugowania Content-Based Filtering}

System oferuje zaawansowany panel debugowania dostępny przez endpoint \texttt{/api/content-based-debug/}. Panel prezentuje:

\textbf{Widok ogólny (bez parametru product\_id)}:

\begin{itemize}
    \item \textbf{Szczegóły algorytmu}: nazwa, metoda (Weighted Feature Vectors + Cosine Similarity), status
    \item \textbf{Wagi cech}: category (40\%), tag (30\%), price (20\%), keywords (10\%)
    \item \textbf{Statystyki bazy danych}: liczba produktów, zapisanych podobieństw, procent pokrycia
    \item \textbf{Status cache}: HIT/MISS, czas wygaśnięcia
    \item \textbf{Top 10 podobieństw}: produkty o najwyższym podobieństwie w systemie
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/contentBasedAdminDebug1.jpg}
  \caption{Panel debugowania Content-Based Filtering.}
  \label{fig:cbf_debug1}
\end{figure}

\textbf{Widok szczegółowy (z parametrem product\_id)}:

Dla konkretnego produktu panel pokazuje:

\begin{itemize}
    \item Wektor cech produktu z wagami (słownik feature → weight)
    \item Top 10 produktów podobnych z szczegółami obliczeń
    \item Wzór matematyczny dla każdej pary: $\frac{dot\_product}{norm_1 \times norm_2}$
    \item Cechy wspólne między produktami
    \item Breakdown podobieństwa: ile % z kategorii, ile z tagów, ile z ceny, ile z keywords
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/contentBasedAdminDebug2.jpg}
  \caption{CBF - szczegółowa analiza podobieństwa produktu.}
  \label{fig:cbf_debug2}
\end{figure}

\textbf{Przykładowe dane z panelu debugowania}:

\begin{verbatim}
Algorithm: Content-Based Filtering (Cosine Similarity)
Formula: cos(θ) = (A·B) / (||A|| × ||B||)

Database Statistics:
- Total Products: 500
- Saved Similarities: 16038
- Percentage Saved: 6.43%
- Threshold: 20% (Only similarities > 20% are saved to database)

Feature Weights:
- Category: 40%
- Tag: 30%
- Price: 20%
- Keywords: 10%
\end{verbatim}

\textbf{Przykład wektora cech produktu} (ACEFAST Powerbank MagSafe M10 10000 mAh):

\begin{verbatim}
Feature Vector (12 features):
- category_accessories.powerbanks: 0.400
- tag_budget:                      0.300
- tag_portable:                    0.300
- tag_fast charging:               0.300
- tag_magsafe compatible:          0.300
- tag_wireless:                    0.300
- price_low:                       0.200
- keyword_charging:                0.020
- keyword_power:                   0.020
- keyword_fast:                    0.020
- keyword_devices:                 0.020
- keyword_magsafe:                 0.020

Top 10 Similar Products:
#1 Baseus Magnetic Mini Wireless Charging 20W 20000mAh z MagSafe: 99.90%
#2 Baseus Magnetic Mini Wireless Charging 20W 20000mAh z MagSafe: 99.90%
#3 Belkin Magnetic Wireless 5000mAh MagSafe + Stand: 99.90%
#4 Baseus mini 5000mAh 20W (magnetyczny): 92.70%
#5 Belkin 20000mAh (15W, USB-C, USB-A): 84.90%

Detailed Calculation (#1):
- Dot Product: 0.6512
- Norm Product 1: 0.8075
- Norm Product 2: 0.8075
- Formula: 0.6512 / (0.8075 × 0.8075) = 0.9988
- Verification: Stored: 0.999 | Calculated: 0.9988 ✓
- Common Features: 10 total
\end{verbatim}

Panel umożliwia administratorowi:
\begin{itemize}
    \item Monitorowanie pokrycia rekomendacji (ile produktów ma podobieństwa)
    \item Identyfikację produktów bez podobieństw (słabo opisane metadane)
    \item Walidację działania wag (czy kategorie dominują prawidłowo)
    \item Ręczne wyzwalanie przeliczenia macierzy
\end{itemize}

\subsection*{3.6 Interfejs użytkownika - sortowanie według CBF}
\addcontentsline{toc}{subsection}{3.6 Interfejs użytkownika - sortowanie według CBF}

Metoda Content-Based Filtering jest wykorzystywana jako jedna z opcji sortowania produktów na stronie głównej sklepu. Administrator może wybrać algorytm CBF w ustawieniach systemu rekomendacji, co powoduje wyświetlanie produktów podobnych do tych, które użytkownik wcześniej przeglądał lub kupił.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/contentBasedAdmin1.jpg}
  \caption{Panel administratora - rekomendacje CBF.}
  \label{fig:cbf_admin}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicAdmin1.jpg}
  \caption{Panel administratora - rekomendacje Fuzzy Logic.}
  \label{fig:fuzzy_admin}
\end{figure}

Porównanie rysunków \ref{fig:cbf_admin} i \ref{fig:fuzzy_admin} demonstruje kluczową różnicę między metodami: przełączenie algorytmu z Content-Based Filtering na Fuzzy Logic powoduje natychmiastową zmianę rekomendowanych produktów. CBF poleca produkty o podobnych cechach (kategoria, tagi, cena), podczas gdy Fuzzy Logic uwzględnia dodatkowo rozmyty profil użytkownika i reguły wnioskowania.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/contentBasedSequenceDiagram.png}
  \caption{Diagram sekwencji - Content-Based Filtering.}
  \label{fig:cbf_sequence}
\end{figure}

Proces generowania rekomendacji CBF przebiega następująco:
\begin{enumerate}
    \item Klient przegląda produkt na stronie ProductPage
    \item Frontend wysyła żądanie GET do \newline
    \texttt{/api/recommendations/content-based/?product\_id=\{id\}}
    \item Backend (ContentBasedAPI) wykonuje zapytanie do modelu ProductSimilarity
    \item Model pobiera top 10 podobnych produktów z bazy danych (sortowanie po \texttt{-similarity\_score})
    \item Backend zwraca odpowiedź 200 OK z listą rekomendacji (product\_id, name, price, similarity\_score)
    \item Frontend wyświetla sekcję "Podobne produkty" na stronie produktu
\end{enumerate}

Rekomendacje CBF są również dostępne w panelu klienta, gdzie użytkownik może zobaczyć produkty podobne do swoich poprzednich zakupów. System automatycznie identyfikuje produkty z wysokim współczynnikiem podobieństwa (powyżej 20\%) i prezentuje je w sekcji spersonalizowanych rekomendacji.

\newpage

\section*{Rozdzia\l{} 4}
\addcontentsline{toc}{section}{Rozdział 4: Logika rozmyta}
\section*{Logika rozmyta w systemie rekomendacji}

\subsection*{4.1 Architektura systemu Fuzzy Logic}
\addcontentsline{toc}{subsection}{4.1 Architektura systemu Fuzzy Logic}

System logiki rozmytej został zaimplementowany w module \texttt{fuzzy\_logic\_engine.py} i składa się z trzech klas:

\textbf{1. FuzzyMembershipFunctions} — definiuje funkcje przynależności dla trzech zmiennych wejściowych:

\begin{itemize}
    \item \textbf{Cena} (price): cheap, medium, expensive — funkcje trójkątne i trapezoidalne z progami dostosowanymi do katalogu e-commerce
    \item \textbf{Jakość} (quality/rating): low, medium, high — bazuje na średniej ocenie produktu (1-5 gwiazdek)
    \item \textbf{Popularność} (popularity/view\_count): low, medium, high — bazuje na liczbie zamówień produktu
\end{itemize}

\textbf{2. FuzzyUserProfile} — buduje rozmyty profil użytkownika na podstawie:

\begin{itemize}
    \item Historii zakupów (dla zalogowanych użytkowników) — analiza kategorii, średniej ceny
    \item Danych sesji (dla gości) — ostatnio przeglądane produkty
    \item Profilu domyślnego (fallback) — gdy brak danych
\end{itemize}

\textbf{3. SimpleFuzzyInference} — silnik wnioskowania Mamdani z 6 regułami IF-THEN i metodą defuzzyfikacji średniej ważonej.

\textbf{Przepływ danych}:

\begin{enumerate}
    \item Pobranie produktów do ewaluacji
    \item Pobranie/budowa rozmytego profilu użytkownika
    \item Dla każdego produktu:
    \begin{enumerate}
        \item Fuzzyfikacja ceny, jakości, popularności
        \item Ewaluacja 6 reguł rozmytych
        \item Agregacja wyników reguł
        \item Defuzzyfikacja do wyniku liczbowego
    \end{enumerate}
    \item Sortowanie produktów według fuzzy\_score
    \item Zwrócenie top N rekomendacji
\end{enumerate}

\subsection*{4.2 Funkcje przynależności — szczegóły implementacji}
\addcontentsline{toc}{subsection}{4.2 Funkcje przynależności}

\textbf{Funkcje przynależności dla ceny}

Klasa \texttt{FuzzyMembershipFunctions} definiuje trzy funkcje dla zmiennej "cena":

\textit{Funkcja "cheap" (tania)} — trójkątna/trapezoidalna:

\begin{equation}
\mu_{cheap}(price) = \begin{cases}
1.0 & \text{jeśli } price \leq 100 \\
\frac{500 - price}{400} & \text{jeśli } 100 < price < 500 \\
0.0 & \text{jeśli } price \geq 500
\end{cases}
\end{equation}

Interpretacja: Produkty poniżej 100 PLN są w pełni "tanie". Od 100 do 500 PLN stopień "taności" maleje liniowo.

\textit{Funkcja "medium" (średnia)} — trapezoidalna:

\begin{equation}
\mu_{medium}(price) = \begin{cases}
0.0 & \text{jeśli } price < 300 \\
\frac{price - 300}{200} & \text{jeśli } 300 \leq price < 500 \\
1.0 & \text{jeśli } 500 \leq price \leq 1200 \\
\frac{1500 - price}{300} & \text{jeśli } 1200 < price < 1500 \\
0.0 & \text{jeśli } price \geq 1500
\end{cases}
\end{equation}

Interpretacja: Przedział $[500, 1200]$ ma pełną przynależność. Przejścia są płynne — cena 400 PLN jest częściowo "tania" i częściowo "średnia".

\textit{Funkcja "expensive" (droga)}:

\begin{equation}
\mu_{expensive}(price) = \begin{cases}
0.0 & \text{jeśli } price \leq 1000 \\
\frac{price - 1000}{1000} & \text{jeśli } 1000 < price < 2000 \\
1.0 & \text{jeśli } price \geq 2000
\end{cases}
\end{equation}

\textbf{Funkcje przynależności dla jakości (rating)}

Oparte na średniej ocenie produktu (skala 1-5):

\begin{itemize}
    \item \textbf{low}: pełna przynależność dla rating $\leq 2.0$, zanika do 0 przy rating = 3.0
    \item \textbf{medium}: trapezoid z pełną przynależnością dla $[3.0, 4.0]$
    \item \textbf{high}: wzrasta od rating = 3.5, pełna przynależność dla rating $\geq 4.5$
\end{itemize}

\textbf{Funkcje przynależności dla popularności (order\_count)}

Oparte na liczbie zamówień produktu:

\begin{itemize}
    \item \textbf{low}: produkty z $\leq 2$ zamówieniami (nowości, niszowe)
    \item \textbf{medium}: produkty z 3-20 zamówieniami (standardowe)
    \item \textbf{high}: produkty z $> 20$ zamówieniami (bestsellery)
\end{itemize}

\textbf{Definicje funkcji przynależności dla ceny}:

Funkcja \textbf{cheap} (trójkątna): $\mu = 1.0$ dla ceny $\leq 100$ PLN, liniowy spadek do $\mu = 0$ przy 500 PLN.

Funkcja \textbf{medium} (trapezoidalna): $\mu = 0$ dla ceny $< 300$ PLN, wzrost do $\mu = 1.0$ w przedziale 300-500 PLN, plateau $\mu = 1.0$ w przedziale 500-1200 PLN, spadek do $\mu = 0$ przy 1500 PLN.

Funkcja \textbf{expensive} (trójkątna): $\mu = 0$ dla ceny $\leq 1000$ PLN, liniowy wzrost do $\mu = 1.0$ przy 2000 PLN i powyżej.

\subsection*{4.3 Rozmyty profil użytkownika}
\addcontentsline{toc}{subsection}{4.3 Rozmyty profil użytkownika}

Klasa \texttt{FuzzyUserProfile} buduje profil preferencji użytkownika jako zbiory rozmyte. Jest to kluczowy element personalizacji rekomendacji.

\textbf{Dla zalogowanych użytkowników}:

\begin{enumerate}
    \item Pobranie historii zamówień z \texttt{prefetch\_related} dla powiązanych produktów i kategorii
    \item Zliczenie kategorii produktów w zamówieniach
    \item Obliczenie stopnia zainteresowania kategorią:
    \begin{equation}
    \mu_{category} = \frac{count_{category}}{total\_items}
    \end{equation}
    \item Obliczenie wrażliwości cenowej na podstawie średniej ceny zakupów
\end{enumerate}

\textbf{Wrażliwość cenowa} (price\_sensitivity):

\begin{equation}
\text{price\_sensitivity} = \begin{cases}
0.9 & \text{jeśli } avg\_price < 300 \text{ PLN (bardzo wrażliwy)} \\
0.6 & \text{jeśli } 300 \leq avg\_price < 700 \text{ (średnio wrażliwy)} \\
0.4 & \text{jeśli } 700 \leq avg\_price < 1500 \text{ (mało wrażliwy)} \\
0.2 & \text{jeśli } avg\_price \geq 1500 \text{ PLN (premium)}
\end{cases}
\end{equation}

Użytkownik kupujący średnio tanie produkty (avg < 300 PLN) ma wysoką wrażliwość cenową (0.9) — system będzie promował tanie produkty. Użytkownik premium (avg > 1500 PLN) ma niską wrażliwość (0.2) — system może rekomendować droższe produkty.

\textbf{Dopasowanie kategorii} — metoda \texttt{fuzzy\_category\_match()}:

Dla każdej kategorii produktu system oblicza stopień dopasowania do profilu użytkownika:

\begin{equation}
\text{match} = 0.6 \cdot \text{similarity}(cat_{user}, cat_{product}) + 0.4 \cdot \mu_{interest}(cat_{user})
\end{equation}

gdzie \texttt{similarity} używa hierarchii kategorii. Przykład:
\begin{itemize}
    \item Kategoria użytkownika: "Electronics.Laptops"
    \item Kategoria produktu: "Electronics.Monitors"
    \item Podobieństwo hierarchiczne: 0.7 (wspólna kategoria nadrzędna "Electronics")
\end{itemize}

\textbf{Profil domyślny} (dla gości/nowych użytkowników):

Dla użytkowników bez historii zakupów system stosuje neutralny profil domyślny:
\begin{itemize}
    \item price\_sensitivity = 0.5 (neutralna wrażliwość cenowa)
    \item category\_preferences = \{\} (brak preferencji kategorii)
    \item quality\_preference = 0.7 (preferuje dobrą jakość)
    \item popularity\_preference = 0.5 (neutralna wobec popularności)
\end{itemize}

\subsection*{4.4 Baza reguł rozmytych}
\addcontentsline{toc}{subsection}{4.4 Baza reguł rozmytych}

System wykorzystuje 6 reguł rozmytych typu Mamdani. Każda reguła ma formę IF-THEN z przypisaną wagą określającą jej ważność:

\textbf{R1: High Quality Bargain} (waga: 0.9)

\begin{lstlisting}[style=pseudocode]
JEZELI quality JEST high ORAZ (price JEST cheap LUB price JEST medium)
WTEDY recommendation JEST strong
\end{lstlisting}

Logika: Wysokiej jakości produkt w rozsądnej cenie to doskonała okazja. Najwyższa waga — ta reguła najsilniej wpływa na wynik.

\textbf{R2: Popular in Category} (waga: 0.7)

\begin{lstlisting}[style=pseudocode]
JEZELI category_match JEST high ORAZ (popularity JEST medium LUB popularity JEST high)
WTEDY recommendation JEST medium-high
\end{lstlisting}

Logika: Popularny produkt z kategorii interesującej użytkownika. Popularność = walidacja społeczna.

\textbf{R3: Price Sensitive Match} (waga: 0.6)

\begin{lstlisting}[style=pseudocode]
JEZELI user.price_sensitivity > 0.6 ORAZ price JEST cheap
WTEDY recommendation JEST moderate
\end{lstlisting}

Logika: Dla użytkowników wrażliwych cenowo (kupujących tanie produkty) promuj tanie opcje.

\textbf{R4: Category Quality Match} (waga: 0.85)

\begin{lstlisting}[style=pseudocode]
JEZELI category_match JEST high ORAZ (quality JEST medium LUB quality JEST high)
WTEDY recommendation JEST strong
\end{lstlisting}

Logika: Dopasowanie do kategorii + dobra jakość. Wysoka waga — dopasowanie kategorii jest istotne.

\textbf{R5: Premium Match} (waga: 0.8)

\begin{lstlisting}[style=pseudocode]
JEZELI user.price_sensitivity < 0.4 ORAZ price JEST expensive ORAZ quality JEST high
WTEDY recommendation JEST strong
\end{lstlisting}

Logika: Dla użytkowników premium (nieczułych cenowo) promuj drogie produkty wysokiej jakości.

\textbf{R6: Quality-Price Balance} (waga: 0.75)

\begin{lstlisting}[style=pseudocode]
JEZELI (quality JEST high ORAZ price JEST reasonable) LUB
       (quality JEST medium ORAZ price JEST cheap)
WTEDY recommendation JEST moderate
\end{lstlisting}

Logika: Dobry stosunek jakości do ceny — "value for money".

\subsection*{4.5 Wnioskowanie i defuzzyfikacja}
\addcontentsline{toc}{subsection}{4.5 Wnioskowanie i defuzzyfikacja}

Metoda \texttt{evaluate\_product()} implementuje pełny cykl wnioskowania Mamdani:

\textbf{Krok 1: Fuzzyfikacja}

Dla każdej zmiennej wejściowej (cena, jakość, popularność) obliczane są stopnie przynależności do wszystkich zbiorów rozmytych. Wynikiem jest słownik zawierający 9 wartości przynależności:

\begin{itemize}
    \item Cena: $\mu_{cheap}$, $\mu_{medium}$, $\mu_{expensive}$
    \item Jakość: $\mu_{low}$, $\mu_{medium}$, $\mu_{high}$
    \item Popularność: $\mu_{low}$, $\mu_{medium}$, $\mu_{high}$
\end{itemize}

\textbf{Krok 2: Ewaluacja reguł}

Każda reguła jest ewaluowana za pomocą T-normy (minimum) dla operatora AND i T-conormy (maksimum) dla OR. Zgodnie z teorią zbiorów rozmytych \cite{zadeh1965fuzzy}:

\begin{equation}
\alpha_{R1} = \min(\mu_{quality\_high}, \max(\mu_{price\_cheap}, \mu_{price\_medium})) \cdot w_{R1}
\end{equation}

Dla każdej z 6 reguł obliczana jest jej aktywacja $\alpha_i$ poprzez aplikację odpowiednich operatorów rozmytych do wartości przynależności.

\textbf{Krok 3: Agregacja}

Wyniki reguł są agregowane. W uproszczonej implementacji używam sumy ważonej (zamiast pełnej agregacji Mamdani):

\begin{equation}
\text{aggregated} = \sum_{i=1}^{6} \alpha_i
\end{equation}

\textbf{Krok 4: Defuzzyfikacja}

System używa uproszczonej metody średniej ważonej:

\begin{equation}
\text{fuzzy\_score} = \frac{\sum_{i=1}^{6} \alpha_i \cdot w_i}{\sum_{i=1}^{6} w_i}
\end{equation}

gdzie $\alpha_i$ to aktywacja reguły $i$, a $w_i$ to waga reguły.

Wagi reguł wynoszą: $w_{R1} = 0.9$, $w_{R2} = 0.7$, $w_{R3} = 0.6$, $w_{R4} = 0.85$, $w_{R5} = 0.8$, $w_{R6} = 0.75$. Suma wag wynosi 4.65, co zapewnia normalizację wyniku do przedziału $[0, 1]$.

\textbf{Wynik końcowy}:

Metoda zwraca słownik z:
\begin{itemize}
    \item \texttt{fuzzy\_score} — wartość z przedziału $[0, 1]$ reprezentująca siłę rekomendacji
    \item \texttt{rule\_activations} — słownik z aktywacją każdej reguły (dla debugowania)
    \item \texttt{category\_match} — stopień dopasowania kategorii
    \item \texttt{price\_membership} — przynależności cenowe (cheap, medium, expensive)
\end{itemize}

\subsection*{4.6 Panel debugowania Fuzzy Logic}
\addcontentsline{toc}{subsection}{4.6 Panel debugowania Fuzzy Logic}

Panel debugowania dostępny przez endpoint \texttt{/api/fuzzy-debug/} prezentuje:

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicAdminDebug1.jpg}
  \caption{Panel debugowania Fuzzy Logic.}
  \label{fig:fuzzy_debug1}
\end{figure}

\textbf{Widok ogólny}:

\begin{itemize}
    \item \textbf{Szczegóły algorytmu}: metoda (Mamdani Fuzzy Inference), liczba reguł (6), T-norma (min), T-conorma (max)
    \item \textbf{Funkcje przynależności}: definicje dla price, quality, popularity z progami
    \item \textbf{Statystyki}: średni fuzzy\_score, rozkład wyników, aktywacja reguł
    \item \textbf{Profil użytkownika}: jeśli podany user\_id — szczegóły profilu rozmytego
\end{itemize}

\textbf{Widok produktu} (z parametrem product\_id):

\begin{itemize}
    \item Wartości fuzzyfikacji (wszystkie przynależności)
    \item Aktywacja każdej z 6 reguł z wyjaśnieniem
    \item Obliczenie końcowe z breakdownem
    \item Porównanie z innymi produktami
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicAdminDebug2.jpg}
  \caption{Fuzzy Logic - ewaluacja produktu.}
  \label{fig:fuzzy_debug2}
\end{figure}

\textbf{Przykładowe dane z panelu debugowania}:

\begin{verbatim}
Algorithm: Fuzzy Logic Inference System (Mamdani-style)
Description: System rekomendacji oparty na logice rozmytej
z uproszczona defuzzyfikacja

User Profile:
- User: admin2 (ID: 2)
- Profile Type: authenticated
- Price Sensitivity: 0.6 - Medium
- Tracked Categories: 26

Category Interests:
- wearables.watches: 0.132
- networking.networkCards: 0.093
- peripherals.microphones: 0.066
- monitoring.cameras: 0.06
- gadgets: 0.06

Membership Functions:
Price Functions:
- CHEAP: μ = 1.0 dla ceny ≤ 100 PLN, spada do 0 przy 500 PLN
- MEDIUM: μ = 1.0 dla ceny 500-1200 PLN
- EXPENSIVE: μ = 1.0 dla ceny ≥ 2000 PLN
\end{verbatim}

\textbf{Przykład fuzzyfikacji produktu} (AMD Ryzen 9 7900X, cena: 400 PLN, rating: 3, views: 1):

\begin{verbatim}
Selected Product:
- ID: 96
- Name: AMD Ryzen 9 7900X
- Price: 400 PLN
- Rating: 3
- View Count: 1
- Categories: components.processors

Fuzzification - Membership Degrees:
Price: 400 PLN
- Cheap: μ = 0.25
- Medium: μ = 0.5
- Expensive: μ = 0
- Dominant: MEDIUM

Quality: 3
- Low: μ = 0.5
- Medium: μ = 0.5
- High: μ = 0
- Dominant: LOW

Popularity: 1 views
- Low: μ = 1
- Medium: μ = 0
- High: μ = 0
- Dominant: LOW

Category Matching:
- Max Match: 0.394
- components.processors: 0.394
\end{verbatim}

\subsection*{4.7 Interfejs użytkownika - rekomendacje Fuzzy Logic}
\addcontentsline{toc}{subsection}{4.7 Interfejs użytkownika - rekomendacje Fuzzy Logic}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/fuzzyLogicSequenceDiagram.png}
  \caption{Diagram sekwencji - Fuzzy Logic.}
  \label{fig:fuzzy_sequence}
\end{figure}

Rekomendacje oparte na logice rozmytej są prezentowane użytkownikowi w panelu klienta w sekcji "Recommended For You (Fuzzy Logic)". System wyświetla wykres kołowy przedstawiający rozkład kategorii w historii zakupów użytkownika oraz listę rekomendowanych produktów.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicClient1.jpg}
  \caption{Panel klienta - rekomendacje Fuzzy Logic.}
  \label{fig:fuzzy_client}
\end{figure}

Wykres "Category Distribution" pokazuje procentowy udział kategorii w historii zakupów użytkownika (np. electronics.phones, accessories.powerBanks, wearables.watches, peripherals.printers, office.accessories). Na podstawie tych danych system buduje rozmyty profil użytkownika i generuje spersonalizowane rekomendacje.

Sekcja "Recommended For You (Fuzzy Logic)" prezentuje produkty z najwyższym wynikiem fuzzy\_score, uwzględniając:
\begin{itemize}
    \item Dopasowanie do kategorii zainteresowań użytkownika
    \item Wrażliwość cenową użytkownika
    \item Jakość produktu (rating)
    \item Popularność produktu (view\_count)
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicClient2.jpg}
  \caption{Zakładka "Fuzzy Recommendations".}
  \label{fig:fuzzy_client2}
\end{figure}

Zakładka "Fuzzy Recommendations" wyświetla produkty wraz z:
\begin{itemize}
    \item \textbf{Fuzzy Score}: całkowity wynik rekomendacji (np. 58.1\%, 56.3\%)
    \item \textbf{Category Match}: stopień dopasowania kategorii do preferencji użytkownika (np. 65.9\%, 60.6\%)
    \item \textbf{View Rule Activations}: przycisk do podglądu aktywacji wszystkich 6 reguł rozmytych
\end{itemize}

Przykładowe rekomendacje z interfejsu:
\begin{itemize}
    \item Motorola edge 40 neo 5G (\$549.99): Fuzzy Score 58.1\%, Category Match 65.9\%
    \item Apple iPad Air 11" M2 (\$749.99): Fuzzy Score 56.3\%, Category Match 60.6\%
    \item Roborock Q8 Max+ White (\$649.99): Fuzzy Score 56.3\%, Category Match 60.6\%
    \item JoyRoom Powerbank 10000mAh (\$49.99): Fuzzy Score 54.3\%, Category Match 64.3\%
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzyLogicClient3.jpg}
  \caption{Zakładka "Your Fuzzy User Profile".}
  \label{fig:fuzzy_client3}
\end{figure}

Zakładka ``Your Fuzzy User Profile'' (Rysunek \ref{fig:fuzzy_client3}) prezentuje rozmyty profil użytkownika zbudowany na podstawie historii zakupów:
\begin{itemize}
    \item \textbf{Profile Type}: typ profilu (authenticated/guest)
    \item \textbf{Price Sensitivity}: wrażliwość cenowa w procentach (np. 60\%)
    \item \textbf{Favorite Categories}: ulubione kategorie z wagami zainteresowania
\end{itemize}

\subsection*{4.8 Wyszukiwanie rozmyte (Fuzzy Search)}
\addcontentsline{toc}{subsection}{4.8 Wyszukiwanie rozmyte (Fuzzy Search)}

Wyszukiwanie rozmyte (Fuzzy Search) wykorzystuje algorytm odległości Levensteina do wyszukiwania produktów z tolerancją na literówki i błędy pisowni. System automatycznie koryguje zapytania użytkownika i proponuje produkty o nazwach podobnych do wyszukiwanego hasła.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/fuzzySearch1.jpg}
  \caption{Wyszukiwarka rozmyta (Fuzzy Search).}
  \label{fig:fuzzy_search}
\end{figure}

Algorytm Levensteina oblicza minimalną liczbę operacji edycji (wstawienie, usunięcie, zamiana znaku) potrzebnych do przekształcenia jednego ciągu w drugi:

\begin{equation}
lev(a,b) = \begin{cases}
|a| & \text{jeśli } |b| = 0 \\
|b| & \text{jeśli } |a| = 0 \\
lev(tail(a), tail(b)) & \text{jeśli } a[0] = b[0] \\
1 + \min \begin{cases}
lev(tail(a), b) \\
lev(a, tail(b)) \\
lev(tail(a), tail(b))
\end{cases} & \text{w przeciwnym wypadku}
\end{cases}
\end{equation}

System wyszukiwania rozmytego zwraca produkty, dla których odległość Levensteina między zapytaniem a nazwą produktu jest mniejsza niż ustalony próg (domyślnie 3).

\newpage

\section*{Rozdzia{} 5}
\addcontentsline{toc}{section}{Rozdzia{} 5: Modele probabilistyczne}
\section*{Modele probabilistyczne — Markov Chain i Naive Bayes}

\subsection*{5.1 Architektura systemu probabilistycznego}
\addcontentsline{toc}{subsection}{5.1 Architektura systemu probabilistycznego}

System probabilistyczny składa się z trzech komponentów zaimplementowanych w \texttt{custom\_recommendation\_engine.py}:

\textbf{1. CustomMarkovChain} — łańcuch Markowa pierwszego rzędu do predykcji sekwencji zakupowych kategorii produktów. Modeluje pytanie: "Jeśli użytkownik kupił produkt z kategorii A, jaka kategoria jest najbardziej prawdopodobna jako następna?"

\textbf{2. CustomNaiveBayes} — naiwny klasyfikator Bayesa z wygładzaniem Laplace'a do:
\begin{itemize}
    \item Predykcji prawdopodobieństwa zakupu (will\_purchase / will\_not\_purchase)
    \item Predykcji ryzyka rezygnacji (will\_churn / will\_not\_churn)
\end{itemize}

\textbf{3. ProbabilisticRecommendationEngine} — silnik łączący oba modele w jeden system rekomendacji z wagami: Markov (60\%) + Naive Bayes (40\%).

\textbf{Przepływ danych}:

\begin{enumerate}
    \item Pobranie historii zamówień wszystkich użytkowników
    \item Budowa sekwencji kategorii dla każdego użytkownika
    \item Trening modelu Markowa na sekwencjach
    \item Budowa cech użytkowników dla Naive Bayes
    \item Trening modelu NB na danych historycznych
    \item Predykcja: Markov przewiduje następne kategorie, NB ocenia prawdopodobieństwo zakupu
    \item Agregacja wyników i generowanie rekomendacji
\end{enumerate}

\subsection*{5.2 Łańcuch Markowa dla sekwencji zakupowych}
\addcontentsline{toc}{subsection}{5.2 Łańcuch Markowa dla sekwencji zakupowych}

Klasa \texttt{CustomMarkovChain} modeluje sekwencje zakupów użytkowników jako łańcuch Markowa pierwszego rzędu, gdzie stanami są kategorie produktów.

\textbf{Struktura danych}:

Łańcuch Markowa przechowuje:
\begin{itemize}
    \item \texttt{transitions} — słownik słowników: \{stan: \{następny\_stan: licznik\}\}
    \item \texttt{states} — zbiór wszystkich stanów (48 kategorii produktów)
    \item \texttt{total\_sequences} — liczba sekwencji użytych do treningu
\end{itemize}

\textbf{Trening modelu}:

Dla każdej sekwencji kategorii zakupowych $[c_1, c_2, ..., c_n]$ algorytm iteruje po parach sąsiadujących stanów $(c_i, c_{i+1})$ i zwiększa licznik przejścia $T[c_i][c_{i+1}]$. Jest to standardowa procedura estymacji macierzy przejść metodą maksymalizacji wiarygodności (MLE).

\textbf{Normalizacja do prawdopodobieństw}:

Prawdopodobieństwo przejścia obliczane jest jako:

\begin{equation}
P(s_j | s_i) = \frac{T[s_i][s_j]}{\sum_{k} T[s_i][s_k]}
\end{equation}

\textbf{Predykcja}:

Dla danego stanu (ostatnia kategoria zakupu) algorytm sortuje wszystkie możliwe następne stany według prawdopodobieństwa przejścia i zwraca top-k. W przypadku stanu bez obserwowanych przejść (cold start), system fallbackuje do globalnie najpopularniejszych kategorii.

\textbf{Generowanie sekwencji}:

Metoda predict\_sequence() generuje sekwencję $n$ przewidywanych kategorii metodą zachłanną (greedy), wybierając w każdym kroku najbardziej prawdopodobny następny stan. Algorytm zawiera mechanizm wykrywania cykli — jeśli kategoria pojawia się więcej niż 2 razy, generowanie jest przerywane.

\textbf{Rozkład stacjonarny} — metoda \texttt{get\_stationary\_distribution()}:

Oblicza rozkład stacjonarny łańcucha metodą przybliżoną (zliczanie częstości stanów docelowych):

Algorytm oblicza rozkład stacjonarny poprzez sumowanie liczby przejść do każdego stanu i normalizację przez całkowitą liczbę przejść. Wynik reprezentuje długoterminowe prawdopodobieństwo znalezienia się użytkownika w danej kategorii.

\subsection*{5.3 Naiwny klasyfikator Bayesa}
\addcontentsline{toc}{subsection}{5.3 Naiwny klasyfikator Bayesa}

Klasa \texttt{CustomNaiveBayes} implementuje multinomialny Naive Bayes z wygładzaniem Laplace'a.

\textbf{Cechy użytkownika} (features):

\begin{itemize}
    \item \texttt{total\_orders} — łączna liczba zamówień (dyskretyzowana: 0-2, 3-5, 6-10, 11+)
    \item \texttt{avg\_order\_value} — średnia wartość zamówienia (low, medium, high, premium)
    \item \texttt{days\_since\_last\_order} — dni od ostatniego zamówienia (recent, moderate, old, very\_old)
    \item \texttt{favorite\_category} — najczęściej kupowana kategoria
    \item \texttt{order\_frequency} — częstość zamówień (rare, occasional, regular, frequent)
\end{itemize}

\textbf{Struktura danych}:

Model przechowuje:
\begin{itemize}
    \item \texttt{class\_priors} — prawdopodobieństwa a priori $P(C)$ dla każdej klasy
    \item \texttt{feature\_likelihoods} — prawdopodobieństwa warunkowe $P(x_i | C)$
    \item \texttt{feature\_vocabularies} — unikalne wartości każdej cechy (dla wygładzania Laplace'a)
\end{itemize}

\textbf{Trening modelu}:

Faza treningu obejmuje:
\begin{enumerate}
    \item Zliczenie wystąpień każdej klasy i obliczenie prawdopodobieństw a priori: $P(C) = \frac{count(C)}{N}$
    \item Dla każdej próbki treningowej — aktualizacja słowników cech dla odpowiedniej klasy
    \item Budowa słownika unikalnych wartości cech (vocabulary) potrzebnego do wygładzania Laplace'a
\end{enumerate}

\textbf{Predykcja}:

Predykcja wykorzystuje twierdzenie Bayesa w przestrzeni logarytmicznej (dla stabilności numerycznej):

\begin{equation}
\log P(C | X) = \log P(C) + \sum_{i=1}^{n} \log P(x_i | C)
\end{equation}

Wyniki są normalizowane przez funkcję softmax, aby uzyskać rozkład prawdopodobieństw sumujący się do 1.

\textbf{Wygładzanie Laplace'a}:

Dla cech niewidzianych podczas treningu stosowane jest wygładzanie Laplace'a, które zapobiega zerowaniu prawdopodobieństwa:

\begin{equation}
P(x_i | C) = \frac{count(x_i, C) + 1}{count(C) + |V|}
\end{equation}

gdzie $|V|$ to liczba unikalnych wartości cechy (rozmiar słownika).

\textbf{Ważność cech}:

Ważność cechy jest mierzona entropią rozkładu jej wartości w różnych klasach:

\begin{equation}
H(feature) = -\sum_{v \in V} P(v | C) \cdot \log_2 P(v | C)
\end{equation}

Wyższa entropia oznacza większą zdolność cechy do rozróżniania klas. Typowy ranking ważności cech dla predykcji zakupu: days\_since\_last\_order > total\_orders > avg\_order\_value > favorite\_category.

\subsection*{5.4 Integracja modeli — ProbabilisticRecommendationEngine}
\addcontentsline{toc}{subsection}{5.4 Integracja modeli}

Klasa \texttt{ProbabilisticRecommendationEngine} łączy oba modele w jeden system rekomendacyjny.

\textbf{Trening}:

System trenuje trzy komponenty:
\begin{enumerate}
    \item \textbf{Markov Chain} — na sekwencjach kategorii z historii zamówień
    \item \textbf{Purchase NB} — na cechach użytkowników z etykietami will\_purchase / will\_not\_purchase
    \item \textbf{Churn NB} — na cechach użytkowników z etykietami will\_churn / will\_not\_churn
\end{enumerate}

\textbf{Predykcja zintegrowana}:

Algorytm generowania rekomendacji w pseudokodzie:

\begin{lstlisting}[style=pseudocode]
FUNKCJA generuj_rekomendacje(uzytkownik, ostatnia_kategoria, k=10):
    markov_predykcje = Markov.przewidz_nastepne(ostatnia_kategoria, top=5)
    cechy_uzytkownika = ekstrahuj_cechy(uzytkownik)
    p_zakupu = NB_zakup.predykcja(cechy_uzytkownika)["will_purchase"]

    produkty = pobierz_produkty_z_kategorii(markov_predykcje)

    DLA KAZDEGO produktu W produkty:
        p_kategorii = maks(prawdopodobienstwo kategorii z Markova)
        score = 0.6 * p_kategorii + 0.4 * p_zakupu
        dodaj(produkt, score) do rekomendacji
    KONIEC

    ZWROC top_k(rekomendacje, k)
KONIEC FUNKCJA
\end{lstlisting}

Wagi agregacji (Markov 60\%, NB 40\%) zostały dobrane empirycznie — Markov Chain lepiej przewiduje następną kategorię, podczas gdy Naive Bayes moduluje wynik na podstawie ogólnego prawdopodobieństwa zakupu użytkownika.

\subsection*{5.5 API probabilistyczne}
\addcontentsline{toc}{subsection}{5.5 API probabilistyczne}

System udostępnia dwa główne endpointy w \texttt{probabilistic\_views.py}:

\textbf{MarkovRecommendationsAPI} (\texttt{GET /api/markov-recommendations/}):

\begin{itemize}
    \item Trenuje modele na bieżących danych (10-15 sekund dla pełnego treningu)
    \item Przewiduje następne kategorie zakupów na podstawie ostatniego zamówienia użytkownika
    \item Zwraca top 6 produktów z przewidywanych kategorii
    \item Oblicza prawdopodobieństwo zakupu i oczekiwany czas do następnego zamówienia
\end{itemize}

Przykładowa odpowiedź:

\begin{verbatim}
{
  "user_id": 42,
  "last_category": "Laptops",
  "predicted_categories": [
    {"category": "Accessories", "probability": 0.45},
    {"category": "Monitors", "probability": 0.28},
    {"category": "Peripherals", "probability": 0.15}
  ],
  "recommended_products": [
    {"id": 123, "name": "Laptop Bag 15\"", "score": 0.72},
    {"id": 456, "name": "USB-C Hub", "score": 0.65}
  ],
  "purchase_probability": 0.78,
  "expected_days_to_next_order": 12.5
}
\end{verbatim}

\textbf{BayesianInsightsAPI} (\texttt{GET /api/bayesian-insights/}):

\begin{itemize}
    \item Preferencje kategorii użytkownika (z Markova)
    \item Ryzyko churnu (z Naive Bayes)
    \item Wzorce behawioralne (feature importance)
    \item Personalizowane rekomendacje
\end{itemize}

Przykładowa odpowiedź:

\begin{verbatim}
{
  "user_id": 42,
  "category_preferences": {
    "Electronics": 0.45,
    "Laptops": 0.30,
    "Accessories": 0.25
  },
  "churn_risk": {
    "will_churn": 0.15,
    "will_not_churn": 0.85,
    "risk_level": "LOW"
  },
  "behavioral_patterns": {
    "order_frequency": "regular",
    "avg_order_value": "medium",
    "days_since_last": "recent"
  },
  "feature_importance": {
    "days_since_last_order": 0.82,
    "order_frequency": 0.65,
    "total_orders": 0.45
  }
}
\end{verbatim}

\subsection*{5.6 Panel debugowania modeli probabilistycznych}
\addcontentsline{toc}{subsection}{5.6 Panel debugowania modeli probabilistycznych}

Panel debugowania prezentuje szczegółowe informacje o obu modelach:

\begin{figure}[H]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsAdminDebug1.jpg}
  \caption{Panel debugowania - Markov Chain.}
  \label{fig:prob_debug1}
\end{figure}

\textbf{Statystyki Markov Chain} (z panelu debugowania):
\begin{itemize}
    \item Rząd łańcucha (Order): 1 (first-order Markov Chain)
    \item Liczba stanów (kategorii): 48
    \item Liczba przejść (transitions): 48
\end{itemize}

\textbf{Top 10 przejść z najwyższym prawdopodobieństwem}:

\begin{verbatim}
| # | From Category        | To Category            | Probability | Count |
|---|----------------------|------------------------|-------------|-------|
| 1 | laptops.learning     | office.accessories     | 100.00%     | 1     |
| 2 | computers.office     | drones                 | 100.00%     | 1     |
| 3 | computers.learning   | power.strips           | 66.67%      | 0.67  |
| 4 | computers.gaming     | peripherals.keyboards  | 50.00%      | 0.5   |
| 5 | computers.gaming     | power.strips           | 50.00%      | 0.5   |
| 6 | laptops.gaming       | electronics.televisions| 50.00%      | 0.5   |
| 7 | laptops.gaming       | laptop.hubs            | 50.00%      | 0.5   |
| 8 | laptops.office       | peripherals.keyboards  | 50.00%      | 0.5   |
| 9 | laptops.office       | components.disks       | 50.00%      | 0.5   |
|10 | components.processors| networking.networkCards| 33.33%      | 0.33  |
\end{verbatim}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsAdminDebug2.jpg}
  \caption{Panel debugowania - Naive Bayes.}
  \label{fig:prob_debug2}
\end{figure}

\textbf{Statystyki Naive Bayes} (z panelu debugowania):

\textit{Purchase Prediction}:
\begin{itemize}
    \item Trained: Yes
    \item Number of Features: 3
    \item Classes: will\_not\_purchase
    \item Class Priors: will\_not\_purchase = 1.0
\end{itemize}

\textit{Churn Prediction}:
\begin{itemize}
    \item Trained: Yes
    \item Number of Features: 3
    \item Classes: will\_churn, will\_not\_churn
    \item Class Priors: will\_churn = 0.95, will\_not\_churn = 0.05
\end{itemize}

\textbf{Przykład analizy użytkownika} (client4, ID: 9):

\begin{verbatim}
User Analysis:
- User: client4 (ID: 9)
- Total Orders: 10
- Total Spent: 31331.33 PLN
- Avg Order Value: 3133.13 PLN
- Days Since Last Order: 74
- Last Category Purchased: cleaning.supplies

Purchase Sequence (Last 10):
components.powerSupply → electronics.tablets → camera.accessories →
laptop.hubs → peripherals.speakers → laptop.hubs → electronics.phones →
gadgets → laptop.hubs → cleaning.supplies

Next Purchase Predictions (Markov Chain):
1. peripherals.printers: 11.11%
2. accessories.powerBanks: 7.41%
3. peripherals.soundCards: 7.41%
\end{verbatim}

\subsection*{5.7 Interfejs użytkownika - rekomendacje probabilistyczne}
\addcontentsline{toc}{subsection}{5.7 Interfejs użytkownika - rekomendacje probabilistyczne}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/probabilisticMethodsSequenceDiagram.png}
  \caption{Diagram sekwencji - Probabilistic Models.}
  \label{fig:prob_sequence}
\end{figure}

Rekomendacje oparte na modelach probabilistycznych są prezentowane użytkownikowi w panelu klienta w zakładce ``Smart Recommendations''. System wyświetla dwie podzakładki:
\begin{itemize}
    \item \textbf{Next Purchase (Markov)}: produkty z kategorii przewidywanych przez łańcuch Markowa jako najbardziej prawdopodobne do zakupu
    \item \textbf{Behavior Insights (Bayesian)}: analiza zachowań zakupowych użytkownika z wykorzystaniem Naive Bayes
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsClient1.jpg}
  \caption{Zakładka "Next Purchase (Markov)".}
  \label{fig:prob_client1}
\end{figure}

Zakładka "Next Purchase (Markov)" prezentuje:
\begin{itemize}
    \item \textbf{Next Purchase Probability}: prawdopodobieństwo zakupu w ciągu 30 dni (np. 50\%)
    \item \textbf{Expected Days Until Next Purchase}: przewidywany czas do następnego zakupu
    \item \textbf{Likely Next Products}: lista produktów z najwyższym Prediction Score (np. Imou Cruiser 2 5MP: 13\%, A4Tech HD PK-910P: 13\%)
    \item \textbf{Your Shopping Patterns}: najczęstsza sekwencja zakupów i długość cyklu (np. power.strips → laptop.hubs → office.accessories, 10 products per cycle)
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsClient2.jpg}
  \caption{Zakładka "Behavior Insights (Bayesian)".}
  \label{fig:prob_client2}
\end{figure}

Zakładka ``Behavior Insights (Bayesian)'' wykorzystuje model Naive Bayes do analizy preferencji zakupowych:
\begin{itemize}
    \item \textbf{Purchase Likelihood}: wykres słupkowy prawdopodobieństwa zakupu dla każdej kategorii
    \item Kategorie z najwyższym prawdopodobieństwem: electronics.phones (10\%), power.strips (9\%), accessories.cables (9\%), office.accessories (9\%)
    \item Model uczy się na podstawie historii zakupów wszystkich użytkowników i tworzy profil behawioralny
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsClient3.jpg}
  \caption{Zakładka "Churn Risk Analysis".}
  \label{fig:prob_client3}
\end{figure}

Zakładka ``Churn Risk Analysis'' (Rysunek \ref{fig:prob_client3}) prezentuje:
\begin{itemize}
    \item \textbf{Churn Risk}: poziom ryzyka rezygnacji klienta (np. 25\% - LOW RISK)
    \item \textbf{Shopping Behavior Analysis}: analiza wzorców zakupowych użytkownika
    \item \textbf{Personalized Suggestions}: spersonalizowane sugestie produktów
\end{itemize}

\subsection*{5.8 Panel administracyjny - widoki probabilistyczne}
\addcontentsline{toc}{subsection}{5.8 Panel administracyjny - widoki probabilistyczne}

Panel administracyjny systemu rekomendacji probabilistycznych prezentuje zaawansowane analizy dla administratora:

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsAdmin1.jpg}
  \caption{Panel administracyjny - Markov Chain Analysis.}
  \label{fig:prob_admin1}
\end{figure}

Rysunek \ref{fig:prob_admin1} prezentuje panel ``Markov Chain Analysis'' zawierający:
\begin{itemize}
    \item \textbf{Sales Forecast}: wykres prognozy sprzedaży w czasie
    \item \textbf{Detailed Forecast}: tabela z szczegółowymi predykcjami dla poszczególnych okresów
\end{itemize}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/probabilisticMethodsAdmin2.jpg}
  \caption{Panel administracyjny - Bayesian Analysis.}
  \label{fig:prob_admin2}
\end{figure}

Rysunek \ref{fig:prob_admin2} prezentuje panel ``Bayesian Analysis'' z:
\begin{itemize}
    \item \textbf{Category Preferences}: wykres słupkowy preferencji kategorii użytkowników
    \item \textbf{Performance Metrics}: metryki wydajności modelu Naive Bayes
\end{itemize}

Rysunek \ref{fig:prob_admin3} prezentuje panel ``Demand Forecast'' z:
\begin{itemize}
    \item \textbf{Demand Trends}: wykres trendów popytu w czasie
    \item \textbf{Seasonality Analysis}: analiza sezonowości zakupów
    \item \textbf{Stock Recommendations}: rekomendacje dotyczące poziomu zapasów
\end{itemize}

\newpage

\section*{Rozdzia{} 6}
\addcontentsline{toc}{section}{Rozdzia{} 6: Architektura techniczna systemu}
\section*{Architektura techniczna systemu}

Niniejszy rozdział jest wspólny z pracą współautora i opisuje architekturę całego systemu e-commerce z modułem rekomendacyjnym.

\subsection*{6.1 Stos technologiczny}
\addcontentsline{toc}{subsection}{6.1 Stos technologiczny}

Aplikacja została zbudowana w oparciu o nowoczesny stos technologiczny:

\textbf{Backend}: Django 4.2 (Python 3.11) wraz z Django REST Framework 3.14. Django zapewnia solidną architekturę MVC, system ORM dla abstrakcji bazy danych, oraz wbudowane mechanizmy bezpieczeństwa. Django REST Framework rozszerza Django o funkcjonalności API RESTful.

\textbf{Frontend}: React 18 z bibliotekami wspierającymi (Axios, Framer Motion, React Router) tworzy Single Page Application (SPA). React Hooks zarządzają stanem aplikacji.

\textbf{Baza danych}: PostgreSQL 14 przechowuje wszystkie dane aplikacji. Wybór PostgreSQL był podyktowany zaawansowanymi funkcjami (indeksy częściowe, full-text search, JSON support).

\textbf{Biblioteki}: NumPy 1.24 (operacje macierzowe dla wektorów cech i macierzy podobieństwa).

\subsection*{6.2 Backend — Django REST Framework}
\addcontentsline{toc}{subsection}{6.2 Backend — Django REST Framework}

Architektura backendu opiera się na wzorcu Model-View-Serializer. Kluczowe pliki dla modułu rekomendacyjnego:

\begin{itemize}
    \item \textbf{custom\_recommendation\_engine.py} — implementacje CBF, Markov, Naive Bayes
    \item \textbf{fuzzy\_logic\_engine.py} — implementacja systemu Fuzzy Logic
    \item \textbf{recommendation\_views.py} — endpoint CBF: \texttt{/api/content-based-debug/}
    \item \textbf{probabilistic\_views.py} — endpointy Markov i Bayes
    \item \textbf{models.py} — modele ProductSimilarity, RecommendationSettings
\end{itemize}

\subsection*{6.3 Frontend — React 18}
\addcontentsline{toc}{subsection}{6.3 Frontend — React 18}

Frontend aplikacji został zbudowany jako Single Page Application (SPA) w technologii React 18, wykorzystując nowoczesne wzorce programowania funkcyjnego i React Hooks do zarządzania stanem. Architektura składa się z modułowych komponentów odpowiedzialnych za poszczególne funkcjonalności systemu.

\textbf{Główne komponenty aplikacji}:

\begin{itemize}
    \item \textbf{App.js} — główny komponent aplikacji zarządzający routingiem React Router v6 oraz globalnym stanem poprzez Context API. Definiuje strukturę tras (routes) oraz layouty dla różnych typów stron (publiczne, chronione, administracyjne).

    \item \textbf{Navbar.jsx} — responsywna nawigacja z wyszukiwarką, linkami do kluczowych sekcji, przyciskami logowania/rejestracji oraz ikoną koszyka z licznikiem produktów. Wykorzystuje React Hooks (useState, useContext) do zarządzania stanem mobilnego menu oraz danymi użytkownika.

    \item \textbf{SearchModal.jsx} — zaawansowany modal wyszukiwania z dwoma trybami: sentiment search (sortowanie według zagregowanego wyniku sentymentu) oraz fuzzy search (wyszukiwanie z wykorzystaniem logiki rozmytej z tolerancją na błędy).

    \item \textbf{ShopContent.jsx} — komponent wyświetlający katalog produktów z sidebar'em filtrów (kategorie, zakres cen, oceny) oraz grid'em kart produktów. Obsługuje dynamiczne filtrowanie i sortowanie.

    \item \textbf{ProductPage.jsx} — szczegółowy widok pojedynczego produktu zawierający galerię zdjęć (slider react-slick), opis, specyfikacje techniczne, kategorie, sekcję opinii klientów z analizą sentymentu, rekomendacje "Frequently Bought Together" oraz przycisk "Add to Cart" z obsługą stanu koszyka (CartContext).

    \item \textbf{CartContent.jsx} — koszyk zakupowy wyświetlający listę wybranych produktów, łączną wartość zamówienia oraz sekcję rekomendacji cross-sell (produkty komplementarne według reguł asocjacyjnych). Użytkownik może modyfikować ilości, usuwać produkty oraz przejść do finalizacji zamówienia.

    \item \textbf{ClientPanel} — panel klienta zawierający zakładki: Dashboard (podsumowanie aktywności, ostatnie zamówienia, statystyki), Orders (historia wszystkich zamówień z możliwością podglądu szczegółów), Account (edycja danych osobowych, zmiana hasła), Recommendations (spersonalizowane rekomendacje Content-Based Filtering, Fuzzy Logic i Probabilistic Models aktualizowane po każdym zamówieniu).

    \item \textbf{AdminPanel} — panel administracyjny dostępny dla użytkowników z uprawnieniami is\_staff. Zawiera zakładki: Products (zarządzanie produktami), Orders (przeglądanie i zarządzanie zamówieniami), Users (zarządzanie użytkownikami), Statistics (wykresy sprzedaży, najpopularniejsze kategorie, statystyki rekomendacji), Debug ML (narzędzia debugowania algorytmów ML: tabela reguł asocjacyjnych, statystyki sentymentu, analiza podobieństw CBF, reguły rozmyte, macierz Markova).
\end{itemize}

\textbf{Routing - React Router v6}:

Aplikacja wykorzystuje deklaratywny routing React Router v6 z zagnieżdżonymi trasami dla stron publicznych (home, shop, product), chronionych (cart, client panel) oraz administracyjnych (admin panel). Komponent PrivateRoute sprawdza autentykację użytkownika i przekierowuje niezalogowanych do strony logowania.

\textbf{Zarządzanie stanem - Context API}:

Aplikacja wykorzystuje Context API zamiast Redux dla prostszego zarządzania stanem globalnym. AuthContext przechowuje dane zalogowanego użytkownika i token JWT. CartContext zarządza stanem koszyka zakupowego z funkcjami add, remove, update quantity.

\textbf{Komunikacja z API - Axios}:

Wszystkie zapytania HTTP obsługiwane przez Axios z globalną konfiguracją interceptorów. Automatyczna obsługa błędów 401 Unauthorized z przekierowaniem do logowania. Dołączanie tokena JWT do nagłówków Authorization dla chronionych endpointów.

\textbf{Animacje - Framer Motion}:

Płynne przejścia między stronami oraz animacje komponentów realizowane przez Framer Motion z efektami fade-in, slide-up i scroll-driven. Poprawia doświadczenie użytkownika (UX) bez obciążania wydajności aplikacji.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/useCaseDiagram.png}
  \caption{Diagram przypadków użycia.}
  \label{fig:use_case}
\end{figure}

\subsection*{6.4 Diagram przypadków użycia}
\addcontentsline{toc}{subsection}{6.4 Diagram przypadków użycia}

Diagram przypadków użycia przedstawia funkcjonalności systemu rekomendacji e-commerce z perspektywy trzech grup użytkowników o różnych poziomach uprawnień.

\textbf{Aktorzy systemu}

System wyróżnia trzech aktorów reprezentujących różne role użytkowników:

\textbf{1. Gość (użytkownik niezalogowany)} -- osoba odwiedzająca sklep bez uwierzytelnienia. Gość ma ograniczone uprawnienia, może przeglądać katalog produktów, korzystać z zaawansowanej wyszukiwarki z algorytmem rozmytym oraz dodawać produkty do koszyka. Nie ma dostępu do spersonalizowanych rekomendacji, ponieważ system nie posiada informacji o jego historii zakupowej.

\textbf{2. Klient (użytkownik zalogowany)} -- zarejestrowany użytkownik posiadający konto w systemie. Dziedziczy wszystkie uprawnienia Gościa, ale dodatkowo otrzymuje dostęp do spersonalizowanych rekomendacji generowanych na podstawie jego historii zakupów. Klient może składać zamówienia, przeglądać historię swoich transakcji oraz zarządzać swoim profilem. System śledzi jego zachowania zakupowe, budując profil preferencji wykorzystywany przez algorytmy rekomendacyjne.

\textbf{3. Administrator} -- użytkownik z uprawnieniami zarządzania systemem rekomendacji. Administrator ma dostęp do dedykowanego panelu umożliwiającego konfigurację systemu, w tym dynamiczną zmianę aktywnego algorytmu rekomendacji (przełączanie między Content-Based Filtering, logiką rozmytą a modelem probabilistycznym). Może generować rekomendacje dla wszystkich użytkowników systemu, przeglądać podgląd rekomendacji przed ich publikacją oraz korzystać z zaawansowanych narzędzi debugowania algorytmów (analiza wag cech, podgląd macierzy podobieństwa, wizualizacja macierzy przejść Markowa).

\textbf{Główne przypadki użycia}

Kluczowe funkcjonalności systemu obejmują:

\textbf{Przeglądanie i wyszukiwanie produktów} -- podstawowa funkcjonalność dostępna dla wszystkich aktorów. Katalog produktów obsługuje stronicowanie, filtrowanie po kategoriach oraz zaawansowane wyszukiwanie rozmyte wykorzystujące algorytm Levenshteina do tolerowania literówek i odmian wyrazów.

\textbf{Wyświetlanie rekomendacji spersonalizowanych} -- przypadek użycia dostępny dla zalogowanych Klientów. System automatycznie generuje listę produktów rekomendowanych na podstawie historii zakupowej użytkownika, wykorzystując aktualnie wybrany algorytm (CBF, rozmyty lub probabilistyczny). Rekomendacje są wyświetlane na stronie głównej, w panelu klienta oraz na stronach szczegółowych produktów jako sugestie ``Klienci kupujący ten produkt kupili również...''.

\textbf{Generowanie rekomendacji przez Administratora} -- Administrator może ręcznie wywołać proces generowania rekomendacji dla wybranego użytkownika lub globalnie dla wszystkich użytkowników systemu. Ta funkcjonalność jest szczególnie przydatna podczas testowania różnych konfiguracji algorytmów oraz po wprowadzeniu zmian w parametrach systemu.

\textbf{Zmiana ustawień algorytmu} -- kluczowa funkcjonalność administracyjna umożliwiająca dynamiczne przełączanie między trzema zaimplementowanymi metodami rekomendacyjnymi. Administrator wybiera algorytm z interfejsu panelu, a zmiana jest natychmiast propagowana do całego systemu bez konieczności restartu aplikacji.

\textbf{Debugowanie i analiza algorytmów} -- zaawansowany przypadek użycia przeznaczony dla Administratora. Panel debugowania prezentuje wewnętrzne metryki działania algorytmów: w trybie CBF wyświetlane są wagi poszczególnych cech produktowych i macierz podobieństwa, w trybie rozmytym pokazywane są profile użytkowników z wartościami funkcji przynależności, w trybie probabilistycznym prezentowane są prawdopodobieństwa zakupów i macierz przejść Markowa.

\textbf{Składanie zamówień} -- dostępne dla Klientów. Proces zakupowy jest śledżony przez system rekomendacji - każde zamówienie aktualizuje profil preferencji użytkownika, macierz przejść Markowa oraz dane treningowe modelu Naive Bayes, co wpływa na jakość przyszłych rekomendacji.

\subsection*{6.5 Baza danych — modele}
\addcontentsline{toc}{subsection}{6.5 Baza danych — modele}

Schemat bazy danych PostgreSQL został wygenerowany automatycznie przez Django ORM na podstawie zdefiniowanych modeli aplikacji. Struktura bazy danych jest podzielona na pięć modułów funkcjonalnych, które wspólnie realizują logikę systemu rekomendacji e-commerce.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/appErd.png}
  \caption{ERD - główne tabele aplikacji.}
  \label{fig:app_erd}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{images/methodsErd.png}
  \caption{ERD - tabele metod rekomendacyjnych.}
  \label{fig:methods_erd}
\end{figure}

\textbf{Moduł Produktów i Kategorii}

Moduł ten stanowi fundament systemu e-commerce, przechowując informacje o oferowanych produktach oraz ich klasyfikacji. Tabela produktów (\texttt{db\_product}) zawiera podstawowe atrybuty każdego artykułu: unikalny identyfikator, nazwę, cenę aktualną oraz opcjonalnie cenę przed obniżką (dla promocji) oraz rozbudowany opis tekstowy. Każdy produkt może należeć do wielu kategorii jednocześnie dzięki relacji wiele-do-wielu, co umożliwia elastyczną klasyfikację (np. laptop może być w kategoriach ``Komputery'', ``Gaming'', ``Produkty mobilne''). Dodatkowo produkty mogą być oznaczane tagami i przypisywane do promocji sprzedażowych.

Tabela kategorii (\texttt{db\_category}) definiuje taksonomię sklepu, obejmując 48 różnych kategorii produktowych. Każda kategoria posiada unikalną nazwę oraz opcjonalny opis wyjaśniający jej zakres. Kategorie są kluczowe dla algorytmów rekomendacji - wykorzystywane są w łańcuchach Markowa do analizy sekwencji zakupowych oraz w logice rozmytej do budowania profili preferencji użytkowników.

Specyfikacje techniczne (\texttt{db\_specification}) przechowują szczegółowe parametry produktów w postaci par klucz-wartość, gdzie klucz to nazwa parametru (np. ``Procesor'', ``RAM'', ``Przekątna ekranu''), a wartość to konkretna specyfikacja. Ta struktura pozwala na dynamiczne definiowanie cech charakterystycznych dla różnych typów produktów. Specyfikacje są intensywnie wykorzystywane przez algorytm Content-Based Filtering do obliczania podobieństwa produktów na podstawie ich cech technicznych.

\textbf{Moduł Użytkowników i Zamówień}

Moduł zarządzania użytkownikami rozszerza standardowy model użytkownika Django (\texttt{AbstractUser}) o dodatkowe pole roli, rozróżniające administratorów od zwykłych klientów. Tabela użytkowników (\texttt{db\_user}) przechowuje dane uwierzytelniające (login, hasło, email) oraz flagi określające status konta i uprawnienia. Rozróżnienie ról jest istotne dla systemu rekomendacji, ponieważ administratorzy mają dostęp do globalnych funkcji zarządzania algorytmami, podczas gdy klienci otrzymują spersonalizowane rekomendacje.

Historia zamówień (\texttt{db\_order}) rejestruje wszystkie transakcje użytkowników wraz z datą złożenia zamówienia oraz statusem jego realizacji. Tabela pośrednicząca produktów w zamówieniach (\texttt{db\_order\_product}) łączy zamówienia z produktami, przechowując informację o ilości każdego zakupionego artykułu. Te dane są fundamentalne dla wszystkich trzech metod rekomendacyjnych - pozwalają budować profile preferencji użytkowników, obliczać prawdopodobieństwa zakupów oraz konstruować macierze przejść między kategoriami produktowymi w modelu Markowa.

\textbf{Moduł Rekomendacji Content-Based Filtering}

Tabela podobieństw produktów (\texttt{method\_product\_similarity}) przechowuje prekompilowane wartości podobieństwa między parami produktów, obliczone na podstawie ich cech technicznych metodą kosinusową. Każdy rekord zawiera identyfikatory dwóch porównywanych produktów, typ zastosowanego podobieństwa oraz wynik w skali 0-1. Unikalne ograniczenie na parę produktów i typ podobieństwa zapobiega duplikacjom. Indeks na pierwszym produkcie i typie podobieństwa umożliwia szybkie wyszukiwanie najbardziej podobnych produktów w czasie rzeczywistym podczas generowania rekomendacji.

\textbf{Moduł Rekomendacji Logiki Rozmytej}

Profile rozmyte użytkowników (\texttt{method\_fuzzy\_user\_profile}) agregują zachowania zakupowe w trzy wymiary: wrażliwość cenową (czy użytkownik wybiera tanie czy drogie produkty), preferencje kategorialne (jakie rodzaje produktów kupuje najczęściej) oraz preferencję jakości (czy wybiera produkty premium). Preferencje kategorialne są przechowywane w formacie JSON, co umożliwia elastyczne reprezentowanie złożonych profili wielokategorialnych. Profile są automatycznie aktualizowane po każdym zamówieniu i wykorzystywane przez silnik rozmyty do generowania spersonalizowanych rekomendacji.

Macierz przejść Markowa (\texttt{method\_markov\_transitions}) modeluje prawdopodobieństwa przejść między kategoriami produktowymi na podstawie historycznych sekwencji zakupowych. Każdy rekord reprezentuje prawdopodobieństwo, że użytkownik, który kupił produkt z kategorii A, następnie kupi produkt z kategorii B. Przechowywane są zarówno znormalizowane prawdopodobieństwa przejścia, jak i surowe liczby obserwacji, co umożliwia aktualizację macierzy w miarę napływu nowych danych bez konieczności przeliczeń od zera.

Wzorce zakupowe użytkowników (\texttt{method\_user\_purchase\_pattern}) agregują częstotliwość zakupów w poszczególnych kategoriach oraz średnią wartość zamówienia per kategoria. Te informacje są wykorzystywane przez algorytm rozmyty do budowania profili oraz przez model Markowa do ważenia prawdopodobieństw przejść.

\textbf{Moduł Probabilistyki Bayesowskiej}

Tabela prawdopodobieństw zakupu (\texttt{method\_purchase\_probability}) przechowuje predykcje modelu Naive Bayes dla par użytkownik-produkt, wskazując z jakim prawdopodobieństwem dany użytkownik kupi konkretny produkt. Dodatkowo zapisywany jest poziom ufności predykcji, co pozwala systemowi rekomendacji filtrować niepewne wyniki.

Prognozy sprzedaży (\texttt{method\_sales\_forecast}) zawierają predykcje przyszłej sprzedaży produktów na określone daty wraz z przedziałami ufności. Są wykorzystywane zarówno w systemie rekomendacji (promowanie produktów z rosnącą sprzedażą), jak i w zarządzaniu magazynem.

Oceny ryzyka (\texttt{method\_risk\_assessment}) przechowują wyniki analizy ryzyka churn użytkowników oraz ryzyka wyprzedania produktów. Każda ocena zawiera typ ryzyka, identyfikator encji (użytkownik/produkt), wynik ryzyka w skali 0-1 oraz opcjonalne sugestie działań mitygujących (np. ``Wysłać kod rabatowy'', ``Uzupełnić stan magazynowy'').

\textbf{Konfiguracja Systemu Rekomendacji}

Tabela ustawień (\texttt{RecommendationSettings}) implementuje wzorzec singleton przechowujący globalną konfigurację systemu, w szczególności aktualnie wybrany algorytm rekomendacji (content\_based, fuzzy\_logic lub probabilistic). Administrator może dynamicznie przełączać algorytm, co natychmiast wpływa na rekomendacje wyświetlane wszystkim użytkownikom systemu.

\subsection*{6.6 Wdrożenie aplikacji — Docker}
\addcontentsline{toc}{subsection}{6.6 Wdrożenie aplikacji — Docker}

Aplikacja została skonteneryzowana przy użyciu Docker, co zapewnia spójność środowiska między development/staging/production oraz upraszcza proces wdrożenia.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.92\textwidth]{images/dockerView.jpg}
  \caption{Deployment Docker - architektura trójwarstwowa.}
  \label{fig:docker_view}
\end{figure}

Architektura deploymentu składa się z trzech kontenerów Docker:

\textbf{1. Backend Container}: Django 4.2, port 8000.

\textbf{2. Frontend Container}: React 18, port 3000.

\textbf{3. Database Container}: PostgreSQL 14, port 5432.

Docker Compose orchestruje wszystkie kontenery z automatyczną obsługą zależności.

\textbf{Zalety konteneryzacji}:
\begin{itemize}
\item \textbf{Powtarzalność} -- identyczne środowisko dev/prod eliminuje problemy ``works on my machine''
\item \textbf{Izolacja} -- każdy serwis w osobnym kontenerze, zero konfliktów zależności
\item \textbf{Przenośność} -- build image raz, uruchom na dowolnym serwerze z Docker
\item \textbf{Łatwość uruchomienia} -- \texttt{docker-compose up} uruchamia całą aplikację jedną komendą
\end{itemize}

\newpage

\section*{Rozdzia{} 7}
\addcontentsline{toc}{section}{Rozdzia{} 7: Wyniki i ewaluacja}
\section*{Wyniki i ewaluacja}

\subsection*{7.1 Metodologia testowania}
\addcontentsline{toc}{subsection}{7.1 Metodologia testowania}

System został przetestowany na danych z aplikacji e-commerce:
\begin{itemize}
    \item 500 produktów w 48 kategoriach
    \item 20 użytkowników z historią zakupów
    \item 265 zamówień, 569 pozycji (OrderProduct)
    \item Środowisko: Django 4.2, PostgreSQL 14, 8GB RAM, Intel i7
\end{itemize}

\subsection*{7.2 Wydajność Content-Based Filtering}
\addcontentsline{toc}{subsection}{7.2 Wydajność Content-Based Filtering}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Metryka} & \textbf{Wartość} \\
\hline
Czas generowania macierzy & 45-60 sekund \\
Czas odpowiedzi (cache HIT) & 50-100 ms \\
Czas odpowiedzi (cache MISS) & 5-10 sekund \\
Próg podobieństwa & 0.2 (20\%) \\
Redukcja rekordów & $\sim$70\% \\
Bulk insert speedup & 80x \\
\hline
\end{tabular}
\caption{Wydajność Content-Based Filtering}
\end{table}

Coverage: 83\% produktów ma przynajmniej jedno podobieństwo > 0.2.

\subsection*{7.3 Wydajność Fuzzy Logic}
\addcontentsline{toc}{subsection}{7.3 Wydajność Fuzzy Logic}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Metryka} & \textbf{Wartość} \\
\hline
Czas ewaluacji produktu & < 1 ms \\
Czas dla 100 produktów & 50-100 ms \\
Pamięć & $\sim$10 MB (stałe) \\
Interpretowalność & 100\% \\
Liczba reguł & 6 \\
\hline
\end{tabular}
\caption{Wydajność Fuzzy Logic}
\end{table}

Fuzzy Logic jest najszybszą metodą — brak macierzy, obliczenia on-the-fly.

\subsection*{7.4 Wydajność modeli probabilistycznych}
\addcontentsline{toc}{subsection}{7.4 Wydajność modeli probabilistycznych}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Metryka} & \textbf{Wartość} \\
\hline
Czas treningu Markov & 2-3 sekundy \\
Czas treningu NB & 1-2 sekundy \\
Czas predykcji & < 10 ms \\
Liczba stanów Markov & 48 (kategorie) \\
Dokładność NB (churn) & $\sim$78\% \\
\hline
\end{tabular}
\caption{Wydajność modeli probabilistycznych}
\end{table}

\subsection*{7.5 Porównanie metod}
\addcontentsline{toc}{subsection}{7.5 Porównanie metod}

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Cecha} & \textbf{CBF} & \textbf{Fuzzy} & \textbf{Probabilistic} \\
\hline
Cold start (nowy produkt) & Tak & Tak & Nie \\
Cold start (nowy użytkownik) & Częściowo & Tak & Nie \\
Interpretowalność & Średnia & Wysoka & Średnia \\
Czas odpowiedzi & 50ms & 50ms & 10ms \\
Pamięć & Wysoka & Niska & Średnia \\
Personalizacja & Słaba & Średnia & Wysoka \\
\hline
\end{tabular}
\caption{Porównanie zaimplementowanych metod rekomendacji}
\end{table}

\subsection*{7.6 Wnioski}
\addcontentsline{toc}{subsection}{7.6 Wnioski}

W ramach pracy zaimplementowano trzy metody rekomendacji produktów:

\textbf{Content-Based Filtering} — rozwiązuje problem zimnego startu dla nowych produktów. Wagi cech (kategoria 40\%, tagi 30\%, cena 20\%, słowa kluczowe 10\%) zostały dobrane empirycznie.

\textbf{Logika rozmyta} — oferuje najwyższą interpretowalność. Każda rekomendacja ma wyjaśnienie w postaci aktywacji 6 reguł IF-THEN.

\textbf{Modele probabilistyczne} — umożliwiają personalizację na podstawie historii (Markov) i profilu (Naive Bayes).

Wszystkie algorytmy zaimplementowano od podstaw w Pythonie, bez zewnętrznych bibliotek ML.

\newpage

\section*{Podsumowanie}
\addcontentsline{toc}{section}{Podsumowanie}

W ramach pracy inżynierskiej zrealizowano następujące cele:

\begin{enumerate}
    \item Zaprojektowano i zaimplementowano modułowy system rekomendacyjny z trzema niezależnymi silnikami
    \item Zaimplementowano algorytmy CBF, Fuzzy Logic i modele probabilistyczne od podstaw
    \item Zoptymalizowano wydajność: cache, bulk operations, indeksowanie bazy danych
    \item Przeprowadzono ewaluację na rzeczywistych danych z aplikacji e-commerce
    \item Przygotowano dokumentację techniczną i diagramy UML
\end{enumerate}

\textbf{Wnioski praktyczne}

Implementacja systemu rekomendacyjnego od podstaw, bez użycia gotowych bibliotek ML (scikit-learn, TensorFlow), pozwoliła na głębokie zrozumienie mechanizmów działania algorytmów oraz ich świadome dostosowanie do specyfiki e-commerce:

\textbf{Content-Based Filtering} okazał się najbardziej uniwersalną metodą. Rozwiązuje problem zimnego startu dla nowych produktów -- wystarczy opis i kategoria, aby system mógł generować rekomendacje. Wagi cech (kategoria 40\%, tagi 30\%, cena 20\%, słowa kluczowe 10\%) zostały dobrane empirycznie na podstawie testów A/B. Główne ograniczenie to efekt ``filter bubble'' -- użytkownik otrzymuje podobne produkty, nie odkrywając nowych kategorii.

\textbf{Logika rozmyta} oferuje najwyższą interpretowalność spośród zaimplementowanych metod. Każda rekomendacja ma wyjaśnienie w postaci aktywacji konkretnych reguł IF-THEN, co jest istotne z perspektywy GDPR (prawo do wyjaśnienia decyzji algorytmicznych). System funkcji przynależności (cheap/medium/expensive) modeluje niepewność w preferencjach użytkownika lepiej niż sztywne progi cenowe. W praktyce Fuzzy Logic sprawdza się najlepiej dla użytkowników z umiarkowaną historią zakupów.

\textbf{Modele probabilistyczne} (Markov Chain + Naive Bayes) umożliwiają najgłębszą personalizację. Łańcuch Markowa przewiduje sekwencje zakupowe na poziomie kategorii produktów -- użytkownik kupujący laptop prawdopodobnie następnie kupi akcesoria. Naive Bayes z wygładzaniem Laplace'a rozwiązuje problem zerowych prawdopodobieństw dla niewidzianych cech. Predykcja churnu (ryzyka rezygnacji klienta) pozwala na proaktywne działania marketingowe.

\textbf{Komplementarność metod}: W praktyce najlepsze wyniki daje kombinacja wszystkich trzech podejść:
\begin{itemize}
    \item CBF dla nowych produktów i użytkowników bez historii
    \item Fuzzy Logic dla personalizacji z zachowaniem interpretowalności
    \item Modele probabilistyczne dla głębokiej analizy behawioralnej stałych klientów
\end{itemize}

\textbf{Ograniczenia i kierunki rozwoju}:
\begin{itemize}
    \item Problem zimnego startu dla nowych użytkowników -- rozwiązanie: wstępna ankieta preferencji
    \item Skalowalność dla katalogów >10000 produktów -- rozwiązanie: approximate nearest neighbors
    \item Brak obsługi kontekstu czasowego -- rozwiązanie: modele sekwencyjne (LSTM)
    \item Słownik sentymentu nie radzi sobie z negacją i ironią -- rozwiązanie: transformery (BERT)
\end{itemize}

System jest gotowy do wdrożenia produkcyjnego. Wszystkie metody są komplementarne i mogą być używane razem lub osobno w zależności od potrzeb biznesowych. Implementacja od podstaw zapewnia pełną kontrolę nad parametrami i możliwość dostosowania do specyficznych wymagań platformy e-commerce.

\newpage

\begin{thebibliography}{99}

\bibitem{pazzani2007content}
Pazzani, M. J., \& Billsus, D. (2007). Content-Based Recommendation Systems. \textit{The Adaptive Web}, Springer, pp. 325-341.

\bibitem{zadeh1965fuzzy}
Zadeh, L. A. (1965). Fuzzy Sets. \textit{Information and Control}, 8(3), pp. 338-353.

\bibitem{mamdani1975experiment}
Mamdani, E. H., \& Assilian, S. (1975). An Experiment in Linguistic Synthesis with a Fuzzy Logic Controller. \textit{International Journal of Man-Machine Studies}, 7(1), pp. 1-13.

\bibitem{rabiner1989tutorial}
Rabiner, L. R. (1989). A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition. \textit{Proceedings of the IEEE}, 77(2), pp. 257-286.

\bibitem{murphy2012machine}
Murphy, K. P. (2012). \textit{Machine Learning: A Probabilistic Perspective}. MIT Press.

\bibitem{ricci2015recommender}
Ricci, F., Rokach, L., \& Shapira, B. (2015). \textit{Recommender Systems Handbook}. Springer.

\bibitem{gomez2016netflix}
Gomez-Uribe, C. A., \& Hunt, N. (2016). The Netflix Recommender System: Algorithms, Business Value, and Innovation. \textit{ACM Transactions on Management Information Systems}, 6(4), pp. 1-19.

\bibitem{klement2000triangular}
Klement, E. P., Mesiar, R., \& Pap, E. (2000). \textit{Triangular Norms}. Springer.

\bibitem{salton1989automatic}
Salton, G., \& Buckley, C. (1988). Term-Weighting Approaches in Automatic Text Retrieval. \textit{Information Processing \& Management}, 24(5), pp. 513-523.

\bibitem{ross2010fuzzy}
Ross, T. J. (2010). \textit{Fuzzy Logic with Engineering Applications}. Wiley, 3rd Edition.

\bibitem{mckinsey2013}
McKinsey \& Company. (2013). Big Data: The Next Frontier for Innovation, Competition, and Productivity.

\bibitem{linden2003amazon}
Linden, G., Smith, B., \& York, J. (2003). Amazon.com Recommendations: Item-to-Item Collaborative Filtering. \textit{IEEE Internet Computing}, 7(1), pp. 76-80.

\bibitem{sarwar2001item}
Sarwar, B., Karypis, G., Konstan, J., \& Riedl, J. (2001). Item-Based Collaborative Filtering Recommendation Algorithms. \textit{Proceedings of WWW}, pp. 285-295.

\bibitem{agrawal1994fast}
Agrawal, R., \& Srikant, R. (1994). Fast Algorithms for Mining Association Rules. \textit{Proceedings of VLDB}, pp. 487-499.

\bibitem{mendel2001uncertain}
Mendel, J. M. (2001). \textit{Uncertain Rule-Based Fuzzy Logic Systems: Introduction and New Directions}. Prentice Hall.

\end{thebibliography}


\newpage
% Wykaz rysunków
\section*{Wykaz ilustracji, rysunków i tabel}
\addcontentsline{toc}{section}{Wykaz ilustracji, rysunków i tabel}
\small
\listoffigures

% Spis tabel
{
\addcontentsline{toc}{section}{Spis tabel}
\small
\listoftables
}

\end{document}
